<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/blogs/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/blogs/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/blogs/images/favicon.ico">
  <link rel="mask-icon" href="/blogs/images/favicon.ico" color="#222">

<link rel="stylesheet" href="/blogs/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/blogs/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.myhz0606.com","root":"/blogs/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null,"valine":{"enable":true,"appId":null,"appKey":null,"serverURLs":null,"placeholder":"Just go go","avatar":"mm","meta":["nick","mail","link"],"pageSize":10,"visitor":true,"comment_count":true,"recordIP":false}},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="莫叶何竹">
<meta property="og:url" content="http://www.myhz0606.com/index.html">
<meta property="og:site_name" content="莫叶何竹">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="wwjiang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://www.myhz0606.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>莫叶何竹</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blogs/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">莫叶何竹</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/blogs/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/blogs/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/blogs/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blogs/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/myhz0606" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.myhz0606.com/2023/02/20/DDPM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blogs/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blogs/2023/02/20/DDPM/" class="post-title-link" itemprop="url">DDPM(denoising diffusion probabilistic)技术小结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-02-20 11:13:00" itemprop="dateCreated datePublished" datetime="2023-02-20T11:13:00+08:00">2023-02-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-03-14 16:33:13" itemprop="dateModified" datetime="2023-03-14T16:33:13+08:00">2023-03-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blogs/categories/diffusion-model/" itemprop="url" rel="index"><span itemprop="name">diffusion model</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>16 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="DDPM技术小结-denoising-diffusion-probabilistic"><a href="#DDPM技术小结-denoising-diffusion-probabilistic" class="headerlink" title="DDPM技术小结 (denoising diffusion probabilistic)"></a>DDPM技术小结 (denoising diffusion probabilistic)</h1><h2 id="1-从直觉上理解DDPM"><a href="#1-从直觉上理解DDPM" class="headerlink" title="1 从直觉上理解DDPM"></a>1 从直觉上理解DDPM</h2><p>在详细推到公式之前，我们先从直觉上理解一下什么是扩散</p>
<p>对于常规的生成模型，如GAN，VAE，它直接从噪声数据生成图像，我们不妨记噪声数据为$z$,其生成的图片为$x$</p>
<p><strong>对于常规的生成模型</strong>：</p>
<p>学习一个解码函数(即我们需要学习的模型)$p$，实现 $p(z)=x $</p>
<script type="math/tex; mode=display">
z \stackrel{p} \longrightarrow x</script><p>常规方法只需要一次预测即能实现噪声到目标的映射，虽然速度快，但是效果不稳定。</p>
<p>常规生成模型的训练过程（以VAE为例）</p>
<script type="math/tex; mode=display">
 x \stackrel{q} \longrightarrow z \stackrel{p} \longrightarrow \widehat{x}</script><p><strong>对于diffusion model</strong></p>
<p>它将噪声到目标的过程进行了多步拆解。不妨假设一共有$T+1$个时间步，第$T$个时间步 $x_T$是噪声数据，第0个时间步的输出是目标图片$x_0$。其过程可以表述为：</p>
<script type="math/tex; mode=display">
 z = x_T \stackrel{p} \longrightarrow x_{T-1} \stackrel{p} \longrightarrow \cdots \stackrel{p} \longrightarrow  x_{1} \stackrel{p} \longrightarrow x_0</script><p>对于DDPM它采用的是一种自回归式的重建方法，每次的输入是当前的时刻及当前时刻的噪声图片。也就是说它把噪声到目标图片的生成分成了T步，这样每一次的预测相当于是对残差的预测。优势是重建效果稳定，但速度较慢。</p>
<p>训练整体pipeline包含两个过程</p>
<h2 id="2-diffusion-pipeline"><a href="#2-diffusion-pipeline" class="headerlink" title="2 diffusion pipeline"></a>2 diffusion pipeline</h2><h3 id="2-1前置知识"><a href="#2-1前置知识" class="headerlink" title="2.1前置知识:"></a>2.1前置知识:</h3><p>高斯分布的一些性质</p>
<p>（1）如果$X \sim \mathcal{N}(\mu, \sigma^2)$,且$a$与$b$是实数,那么$aX+b \sim \mathcal{N}(a\mu+b, (a\sigma)^2)$</p>
<p>（2）如果$X \sim \mathcal{N}(\mu(x), \sigma^2(x)) $,$Y \sim \mathcal{N}(\mu(y), \sigma^2(y))$,且$X,Y$是统计独立的正态随机变量,则它们的和也满足高斯分布(高斯分布可加性).</p>
<script type="math/tex; mode=display">
X+Y \sim \mathcal{N}(\mu(x)+\mu{(y), \sigma^2(x) + \sigma^2(y)}) \\
X-Y \sim \mathcal{N}(\mu(x)-\mu{(y), \sigma^2(x) + \sigma^2(y)})</script><p>均值为$\mu$方差为$\sigma$的高斯分布的概率密度函数为</p>
<script type="math/tex; mode=display">
\begin{eqnarray}
f(x) &=& \frac{1}{\sqrt{2\pi} \sigma } \exp \left ({- \frac{(x - \mu)^2}{2\sigma^2} } \right) \nonumber \\
&=& \frac{1}{\sqrt{2\pi} \sigma } \exp \left[ -\frac{1}{2} \left( \frac{1}{\sigma^2}x^2 - \frac{2\mu}{\sigma^2}x + \frac{\mu^2}{\sigma^2}  \right )  \right]
\end{eqnarray}</script><h3 id="2-2-加噪过程"><a href="#2-2-加噪过程" class="headerlink" title="2.2 加噪过程"></a>2.2 加噪过程</h3><p>1 前向过程：将图片数据映射为噪声</p>
<p>每一个时刻都要添加高斯噪声，后一个时刻都是由前一个时刻加噪声得到。（其实每一个时刻加的噪声就是训练所用的标签）。即</p>
<script type="math/tex; mode=display">
x_0 \stackrel{q} \longrightarrow x_1 \stackrel{q} \longrightarrow x_{2} \stackrel{q} \longrightarrow \cdots \stackrel{q} \longrightarrow  x_{T-1} \stackrel{q} \longrightarrow x_T=z</script><p>下面我们详细来看</p>
<p>记$\beta_t = 1 - \alpha_t$，$\beta_t$随t的增加而增大(论文中<sup><a href="#fn_2" id="reffn_2">2</a></sup>时从0.0001 -&gt; 0.02) (这是因为一开始加一点噪声就很明显,后面需要增大噪声的量才明显).DDPM将加噪声过程建模为(这个是定义式,当然也可以定义成别的!)</p>
<script type="math/tex; mode=display">
\begin{eqnarray}
x_t &=& \sqrt{\alpha_t}x_{t-1} + \sqrt{(1 - \alpha_t)}z_t \nonumber \\
&=&  \sqrt{\alpha_t}x_{t-1} + \sqrt{\beta_t}z_t
\end{eqnarray}</script><p>$x_t$为在$t$时刻的图片，当$t=0$时为原图；$z_t$为在$t$时刻所加的噪声，服从标准正态分布$z_t \sim \mathcal{N}(0, \textbf{I})$;$\alpha_t$是常数,是自己定义的变量;根据高斯分布的定义,$x_t$的分布$q(x_t|x_{t-1})=\mathcal{N}(x_t; \sqrt{\alpha_t}x_{t-1}, (1 - \alpha_t) \textbf{I})$随着$T$增大,$x_t$越来越接近纯高斯分布.</p>
<p>同理:</p>
<script type="math/tex; mode=display">
x_{t-1} = \sqrt{\alpha_{t-1} }x_{t-2} + \sqrt{1 - \alpha_{t-1} }z_{t-1}</script><p>将式(9)代入式(8)可得:</p>
<script type="math/tex; mode=display">
\begin{eqnarray}
x_t &=& \sqrt{\alpha_t} (\sqrt{\alpha_{t-1} }x_{t-2} + \sqrt{1 - \alpha_{t-1} }z_{t-1}) + \sqrt{1 - \alpha_t}z_t  \nonumber\\
    &=& \sqrt{\alpha_t \alpha_{t-1} }x_{t-2} + (\sqrt{\alpha_t (1 - \alpha_{t-1})} z_{t-1}  + \sqrt{1 - \alpha_t}z_t)
\end{eqnarray}</script><p>由于$z_{t-1}$服从均值为0,方差为1的高斯分布(即标准正态分布),根据定义$\sqrt{\alpha_t (1 - \alpha_{t-1})} z_{t-1}$服从的是均值为0,方差为$\alpha_t (1 - \alpha_{t-1})$的高斯分布.即$\sqrt{\alpha_t (1 - \alpha_{t-1})} z_{t-1} \sim \mathcal{N}(0, \alpha_t (1 - \alpha_{t-1})\textbf{I})$.同理可得$\sqrt{1 - \alpha_t}z_t \sim \mathcal{N}(0, (1 - \alpha_t)\textbf{I})$.则<strong>(高斯分布可加性,可以通过定义推得,不赘述)</strong> </p>
<script type="math/tex; mode=display">
\begin{eqnarray}
(\sqrt{\alpha_t (1 - \alpha_{t-1})} , z_{t-1}  + \sqrt{1 - \alpha_t}z_t) \sim \mathcal{N}(0, \alpha_t (1 - \alpha_{t-1}) + 1 - \alpha_t) &=&  \mathcal{N}(0, 1 - \alpha_t \alpha_{t-1})
\end{eqnarray}</script><p>我们不妨记$\overline{z}_{t-2} \sim \mathcal{N}(0, \textbf{I})$,则$\sqrt{1 - \alpha_t \alpha_{t-1} } \overline{z}_{t-2} \sim \mathcal{N}(0, (1 - \alpha_t \alpha_{t-1})\textbf{I})$则式(10)最终可改写为</p>
<script type="math/tex; mode=display">
x_t = \sqrt{\alpha_t \alpha_{t-1} } x_{t-2} +  \sqrt{1 - \alpha_t \alpha_{t-1} } \overline{z}_{t-2}</script><p>通过递推,容易得到</p>
<script type="math/tex; mode=display">
\begin{eqnarray}
x_t &=& \sqrt{\alpha_t \alpha_{t-1} \cdots \alpha_1} x_0 +  \sqrt{1 - \alpha_t \alpha_{t-1} \dots \alpha_1} \overline{z}_0 \nonumber\\
&=& \sqrt{\prod_{i=1}^{t} {\alpha_i} }x_0 + \sqrt{1 - \prod_{i=1}^{t} {\alpha_i} } \overline {z}_0 \nonumber \\

&\stackrel{\mathrm{令} \overline{\alpha}_{t}  \prod_{i=1}^{t} {\alpha_i} } = & \sqrt{\overline{\alpha}_{t} }x_0+\sqrt{1 - \overline{\alpha}_{t} }\overline{z}_{0}
\end{eqnarray}</script><p>其中$\overline{z}_{0} \sim \mathcal{N}(0, \mathrm{I})$,$x_0$为原图.从式(13)可见,<strong>我们可以从$x_0$得到任意时刻的$x_t$的分布(14),</strong>而无需按照时间顺序递推!这极大提升了计算效率.</p>
<script type="math/tex; mode=display">
\begin{eqnarray}
q(x_t|x_0) &=&  \mathcal{N}(x_t; \mu{(x_t, t)},\sigma^2{(x_t, t)}{}\textbf{I})
\nonumber\\
&=& \mathcal{N}(x_t; \sqrt{\overline{\alpha}_{t} }x_0,(1 - \overline{\alpha}_{t})\textbf{I})
\end{eqnarray}</script><p>⚠️<strong><font color="#DC143C">加噪过程是确定的,没有模型的介入</font>.</strong> 其目的是制作训练时标签</p>
<h3 id="2-3-去噪过程"><a href="#2-3-去噪过程" class="headerlink" title="2.3 去噪过程"></a>2.3 去噪过程</h3><p>给定$x_T$如何求出$x_0$呢?直接求解是很难的,作者给出的方案是:我们可以一步一步求解.即学习一个解码函数$p$,这个$p$能够知道$x_{t}$到$x_{t-1}$的映射规则.如何定义这个$p$是问题的关键.有了$p$,只需从$x_{t}$到$x_{t-1}$逐步迭代,即可得出$x_0$.</p>
<script type="math/tex; mode=display">
z = x_T \stackrel{p} \longrightarrow x_{T-1} \stackrel{p} \longrightarrow \cdots \stackrel{p} \longrightarrow  x_{1} \stackrel{p} \longrightarrow x_0</script><p>去噪过程是加噪过程的逆向.如果说加噪过程是求给定初始分布$x_0$求任意时刻的分布$x_t$,即$q(x_t|x_0)$那么去噪过程所求的分布就是给定任意时刻的分布$x_t$求其初始时刻的分布$x_0$,即$p(x_0|x_t)$ ,通过马尔可夫假设,可以对上述问题进行化简</p>
<script type="math/tex; mode=display">
\begin{eqnarray}
p(x_0|x_t) &=& p(x_0|x1)p(x1|x2)\cdots p(x_{t-1}| x_t) 
\nonumber \\ 
&=& \prod_{i=0}^{t-1}{p(x_i|x_{i+1})}
\end{eqnarray}</script><p>如何求${p(x_{t-1}|x_{t})}$呢?前面的加噪过程我们大力气推到出了${q(x_{t}|x_{t-1})}$,我们可以通过贝叶斯公式把它利用起来</p>
<script type="math/tex; mode=display">
p(x_{t-1}|x_t) = \frac{p(x_{t}|x_{t-1})p(x_{t-1})}{p(x_t)}</script><p>⚠️<font color="#DC143C"><strong>这里的(去噪)$p$和上面的(加噪)$q$只是对分布的一种符号记法,它们是等价的.</strong></font></p>
<p>有了式(17)还是一头雾水,$p(x_t)$和$p(x_{t-1})$都不知道啊!该怎么办呢?这就要借助模型的威力了.下面来看如何构建我们的模型.</p>
<p>延续加噪过程的推导$p(x_t|x_0)$和$p(x_{t-1}|x_0)$我们是可以知道的.因此若我们知道初始分布$x_0$,则</p>
<script type="math/tex; mode=display">
\small
\begin{eqnarray}

p(x_{t-1}|x_t,x_0) &=& \frac{p(x_{t}|x_{t-1}, x_0)p(x_{t-1}|x_0)}{p(x_t|x_0)}
 \\
&=& \frac{\mathcal{N}(x_t; \sqrt{\alpha_t}x_{t-1}, (1 - \alpha_t) \textbf{I} ) 
\mathcal{N}(x_{t-1}; \sqrt{\overline{\alpha}_{t-1} }x_0,(1 - \overline{\alpha}_{t-1}) \textbf{I})}

{ \mathcal{N}(x_t; \sqrt{\overline{\alpha}_{t} }x_0,(1 - \overline{\alpha}_{t}) \textbf{I} )} \\
&\stackrel{将式(6)代入} \propto &  

\frac{
    \exp \left ({- \frac{(x_t - \sqrt{\alpha_t}x_{t-1} )^2}{2 (1 - \alpha_t)} } \right) 
  \exp \left ({- \frac{(x_{t-1} - \sqrt{\overline{\alpha}_{t-1} }x_0 )^2}{2 (1 - \overline{\alpha}_{t-1})} } \right) 
  }
 {

  \exp \left ({- \frac{(x_{t} - \sqrt{\overline{\alpha}_{t} }x_0 )^2}{2 (1 - \overline{\alpha}_{t})} }      \right)
 } \\
  &=& 
 \exp \left [-\frac{1}{2} \left (  
 \frac{(x_t - \sqrt{\alpha_t}x_{t-1} )^2}{1 - \alpha_t} + 
 \frac{(x_{t-1} - \sqrt{\overline{\alpha}_{t-1} }x_0 )^2}{1 - \overline{\alpha}_{t-1} } - 
 \frac{(x_{t} - \sqrt{\overline{\alpha}_{t} }x_0 )^2}{1 - \overline{\alpha}_{t} }


 \right)   \right] \\ 
 &=& \exp \left [ 

 -\frac{1}{2} \left(  

 \left( \frac{\alpha_t}{1-\alpha_t} + \frac{1}{1 - \overline{\alpha}_{t-1} } \right)x^2_{t-1} -

\left ( \frac{2\sqrt{\overline{\alpha_{t} } } }{1 - \alpha_t}x_t + \frac{2 \sqrt{\overline{\alpha}_{t-1} } }  {1 - \overline{\alpha}_{t-1} }x_0  \right)x_{t-1} + C(x_t, x_0)


 \right)


 \right]


\end{eqnarray}</script><p>结合高斯分布的定义(6)来看式(22),不难发现$p(x_{t-1}|x_t,x_0)$也是服从高斯分布的.并且结合式(6)我们可以求出其方差和均值</p>
<script type="math/tex; mode=display">
\begin{eqnarray}
\frac{1}{\sigma_2} &=&  \frac{\alpha_t}{1-\alpha_t} + \frac{1}{1 - \overline{\alpha}_{t-1} } \\
\frac{2\mu}{\sigma^2} &=& \frac{2\sqrt{\overline{\alpha_{t} } } }{1 - \alpha_t}x_t + \frac{2 \sqrt{\overline{\alpha}_{t-1} } }  {1 - \overline{\alpha}_{t-1} }x_0
\end{eqnarray}</script><p>可以求得:</p>
<script type="math/tex; mode=display">
\begin{eqnarray}
\sigma^2 &=& \frac{1 - \overline{\alpha}_{t-1} }{1 - \overline{\alpha}_{t} } (1 - \alpha_t) \nonumber \\ 
\mu &=& \frac{\sqrt{\alpha_t} (1 - \overline{\alpha}_{t-1})}  {1 - \overline{\alpha}_t}x_t + 
\frac{\sqrt{\overline{\alpha}_{t-1} } (1 - \alpha_t) }{1 - \overline{\alpha}_t}x_0 
\end{eqnarray}</script><p>通过上式,我们可得</p>
<script type="math/tex; mode=display">
p(x_{t-1}|x_t,x_0) = \mathcal{N}(x_{t-1}; \frac{\sqrt{\alpha_t} (1 - \overline{\alpha}_{t-1})}  {1 - \overline{\alpha}_t}x_t + 
\frac{\sqrt{\overline{\alpha}_{t-1} } (1 - \alpha_t) }{1 - \overline{\alpha}_t}x_0 , 
(\frac{1 - \overline{\alpha}_{t-1} }{1 - \overline{\alpha}_{t} } (1 - \alpha_t)) \textbf{I})</script><p>该式是真实的条件分布.我们目标是让模型学到的条件分布$p_\theta(x_{t-1}|x_t)$尽可能的接近真实的条件分布$p(x_{t-1}|x_t, x_0)$.从上式可以看到方差是个固定量,那么我们要做的就是让$p(x_{t-1}|x_t, x_0)$与$p_\theta(x_{t-1}|x_t)$的均值尽可能的对齐,即</p>
<p>(这个结论也可以通过最小化上述两个分布的KL散度推得)</p>
<script type="math/tex; mode=display">
\mathrm{arg} \mathop{min}_\theta \parallel u(x_0, x_t), u_\theta(x_t, t) \parallel</script><p>下面的问题变为:<strong><font color="#DC143C">如何构造$u_\theta(x_t, t)$来使我们的优化尽可能的简单 </font></strong> </p>
<p>我们注意到$\mu(x_0, x_t)$与$\mu_\theta(x_t, t)$都是关于$x_t$的函数,不妨让他们的$x_t$保持一致,则可将$\mu_\theta(x_t, t)$写成</p>
<script type="math/tex; mode=display">
\mu_\theta(x_t, t) = \frac{\sqrt{\alpha_t} (1 - \overline{\alpha}_{t-1})}  {1 - \overline{\alpha}_t}x_t + 
\frac{\sqrt{\overline{\alpha}_{t-1} } (1 - \alpha_t) }{1 - \overline{\alpha}_t} f_\theta(x_t, t)</script><p>$f_\theta(x_t, t)$是我们需要训练的模型.这样对齐均值的问题就转化成了: <strong>给定$x_t, t$来预测原始图片输入$x_0$.</strong>根据上文的加噪过程,我们可以很容易制造训练所需的数据对! (Dalle2的训练采用的是这个方式,可能这就是大力出奇迹吧).事情到这里就结束了吗?</p>
<p>DDPM作者表示直接从$x_t$到$x_0$的预测数据跨度太大了,且效果一般.我们可以将式(12)做一下变形</p>
<script type="math/tex; mode=display">
\begin{eqnarray}
x_t &=&  \sqrt{\overline{\alpha}_{t} }x_0+\sqrt{1 - \overline{\alpha}_{t} }\overline{z}_{0} \nonumber \\
x_0 &=& \frac{1}{\sqrt{\overline{\alpha}_{t} } }(x_t - \sqrt{1 - \overline{\alpha}_{t} }\overline{z}_{0})
\end{eqnarray}</script><p>代入到式(24)中</p>
<script type="math/tex; mode=display">
\begin{eqnarray}
\mu &=& \frac{\sqrt{\alpha_t} (1 - \overline{\alpha}_{t-1})}  {1 - \overline{\alpha}_t}x_t + 
\frac{\sqrt{\overline{\alpha}_{t-1} } (1 - \alpha_t) }{1 - \overline{\alpha}_t} \frac{1}{\sqrt{\overline{a}_{t} } }(x_t - \sqrt{1 - \overline{a}_{t} }\overline{z}_{0}) \nonumber \\

 &=& \frac{\sqrt{\alpha_t} (1 - \overline{\alpha}_{t-1})}  {1 - \overline{\alpha}_t}x_t + 
\frac{(1 - \alpha_t) }{1 - \overline{\alpha}_t} \frac{1}{\sqrt{\alpha}_{t} }(x_t - \sqrt{1 - \overline{\alpha}_{t} }\overline{z}_{0}) \nonumber \\

&\stackrel{合并x_t} =& \frac{\alpha_t(1 - \overline{\alpha}_{t-1}) + (1 - \alpha_t)  }{\sqrt{\alpha}_t (1 - \overline{\alpha}_t)}x_t - \frac{\sqrt{1 - \overline{\alpha}_t}(1 - \alpha_t) }{\sqrt{\alpha_t}(1 - \overline{\alpha}_t)}\overline{z}_0 \nonumber \\
&=& \frac{1 - \overline{\alpha}_t}{\sqrt{\alpha}_t (1 - \overline{\alpha}_t)}x_t - 
\frac{1 - \alpha_t }{\sqrt{\alpha_t}\sqrt{1 - \overline{\alpha}_t} }\overline{z}_0 \nonumber \\
&=& \frac{1}{\sqrt{\alpha}_t}x_t - 
\frac{1 - \alpha_t }{\sqrt{\alpha_t}\sqrt{1 - \overline{\alpha}_t} }\overline{z}_0 

\end {eqnarray}</script><p>经过这次化简,我们将$\mu{(x_0, x_t)} \Rightarrow \mu{(x_t, \overline{z}_0)}$,其中$\overline{z}_0 \sim \mathcal{N}(0, \textbf{I})$,可以将式(29)转变为</p>
<script type="math/tex; mode=display">
\mu_\theta(x_t, t) = \frac{1}{\sqrt{\alpha_t} } x_t -
\frac{1 - \alpha_t }{\sqrt{\alpha_t}\sqrt{1 - \overline{\alpha}_t} }f_\theta(x_t, t)</script><p><font color="#DC143C"><strong>此时对齐均值的问题就转化成:给定$x_t, t$预测$x_t$加入的噪声$\overline{z}_0$,</strong> </font>也就是说我们的模型预测的是噪声$f_\theta{(x_t, t)} \simeq \overline{z}_0$</p>
<h4 id="2-3-1-训练与采样过程"><a href="#2-3-1-训练与采样过程" class="headerlink" title="2.3.1 训练与采样过程"></a>2.3.1 训练与采样过程</h4><p>训练的目标就是这两个噪声的尽可能的相近(用MSE或L1-loss).</p>
<script type="math/tex; mode=display">
L = \mathrm{arg} \mathop{min}_\theta \parallel \epsilon - \epsilon_{\theta}(x_t, t)\parallel ^2</script><p>下图为论文提供的训练和采样过程</p>
<p><img src="https://myhz0606blog.oss-cn-beijing.aliyuncs.com/DDPM/algorithm.png"><br><!-- <img src="../../../../images/DDPM/algorithm.png"  height = 500 alt="图片名称"/> --></p>
<h4 id="2-3-2-采样过程"><a href="#2-3-2-采样过程" class="headerlink" title="2.3.2 采样过程"></a>2.3.2 采样过程</h4><p>通过以上讨论,我们推导出$p_\theta(x_{t-1}|x_t)$高斯分布的均值和方差.$p_\theta(x_{t-1}|x_t)=\mathcal{N}(x_{t-1}; \mu_{\theta}(x_t, t), \sigma^2(t) \textbf{I})$,根据文献<sup><a href="#fn_1" id="reffn_1">1</a></sup>从一个高斯分布中采样一个随机变量可用一个重参数化技巧进行近似</p>
<script type="math/tex; mode=display">
\begin{eqnarray}
x_{t-1} &=& \mu_{\theta}(x_t, t) + \sigma(t) \epsilon,其中 \epsilon \in \mathcal{N}(\epsilon; 0, \textbf{I}) \\
 & = & \frac{1}{\sqrt{\alpha_t} } (x_t -
\frac{1 - \alpha_t }{\sqrt{1 - \overline{\alpha}_t} }f_\theta(x_t, t)) + \sigma(t) \epsilon

\end{eqnarray}</script><p>式(39)和论文给出的采样递推公式一致.</p>
<p>至此,已完成DDPM整体的pipeline.</p>
<p>还没想明白的点,为什么不能根据(7)的变形来进行采样计算呢?</p>
<script type="math/tex; mode=display">
x_{t-1} = \frac{1}{\sqrt{\alpha_t} }x_t - \sqrt{\frac{1 - \alpha_t}{\alpha_t} } f_\theta(x_t, t)</script><h2 id="3-从代码理解训练-amp-预测过程"><a href="#3-从代码理解训练-amp-预测过程" class="headerlink" title="3 从代码理解训练&amp;预测过程"></a>3 从代码理解训练&amp;预测过程</h2><h3 id="3-1-训练过程"><a href="#3-1-训练过程" class="headerlink" title="3.1 训练过程"></a>3.1 训练过程</h3><p>参考代码仓库: <a target="_blank" rel="noopener" href="https://github.com/lucidrains/denoising-diffusion-pytorch/tree/main/denoising_diffusion_pytorch">https://github.com/lucidrains/denoising-diffusion-pytorch/tree/main/denoising_diffusion_pytorch</a></p>
<p>已知项: 我们假定有一批$N$张图片$\{x_i |i=1, 2, \cdots, N\}$</p>
<p><strong>第一步</strong>: 随机采样$K$组成batch,如$\mathrm{x_start}= \{ x_k|k=1,2, \cdots, K \}$, $\mathrm{Shape}(\mathrm{x_start}) = (K, C, H, W)$</p>
<p><strong>第二步</strong>: 随机采样一些时间步</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t = torch.randint(<span class="number">0</span>, self.num_timesteps, (b,), device=device).long()  <span class="comment"># 随机采样时间步</span></span><br></pre></td></tr></table></figure>
<p>第三步: 随机采样噪声</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">noise = default(noise, <span class="keyword">lambda</span>: torch.randn_like(x_start))  <span class="comment"># 基于高斯分布采样噪声</span></span><br></pre></td></tr></table></figure>
<p><strong>第四步</strong>: 计算$\mathrm{x_start}$在所采样的时间步的输出$x_T$(即加噪声).(根据公式12)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">linear_beta_schedule</span>(<span class="params">timesteps</span>):</span><br><span class="line">    scale = <span class="number">1000</span> / timesteps</span><br><span class="line">    beta_start = scale * <span class="number">0.0001</span></span><br><span class="line">    beta_end = scale * <span class="number">0.02</span></span><br><span class="line">    <span class="keyword">return</span> torch.linspace(beta_start, beta_end, timesteps, dtype = torch.float64)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">betas = linear_beta_schedule(timesteps)</span><br><span class="line">alphas = <span class="number">1.</span> - betas</span><br><span class="line">alphas_cumprod = torch.cumprod(alphas, dim=<span class="number">0</span>)</span><br><span class="line">sqrt_one_minus_alphas_cumprod = torch.sqrt(<span class="number">1.</span> - alphas_cumprod)</span><br><span class="line">sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract</span>(<span class="params">a, t, x_shape</span>):</span><br><span class="line">    b, *_ = t.shape</span><br><span class="line">    out = a.gather(-<span class="number">1</span>, t)</span><br><span class="line">    <span class="keyword">return</span> out.reshape(b, *((<span class="number">1</span>,) * (<span class="built_in">len</span>(x_shape) - <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">q_sample</span>(<span class="params">x_start, t, noise=<span class="literal">None</span></span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  \begin&#123;eqnarray&#125;</span></span><br><span class="line"><span class="string">    x_t &amp;=&amp; \sqrt&#123;\alpha_t&#125;x_&#123;t-1&#125; + \sqrt&#123;(1 - \alpha_t)&#125;z_t \nonumber \\</span></span><br><span class="line"><span class="string">    &amp;=&amp;  \sqrt&#123;\alpha_t&#125;x_&#123;t-1&#125; + \sqrt&#123;\beta_t&#125;z_t</span></span><br><span class="line"><span class="string">  \end&#123;eqnarray&#125;</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        extract(sqrt_alphas_cumprod, t, x_start.shape) * x_start +</span><br><span class="line">        extract(sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">x = q_sample(x_start = x_start, t = t, noise = noise)  <span class="comment"># 这就是x0在时间步T的输出</span></span><br></pre></td></tr></table></figure>
<p><strong>第五步</strong>: 预测噪声.输入$x_T,t$到噪声预测模型,来预测此时的噪声$\hat{z}_t = \epsilon_\theta(x_T, t)$.论文用到的模型结构是Unet,与传统Unet的输入有所不同的是增加了一个时间步的输入.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_out = self.model(x, t, x_self_cond=<span class="literal">None</span>)  <span class="comment"># 预测噪声</span></span><br></pre></td></tr></table></figure>
<p><strong>这里面有一个需要注意的点:模型是如何对时间步进行编码并使用的</strong></p>
<ul>
<li>首先会对时间步进行一个编码,将其变为一个向量,以正弦编码为例</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SinusoidalPosEmb</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">      	<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">      	Args:</span></span><br><span class="line"><span class="string">      		x (Tensor), shape like (B,)</span></span><br><span class="line"><span class="string">      	&quot;&quot;&quot;</span></span><br><span class="line">        device = x.device</span><br><span class="line">        half_dim = self.dim // <span class="number">2</span></span><br><span class="line">        emb = math.log(<span class="number">10000</span>) / (half_dim - <span class="number">1</span>)</span><br><span class="line">        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)</span><br><span class="line">        emb = x[:, <span class="literal">None</span>] * emb[<span class="literal">None</span>, :]</span><br><span class="line">        emb = torch.cat((emb.sin(), emb.cos()), dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> emb</span><br><span class="line">      </span><br><span class="line"><span class="comment"># 时间步的编码pipeline如下,本质就是将一个常数映射为一个向量</span></span><br><span class="line">self.time_mlp = nn.Sequential(</span><br><span class="line">    SinusoidalPosEmb(dim),</span><br><span class="line">    nn.Linear(fourier_dim, time_dim),</span><br><span class="line">    nn.GELU(),</span><br><span class="line">    nn.Linear(time_dim, time_dim)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li>将时间步的embedding嵌入到Unet的block中,使模型能够学习到时间步的信息</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, dim_out, groups = <span class="number">8</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.proj = WeightStandardizedConv2d(dim, dim_out, <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        self.norm = nn.GroupNorm(groups, dim_out)</span><br><span class="line">        self.act = nn.SiLU()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, scale_shift = <span class="literal">None</span></span>):</span><br><span class="line">        x = self.proj(x)</span><br><span class="line">        x = self.norm(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> exists(scale_shift):</span><br><span class="line">            scale, shift = scale_shift</span><br><span class="line">            x = x * (scale + <span class="number">1</span>) + shift  <span class="comment"># 将时间向量一分为2,一份用于提升幅值,一份用于修改相位</span></span><br><span class="line"></span><br><span class="line">        x = self.act(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">      </span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResnetBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, dim_out, *, time_emb_dim = <span class="literal">None</span>, groups = <span class="number">8</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.mlp = nn.Sequential(</span><br><span class="line">            nn.SiLU(),</span><br><span class="line">            nn.Linear(time_emb_dim, dim_out * <span class="number">2</span>)</span><br><span class="line">        ) <span class="keyword">if</span> exists(time_emb_dim) <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        self.block1 = Block(dim, dim_out, groups = groups)</span><br><span class="line">        self.block2 = Block(dim_out, dim_out, groups = groups)</span><br><span class="line">        self.res_conv = nn.Conv2d(dim, dim_out, <span class="number">1</span>) <span class="keyword">if</span> dim != dim_out <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, time_emb = <span class="literal">None</span></span>):</span><br><span class="line"></span><br><span class="line">        scale_shift = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> exists(self.mlp) <span class="keyword">and</span> exists(time_emb):</span><br><span class="line">            time_emb = self.mlp(time_emb)</span><br><span class="line">            time_emb = rearrange(time_emb, <span class="string">&#x27;b c -&gt; b c 1 1&#x27;</span>)</span><br><span class="line">            scale_shift = time_emb.chunk(<span class="number">2</span>, dim = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        h = self.block1(x, scale_shift = scale_shift)</span><br><span class="line"></span><br><span class="line">        h = self.block2(h)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> h + self.res_conv(x)</span><br></pre></td></tr></table></figure>
<p><strong>第六步</strong>:计算损失,反向传播.计算预测的噪声与实际的噪声的损失,损失函数可以是L1或mse</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@property</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_fn</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">if</span> self.loss_type == <span class="string">&#x27;l1&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> F.l1_loss</span><br><span class="line">    <span class="keyword">elif</span> self.loss_type == <span class="string">&#x27;l2&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> F.mse_loss</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">f&#x27;invalid loss type <span class="subst">&#123;self.loss_type&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>通过不断迭代上述6步即可完成模型的训练</p>
<h3 id="3-2采样过程"><a href="#3-2采样过程" class="headerlink" title="3.2采样过程"></a>3.2采样过程</h3><p>第一步:随机从高斯分布采样一张噪声图片,并给定采样时间步</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = torch.randn(shape, device=device)</span><br></pre></td></tr></table></figure>
<p>第二步: 根据预测的当前时间步的噪声,通过公式计算当前时间步的均值和方差</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">posterior_mean_coef1 = betas * torch.sqrt(alphas_cumprod_prev) / (<span class="number">1.</span> - alphas_cumprod) <span class="comment"># 式(24)x_0的系数</span></span><br><span class="line">posterior_mean_coef = (<span class="number">1.</span> - alphas_cumprod_prev) * torch.sqrt(alphas) / (<span class="number">1.</span> - alphas_cumprod)  <span class="comment"># 式(24) x_t的系数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract</span>(<span class="params">a, t, x_shape</span>):</span><br><span class="line">  b, *_ = t.shape</span><br><span class="line">  out = a.gather(-<span class="number">1</span>, t)</span><br><span class="line">  <span class="keyword">return</span> out.reshape(b, *((<span class="number">1</span>,) * (<span class="built_in">len</span>(x_shape) - <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">q_posterior</span>(<span class="params">self, x_start, x_t, t</span>):</span><br><span class="line">  posterior_mean = (</span><br><span class="line">      extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +</span><br><span class="line">      extract(self.posterior_mean_coef2, t, x_t.shape) * x_t</span><br><span class="line">  )  <span class="comment"># 求出此时的均值</span></span><br><span class="line">  posterior_variance = extract(self.posterior_variance, t, x_t.shape)  <span class="comment"># 求出此时的方差</span></span><br><span class="line">  posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape) <span class="comment"># 对方差取对数,可能为了数值稳定性</span></span><br><span class="line">  <span class="keyword">return</span> posterior_mean, posterior_variance, posterior_log_variance_clipped  </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">p_mean_variance</span>(<span class="params">self, x, t, x_self_cond = <span class="literal">None</span>, clip_denoised = <span class="literal">True</span></span>):</span><br><span class="line">    preds = self.model_predictions(x, t, x_self_cond)  <span class="comment"># 预测噪声</span></span><br><span class="line">    x_start = preds.pred_x_start  <span class="comment"># 模型预测的是在x_t时间步噪声,x_start是根据公式(12)求</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> clip_denoised:</span><br><span class="line">        x_start.clamp_(-<span class="number">1.</span>, <span class="number">1.</span>)</span><br><span class="line"></span><br><span class="line">    model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start = x_start, x_t = x, t = t)</span><br><span class="line">    <span class="keyword">return</span> model_mean, posterior_variance, posterior_log_variance, x_start</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>第三步: 根据公式(33)计算得到前一个时刻图片$x_{t-1}$ </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">p_sample</span>(<span class="params">self, x, t: <span class="built_in">int</span>, x_self_cond = <span class="literal">None</span>, clip_denoised = <span class="literal">True</span></span>):</span><br><span class="line">    b, *_, device = *x.shape, x.device</span><br><span class="line">    batched_times = torch.full((x.shape[<span class="number">0</span>],), t, device = x.device, dtype = torch.long)</span><br><span class="line">    model_mean, _, model_log_variance, x_start = self.p_mean_variance(x = x, t = batched_times, x_self_cond = x_self_cond, clip_denoised = clip_denoised)  <span class="comment"># 计算当前分布的均值和方差</span></span><br><span class="line">    noise = torch.randn_like(x) <span class="keyword">if</span> t &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0.</span> <span class="comment"># 从高斯分布采样噪声</span></span><br><span class="line">    pred_img = model_mean + (<span class="number">0.5</span> * model_log_variance).exp() * noise  <span class="comment"># 根据</span></span><br><span class="line">    <span class="keyword">return</span> pred_img, x_start</span><br></pre></td></tr></table></figure>
<p>通过迭代以上三步,直至$T=0$完成采样.</p>
<h2 id="思考和讨论"><a href="#思考和讨论" class="headerlink" title="思考和讨论"></a>思考和讨论</h2><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><blockquote id="fn_1">
<sup>1</sup>. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2208.11970.pdf">Understanding Diffusion Models: A Unified Perspective</a><a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_2">
<sup>2</sup>. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.11239">Denoising Diffusion Probabilistic Models</a><a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.myhz0606.com/2023/01/28/image_hash_exp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blogs/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blogs/2023/01/28/image_hash_exp/" class="post-title-link" itemprop="url">Image Hash Roadmap</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-01-28 16:05:00" itemprop="dateCreated datePublished" datetime="2023-01-28T16:05:00+08:00">2023-01-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-03-14 16:35:33" itemprop="dateModified" datetime="2023-03-14T16:35:33+08:00">2023-03-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blogs/categories/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/" itemprop="url" rel="index"><span itemprop="name">图像检索</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>23 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="1-问题引出"><a href="#1-问题引出" class="headerlink" title="1 问题引出"></a>1 问题引出</h2><h3 id="1-1-从最近邻搜索谈起-nearest-neighbor-search-NN"><a href="#1-1-从最近邻搜索谈起-nearest-neighbor-search-NN" class="headerlink" title="1.1 从最近邻搜索谈起(nearest neighbor search, NN)"></a>1.1 从最近邻搜索谈起(nearest neighbor search, NN)</h3><p>最近邻检索：给定一张查询图片q(即query)（或文本），从数据库$\mathcal{X}$中找到与之最相近的N张图片（或文本）。在实际的检索场景中，我们会用一条向量来作为图片(或文本)的表征。</p>
<p>用公式表达最近邻检索：</p>
<script type="math/tex; mode=display">
\mathrm{NN}(q)=\mathrm{arg}\mathop{min}\limits_{x\in \mathcal{X} } \ \mathrm{dist}(q, x)</script><p>dist 是某一种距离计算公式（如欧式距离、余弦距离）</p>
<p>直觉来看，最近邻问题很简单，<strong>只要计算query和库中所有向量的距离，再按照距离的大小排序返回最相近样本的索引即可。</strong>但是当数据规模过大时这就成为了一个问题。假设查询图片的向量维度为256（即$d\in \mathbb{R}^{256}$）,数据了类型为float64，一条向量的数据大小为 256 * 64 / 8 = 2KB。此时采用这种暴力搜索的方法进行检索，代价会非常大。</p>
<p>（实验CPU：Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>数据库规模</th>
<th>距离计算耗时</th>
<th>向量数据库大小</th>
</tr>
</thead>
<tbody>
<tr>
<td>一百万</td>
<td>$\sim$ 24.13s秒</td>
<td>$\sim$ 2GB</td>
</tr>
<tr>
<td>一千万</td>
<td>$\sim$ 4分钟</td>
<td>$\sim$ 20GB</td>
</tr>
<tr>
<td>一亿</td>
<td>$\sim$ 40分钟</td>
<td>$\sim$ 200GB</td>
</tr>
</tbody>
</table>
</div>
<p>可见当数据量较大时，无论是从向量存储还是从搜索时延都无法满足实际应用需求。在工程中，当向量维度较低时，我们常用Kd-tree来加速搜索。当数据规模过大是（亿级），我们往往用到近似最近邻搜索技术(approximate nearest neighbor search，ANN)，ANN技术的核心技术之一就是向量量化技术(vector quantization, VQ<sup><a href="#fn_41" id="reffn_41">41</a></sup>)，常用的方法有乘积量化（product quantization，PQ<sup><a href="#fn_42" id="reffn_42">42</a></sup>）,哈希等。</p>
<h3 id="1-2-图片向量哈希是啥，有啥难点"><a href="#1-2-图片向量哈希是啥，有啥难点" class="headerlink" title="1.2 图片向量哈希是啥，有啥难点"></a>1.2 图片向量哈希是啥，有啥难点</h3><h4 id="1-2-1-图片向量哈希是啥"><a href="#1-2-1-图片向量哈希是啥" class="headerlink" title="1.2.1 图片向量哈希是啥"></a>1.2.1 图片向量哈希是啥</h4><p>向量哈希是ANN技术中向量量化技术的一种常用方法。其目标是学习一个哈希量化函数将一个浮点型或整型的向量量化为一个哈希向量（仅含有两个值，0/1或-1/1）且尽可能的保证搜索结果能够维持（即 similarity preserving）。此时公式（1）可转化为：</p>
<script type="math/tex; mode=display">
\mathrm{HashNN}(q)=\mathrm{arg}\mathop{min}\limits_{x\in \mathcal{X} } \ \mathrm{HammingDist}(q, x)</script><script type="math/tex; mode=display">
\mathrm{HammingDist}(x_1, x_2)=\mathrm{sum}( x1 \oplus x2)</script><p>通过上面可以看出图片哈希检索与经典的NN检索有两个主要的不同点：</p>
<ol>
<li>图片向量数据类型不同。哈希向量数域集合只有两个值{-1, 1}，浮点向量的数域集合接近无穷。这个特性能够大大降低向量检索任务的内存消耗。以上文256位的向量为例，数据类型为float64时一条向量占用2KB。但为哈希向量时一条数据类型仅为 256 * 1 / 8 = 32B,降低64倍的存储空间。可见哈希能够大幅度降低磁盘、内存的消耗。</li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th>数据库规模</th>
<th>float64向量数据库大小</th>
<th>哈希向量数据库大小</th>
</tr>
</thead>
<tbody>
<tr>
<td>一百万</td>
<td>$\sim$ 2GB</td>
<td>$\sim$ 31 MB</td>
</tr>
<tr>
<td>一千万</td>
<td>$\sim$ 20GB</td>
<td>$\sim$ 310 MB</td>
</tr>
<tr>
<td>一亿</td>
<td>$\sim$ 200GB</td>
<td>$\sim$ 3GB</td>
</tr>
</tbody>
</table>
</div>
<ol>
<li>距离计算公式不同。哈希检索用hamming距离作为其距离计算指标。即对两个向量按位求异或后相加。<strong>相对浮点数欧式距离、余弦距离的计算更快。</strong></li>
</ol>
<h4 id="1-2-2-图片向量哈希的主要难点（要解决什么问题）"><a href="#1-2-2-图片向量哈希的主要难点（要解决什么问题）" class="headerlink" title="1.2.2 图片向量哈希的主要难点（要解决什么问题）"></a>1.2.2 图片向量哈希的主要难点（要解决什么问题）</h4><p>难点1: <strong>如何解决相似度维持问题（similarity preserving</strong>）。即如何保证哈希后的检索结果和原向量的检索结果尽可能的一致。</p>
<script type="math/tex; mode=display">
\mathrm{NN}(q) \simeq \mathrm{HashNN}(q)</script><p>难点2: 向量哈希需要将向量从浮点数（或整数）映射到只包含两个值的数域空间（0/1或-1/1），这往往会用到符号函数。<strong>但符号函数不可导，如何用梯度下降进行优化？</strong>（针对用深度学习的哈希方法）。</p>
<h2 id="2-图片向量哈希方法"><a href="#2-图片向量哈希方法" class="headerlink" title="2 图片向量哈希方法"></a>2 图片向量哈希方法</h2><h3 id="2-1-相似度维持的解决方案"><a href="#2-1-相似度维持的解决方案" class="headerlink" title="2.1 相似度维持的解决方案"></a>2.1 相似度维持的解决方案</h3><p>在深度哈希任务中，主要通过<strong>设计特定的损失函数来解决相似度维持问题</strong>。</p>
<h4 id="2-1-1-基于成对标签"><a href="#2-1-1-基于成对标签" class="headerlink" title="2.1.1  基于成对标签"></a>2.1.1  基于成对标签</h4><p>比较有代表性的是DSH<sup><a href="#fn_2" id="reffn_2">2</a></sup>,DSDH<sup><a href="#fn_7" id="reffn_7">7</a></sup>,DPSH<sup><a href="#fn_3" id="reffn_3">3</a></sup>等。假定网络输入的图片$x_1, x_2$,经过网络输出的浮点向量为$f_1, f_2$， 经过哈希层后得到的哈希向量分别为$b_1, b_2, b_i \in \{-1, 1\}^c$，c是哈希向量的维度。成对标签规则如下：</p>
<ul>
<li>若$x_1, x_2$归属同一个类别（或认为相似），则认为其成对标签$s_{12}=1$</li>
<li>若$x_1, x_2$归属同不同类别否则为$s_{12}=0$。</li>
</ul>
<p>对于任意两个数据点$i,j$其似然概率定义如下</p>
<script type="math/tex; mode=display">
p(s_{ij} | \mathcal{B}) =
\left \{
\begin{aligned}
& \sigma(\Omega_{ij})   \, & s_{ij} = 1 \\
& 1 - \sigma(\Omega_{ij}) \, & s_{ij} = 0
\end{aligned}
\right.</script><p>其中 $\Omega_{ij}=\frac{1}{2}b_i^Tb_j$，$\sigma(\Omega_{ij})=\frac{1}{1+e^{-\Omega_{ij} } }$</p>
<p>其目标函数为</p>
<script type="math/tex; mode=display">
\mathop{min}\limits_{\mathcal{B} }=- \mathop{log} p(\mathcal{S}|\mathcal{B})=-\sum \limits_{s_{ij} \in \mathcal{S} } \mathop{log} p(s_{ij}| \mathcal{B})=-\sum \limits_{s_{ij} \in \mathcal{S} } (s_{ij} \Omega_{ij} - log(1 + e^{\Omega_{ij} }))</script><p><strong>此类方法的扩展有</strong>：引入margin来优化类内方差与类间方差<sup><a href="#fn_10" id="reffn_10">10</a></sup>、扩展到三元组<sup><a href="#fn_4" id="reffn_4">4</a></sup>、基于类别分布进行加权<sup><a href="#fn_6" id="reffn_6">6</a></sup>、亦或是扩展到多标签<sup><a href="#fn_11" id="reffn_11">11</a></sup></p>
<h4 id="2-1-2-基于语义标签"><a href="#2-1-2-基于语义标签" class="headerlink" title="2.1.2 基于语义标签"></a>2.1.2 基于语义标签</h4><p>这类方法很多时候和成对标签损失一起用<sup><a href="#fn_7" id="reffn_7">7</a></sup>。主要思想是：当我们有图片的标签时，只考虑pairwise信息没有充分利用到标签信息，故增加一个分类的损失来协助训练。</p>
<script type="math/tex; mode=display">
  \sum_{i=1}^{N}L(y_i, W^Tb_i)</script><p>主流的分类损失有3种：1）交叉熵损失；2）浮点向量投影得到的概率向量与哈希向量投影得到的二值向量的KL散度；3）L2损失。</p>
<h4 id="2-1-3-基于相似度一致"><a href="#2-1-3-基于相似度一致" class="headerlink" title="2.1.3 基于相似度一致"></a>2.1.3 基于相似度一致</h4><p>假定$f$输入图片的浮点特征向量，$b$是输入图片的哈希向量。对于一个batch的浮点向量为$[f_1, f_2, ..,, f_N]$，哈希向量为$[b_1, b_2, …, b_N]$浮点向量构成的相似度矩阵$S_f=[[f_1f_1^T, f_1f_2^T, …, f_1f_N^T]; …; [f_Nf_1^T, f_Nf_2^T, …, f_Nf_N^T]]$。哈希向量构成的相似度矩阵$S_b=[[b_1b_1^T, b_1b_2^T, …, b_1b_N^T]; …; [b_Nb_1^T, b_Nb_2^T, …, b_Nb_N^T]]$</p>
<p>在实际的应用中有直接用MSE来使相似度矩阵最小化；也有利用对比学习思想构造相似度矩阵用交叉语义一致性来优化<sup><a href="#fn_19" id="reffn_19">19</a></sup>。也有直接利用Batch本身标签的相似度矩阵$S$来和哈希形成相似度矩阵$S_b$进行优化<sup><a href="#fn_24" id="reffn_24">24</a></sup>。</p>
<h4 id="2-1-4-基于重建"><a href="#2-1-4-基于重建" class="headerlink" title="2.1.4 基于重建"></a>2.1.4 基于重建</h4><p>此类方法一般基于VAE架构。其核心思想是：将浮点向量进行哈希量化后，再用哈希向量进行重建，优化目标是重建后与重建前的feature map尽可能的接近。</p>
<p>比较有代表性的工作是TBH<sup><a href="#fn_17" id="reffn_17">17</a></sup>，相较基础的VAE架构同时引入了图卷积来进一步同步哈希向量和浮点向量的特征。</p>
<h4 id="2-1-5-其它相似度维持损失函数"><a href="#2-1-5-其它相似度维持损失函数" class="headerlink" title="2.1.5 其它相似度维持损失函数"></a>2.1.5 其它相似度维持损失函数</h4><p>如优化检索排序的 SortedNCE<sup><a href="#fn_29" id="reffn_29">29</a></sup>，优化哈希码聚类分布的 CSQ<sup><a href="#fn_15" id="reffn_15">15</a></sup>，基于优化对比量化损失的MeCoQ<sup><a href="#fn_31" id="reffn_31">31</a></sup>等。</p>
<h4 id="2-1-6-优化哈希码一些约束"><a href="#2-1-6-优化哈希码一些约束" class="headerlink" title="2.1.6 优化哈希码一些约束"></a>2.1.6 优化哈希码一些约束</h4><p>为了避免过拟合往往会增加一个量化损失，使得生成的哈希向量与原向量量化误差别太大。一版采用L2损失或SmoothL1。</p>
<script type="math/tex; mode=display">
L_{quan} = \sum_i ^ N{ \parallel b_i - f_i \parallel ^2 }</script><p>为了使得生成的哈希向量差异性更大往往会增加一个平衡损失使得生成的哈希向量1/-1的个数差不多。</p>
<script type="math/tex; mode=display">
L_{balance}=\frac{1}{N} \parallel BB^T - I \parallel ^2</script><h3 id="2-2-符号函数不可导的解决方案"><a href="#2-2-符号函数不可导的解决方案" class="headerlink" title="2.2 符号函数不可导的解决方案"></a>2.2 符号函数不可导的解决方案</h3><h4 id="2-2-1-改写梯度更新规则"><a href="#2-2-1-改写梯度更新规则" class="headerlink" title="2.2.1 改写梯度更新规则"></a>2.2.1 改写梯度更新规则</h4><p>Pytorch提供了自定义梯度更新的接口。有代表性的GreedyHash<sup><a href="#fn_9" id="reffn_9">9</a></sup>所用的方法前向过程调用符号函数，反向过程不计算符号函数的梯度。实现的关键是Pytorch中的<code>torch.autograd.Function</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GreedyHashLayer</span>(torch.autograd.Function):</span><br><span class="line"> </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, <span class="built_in">input</span></span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">input</span>.sign()</span><br><span class="line"> </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_output</span>):</span><br><span class="line">        <span class="keyword">return</span> grad_output</span><br></pre></td></tr></table></figure>
<h4 id="2-2-2-基于“松弛”（relaxation）思想训练中替代符号函数为其它可导函数"><a href="#2-2-2-基于“松弛”（relaxation）思想训练中替代符号函数为其它可导函数" class="headerlink" title="2.2.2 基于“松弛”（relaxation）思想训练中替代符号函数为其它可导函数"></a>2.2.2 基于“松弛”（relaxation）思想训练中替代符号函数为其它可导函数</h4><p>此类方法是image hash最为常用的方法。核心思想是：在训练过程将二值化函数用一个可微的函数替代，在推理过程中再用符号函数进行二值化。</p>
<p><img src="https://myhz0606blog.oss-cn-beijing.aliyuncs.com/image_hash_exp/HashNet_1.jpeg"></p>
<h2 id="3-构建专利图片哈希检索系统"><a href="#3-构建专利图片哈希检索系统" class="headerlink" title="3 构建专利图片哈希检索系统"></a>3 构建专利图片哈希检索系统</h2><h3 id="3-1-问题分析及技术选型"><a href="#3-1-问题分析及技术选型" class="headerlink" title="3.1 问题分析及技术选型"></a>3.1 问题分析及技术选型</h3><p>目前线上已刷1亿+外观向量，1亿+实用新型向量，4亿+发明专利向量。<strong>现阶段我们所用image2vector的pipeline为</strong><br>图像 -&gt; 去白边 -&gt; （提轮廓, shape-only）-&gt; resize -&gt; 特征提取 -&gt; PCA降维。若采用全量训练的方式更新image2vector模型需要全量重刷已有的向量，代价很大。并且目前自训的模型还达不到Facebook在数十亿规模数据训练的基础模型。</p>
<p>本实验采用的image2hash架构为：固定特征提取模块，在已有pipeline上增加一个哈希层达到image2hash的效果。通过对论文的调研，可以尝试的方向有两大类，一类基于模型，一类基于统计。</p>
<p><img src="https://myhz0606blog.oss-cn-beijing.aliyuncs.com/image_hash_exp/arch.png" alt="arch"></p>
<h4 id="3-1-1-采用模型训练向量哈希参数"><a href="#3-1-1-采用模型训练向量哈希参数" class="headerlink" title="3.1.1 采用模型训练向量哈希参数"></a>3.1.1 采用模型训练向量哈希参数</h4><p>与论文场景不同，此处需要将特征提取模块（backbone）的权重全部冻结，只训练哈希层的权重。主要有三类可行的方法：</p>
<p>1）可用公开数据结合标签语义损失+量化损失+平衡损失等进行训练。</p>
<p>2）用专利数据采用自监督的方法进行训练。</p>
<p>3）亦或者直接用最小化浮点向量和哈希向量的量化误差进行训练。</p>
<h5 id="3-1-1-1基于开源数据训练哈希参数"><a href="#3-1-1-1基于开源数据训练哈希参数" class="headerlink" title="3.1.1.1基于开源数据训练哈希参数"></a>3.1.1.1基于开源数据训练哈希参数</h5><p>为了快速验证模型效果，首先在imagenet100上进行验证。复现了几个主流的基于深度学习训练哈希层的方法，并在imagenet100上进行测试。（Dbhash是参考Dbnet思想构建的方法）。从结果上，当模型收敛，几类方法的mAP差距不大，但Dbhash的收敛速度特别快，<strong>故采用Dbhash架构来训练哈希层</strong>。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>epoch</th>
<th>Dbhash</th>
<th>GreedyHash<sup><a href="#fn_9" id="reffn_9">9</a></sup></th>
<th>CSQ<sup><a href="#fn_15" id="reffn_15">15</a></sup></th>
<th>DHN<sup><a href="#fn_5" id="reffn_5">5</a></sup></th>
<th>DPSH<sup><a href="#fn_3" id="reffn_3">3</a></sup></th>
</tr>
</thead>
<tbody>
<tr>
<td>10</td>
<td>88.61%</td>
<td>86.82%</td>
<td>68.88%</td>
<td>65.85%</td>
<td>66.18%</td>
</tr>
<tr>
<td>20</td>
<td>90.27%</td>
<td>89.46%</td>
<td>78.02%</td>
<td>74.81%</td>
<td>75.88%</td>
</tr>
<tr>
<td>30</td>
<td>90.34%</td>
<td>90.00%</td>
<td>82.14%</td>
<td>81.87%</td>
<td>82.50%</td>
</tr>
<tr>
<td>40</td>
<td>90.48%</td>
<td>90.21%</td>
<td>84.64%</td>
<td>85.72%</td>
<td>86.03%</td>
</tr>
<tr>
<td>50</td>
<td>90.55%</td>
<td>90.27%</td>
<td>85.94%</td>
<td>88.11%</td>
<td>88.09%</td>
</tr>
<tr>
<td>60</td>
<td>90.53%</td>
<td>90.56%</td>
<td>86.86%</td>
<td>89.58%</td>
<td>89.28%</td>
</tr>
<tr>
<td>70</td>
<td>90.60%</td>
<td>90.60%</td>
<td>87.57%</td>
<td>90.75%</td>
<td>89.89%</td>
</tr>
<tr>
<td>80</td>
<td>90.59%</td>
<td>90.59%</td>
<td>88.20%</td>
<td>91.56%</td>
<td>90.37%</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p><strong>DBhash 模型架构</strong></p>
<p>整体架构如下图所示，需要训练的哈希层为Thresh layer。</p>
<p><img src="https://myhz0606blog.oss-cn-beijing.aliyuncs.com/image_hash_exp/DBhash_1.png"></p>
<p><strong>训练目标函数有3个</strong>：语义标签分类损失、KL散度及量化损失。（效果见3.3.1）</p>
<p><strong>训练数据</strong>：imagenet1K</p>
<p><strong>PS：</strong>在实际尝试的过程中发现一个坑。BN层的统计数据(running_mean, running_var)更新是在每一次训练阶段model.train()后的forward()方法中自动实现的，<strong>而不是</strong>在梯度计算与反向传播中更新optim.step()中完成。采用require_grad=False这个方法无法正常冻结。正确的冻结BN的方式是在模型训练时，把BN单独挑出来，重新设置其状态为eval (在model.train()之后覆盖training状态）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">set_bn_eval</span>(<span class="params">m</span>):</span><br><span class="line">    classname = m.__class__.__name__</span><br><span class="line">    <span class="keyword">if</span> classname.find(<span class="string">&#x27;BatchNorm&#x27;</span>) != -<span class="number">1</span>:</span><br><span class="line">      m.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">model.apply(set_bn_eval)</span><br></pre></td></tr></table></figure>
<h5 id="3-1-1-2直接基于最小化量化误差来训练哈希层"><a href="#3-1-1-2直接基于最小化量化误差来训练哈希层" class="headerlink" title="3.1.1.2直接基于最小化量化误差来训练哈希层"></a>3.1.1.2直接基于最小化量化误差来训练哈希层</h5><p>本次POC主要尝试了iteration quantization（ITQ<sup><a href="#fn_43" id="reffn_43">43</a></sup>）。这个方法的核心思路是将经过PCA的向量数据集中的数据点映射到一个二进制超立方体的顶点上，使得对应的量化误差最小，从而而已得到对应该数据集优良的二进制编码。其核心思路是：找到最优的旋转投影矩阵来使得量化误差最小。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ITQ</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;training hash code by ITQ method&quot;&quot;&quot;</span></span><br><span class="line">    DEFAULT_DEVICE = torch.device(<span class="string">&quot;cuda&quot;</span>) <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, device=DEFAULT_DEVICE</span>):</span><br><span class="line">        self.device = device</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span> </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_pipeline</span>(<span class="params"></span></span><br><span class="line"><span class="params">            self, </span></span><br><span class="line"><span class="params">            vec_rtpath, </span></span><br><span class="line"><span class="params">            file_type, </span></span><br><span class="line"><span class="params">            pca_file=<span class="literal">None</span>, </span></span><br><span class="line"><span class="params">            checkpoints=<span class="literal">None</span>, </span></span><br><span class="line"><span class="params">            iterations=<span class="number">1000</span>, </span></span><br><span class="line"><span class="params">            thred=<span class="literal">None</span>, </span></span><br><span class="line"><span class="params">            debug=<span class="literal">False</span></span></span><br><span class="line"><span class="params">            </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        trainset = self.prepare_patent_data(</span><br><span class="line">            vec_rtpath, file_type, pca_file=pca_file, debug=debug</span><br><span class="line">        )</span><br><span class="line">        self.train(</span><br><span class="line">            trainset, checkpoints=checkpoints, iterations=iterations, thred=thred</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">prepare_patent_data</span>(<span class="params">self, vec_rtpath, file_type, pca_file=<span class="literal">None</span>, debug=<span class="literal">False</span></span>):</span><br><span class="line">        vector_ls, image_ls = VectorFileDecoder(file_type=file_type)(</span><br><span class="line">            vec_rtpath, sample_number=<span class="number">30</span> <span class="keyword">if</span> debug <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> pca_file <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            pca_func = <span class="keyword">lambda</span> x: x </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pca_func = PCA(pca_file)</span><br><span class="line">        vector_ls = [pca_func(np.array(i).reshape(<span class="number">1</span>, -<span class="number">1</span>)).reshape(-<span class="number">1</span>).tolist() <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(vector_ls)]</span><br><span class="line">        vector_arr = np.array(vector_ls)  <span class="comment"># N * M</span></span><br><span class="line">        <span class="keyword">return</span> vector_arr</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, trainset: np.ndarray, checkpoints=<span class="literal">None</span>, iterations=<span class="number">1000</span>, thred=<span class="literal">None</span></span>):</span><br><span class="line">        trainset_tensor = torch.from_numpy(trainset.astype(np.float32)).to(self.device)</span><br><span class="line">        V = trainset_tensor</span><br><span class="line">        nbits = trainset_tensor.shape[<span class="number">1</span>]</span><br><span class="line">        R = torch.randn(nbits, nbits).to(self.device) </span><br><span class="line">        torch.nn.init.orthogonal_(R)</span><br><span class="line">        origin_quan_loss = self.frobenius_norm(V.sign(), V)</span><br><span class="line">        <span class="keyword">if</span> thred <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            binary_vec = FaissSearchAPI.img2hash_by_thred(</span><br><span class="line">                trainset, thred, to_int8_compress=<span class="literal">False</span></span><br><span class="line">            ).astype(np.float32)</span><br><span class="line">            logger.info(<span class="string">f&quot;generate binary vector by OT method: binary vec shape: <span class="subst">&#123;binary_vec.shape&#125;</span>&quot;</span>)</span><br><span class="line">            origin_quan_loss_2 = self.frobenius_norm(torch.from_numpy(binary_vec).to(self.device), V)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            origin_quan_loss_2 = <span class="number">0.0000</span></span><br><span class="line"></span><br><span class="line">        best_quant_loss = <span class="number">1e10</span></span><br><span class="line">        best_R = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">            <span class="comment"># step 1: update B</span></span><br><span class="line">            V_tilde = V @ R </span><br><span class="line">            B = V_tilde.sign()</span><br><span class="line">            <span class="comment"># step2: update R </span></span><br><span class="line">            [S, _, S_tilde_transpose] = torch.svd(B.t() @ V)</span><br><span class="line">            R = (S_tilde_transpose.t() @ S.t())</span><br><span class="line"></span><br><span class="line">            quant_loss = self.frobenius_norm(B, V_tilde)</span><br><span class="line">            <span class="keyword">if</span> quant_loss &lt; best_quant_loss:</span><br><span class="line">                best_quant_loss = quant_loss</span><br><span class="line">                best_R = R </span><br><span class="line">            logger.info(<span class="string">f&quot;Iter: <span class="subst">&#123;i:04d&#125;</span> frobenius_norm: <span class="subst">&#123;quant_loss:<span class="number">.4</span>f&#125;</span>, BEST: <span class="subst">&#123;best_quant_loss:<span class="number">.4</span>f&#125;</span>, ORIGIN: <span class="subst">&#123;origin_quan_loss:<span class="number">.4</span>f&#125;</span>, ORI2: <span class="subst">&#123;origin_quan_loss_2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> checkpoints:</span><br><span class="line">            np.savez(checkpoints, R=best_R.cpu().numpy()) </span><br><span class="line">             </span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">frobenius_norm</span>(<span class="params">B, V_tilde</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;$E = || B - V_tilde ||_&#123;F&#125;^&#123;2&#125;$&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> (B - V_tilde).<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>().sqrt().item() / B.shape[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h4 id="3-1-2-基于统计特征获得向量哈希参数"><a href="#3-1-2-基于统计特征获得向量哈希参数" class="headerlink" title="3.1.2 基于统计特征获得向量哈希参数"></a>3.1.2 基于统计特征获得向量哈希参数</h4><p>该方法的本质是挖掘浮点向量的数值分布统计特征，以最小化量化损失、平衡损失为目标来构建哈希层。基于最优传输理论（Op timal Transport, OT）的Bi-HalfNet<sup><a href="#fn_16" id="reffn_16">16</a></sup>。论文为什么写了很多，感兴趣可以看原文，这里主要讲怎么做。目前我们有1800w的专利图片向量，其构成的矩阵记为$\mathrm{M}=\{m_i |i=1,2,…,18000000  \}, m_i \in \mathbb{R}^{256}$,对于向量检索任务，向量$m_i$可以看作是对应图片$x_i$的表征。已知$m_i$是256维，基于OT理论的哈希方法是将$m_i$的每一维都当作一个特征。已知$m_i=[m_{i,1}, m_{i,2},…,m_{i,256}]$。将所有样本第一维的特征汇聚一起可得：$f_1=\{m_{i1}|i=1,2, …, 18000000 \}$，如何得到一个划分，将$f_i$转为二值化，且量化误差最小是我们的目标函数，即</p>
<script type="math/tex; mode=display">
\mathop{min} \sum \limits_{j} \parallel  f_i^{j} - b_i^{j} \parallel ^ 2</script><p>$f_i^{j}$表示在$f_i$的第$j$个样本；$b_i^{j}$表示$f_i^{j}$的哈希表示。</p>
<p>显然$\mathop{mean} (f_i)$是我们所需的解。但仅仅考虑量化误差没有兼顾哈希特征的丰富性，在实践中往往会加入一个平衡误差来使得一条哈希向量两个值的数量尽可能的接近。$f_i$的中位数是我们所需的解。</p>
<p>综上所述，我们只需分别找到每一维的中位数作为该位置的划分，即可获得最小量化误差、最优平衡的哈希表征。 </p>
<h3 id="3-2检索系统搭建"><a href="#3-2检索系统搭建" class="headerlink" title="3.2检索系统搭建"></a>3.2检索系统搭建</h3><p>Milvus 1.x并不支持哈希检索。本次POC采用Faiss平台搭建基于哈希的检索系统。（吐槽一下，faiss关于搭建哈希搜索的文档真的非常简略）里面有个大坑是插入哈希code导Faiss引擎是需要将哈希吗转为int8后在输入，随后需要将向量的维度变为 $\mathrm{dim} /8$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">bytes2int8</span>(<span class="params">byte_vec</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    convert 0,1 matrix to uint8</span></span><br><span class="line"><span class="string">    shape: (N, M) -&gt; (N, M // 8)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> byte_vec.ndim == <span class="number">2</span></span><br><span class="line">    mutiple = np.array([<span class="number">2</span>**i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7</span>, -<span class="number">1</span>, -<span class="number">1</span>)]).reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">    hash_code = byte_vec</span><br><span class="line">    hash_code_uint8 = np.concatenate(</span><br><span class="line">        [np.<span class="built_in">sum</span>(hash_code[:, i * <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">8</span>] * mutiple, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(hash_code.shape[<span class="number">1</span>] // <span class="number">8</span>)],</span><br><span class="line">        axis=<span class="number">1</span></span><br><span class="line">    ).astype(np.uint8)</span><br><span class="line">    <span class="keyword">return</span> hash_code_uint8</span><br></pre></td></tr></table></figure>
<h4 id="3-2-1索引构建"><a href="#3-2-1索引构建" class="headerlink" title="3.2.1索引构建"></a>3.2.1索引构建</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FaissSearchEngin</span>:</span><br><span class="line">    SUPPORT_INDEX_TYPE = <span class="built_in">set</span>(</span><br><span class="line">        [</span><br><span class="line">            <span class="string">&quot;binary_flat_ivf&quot;</span>,</span><br><span class="line">            <span class="string">&quot;binary_flat&quot;</span>,</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        index_type,</span></span><br><span class="line"><span class="params">        index_params=<span class="built_in">dict</span>(<span class="params"></span>),</span></span><br><span class="line"><span class="params">        index_rtpath=DEFAULT_INDEX_RTPATH,</span></span><br><span class="line"><span class="params">        vector=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        img_name_ls=<span class="literal">None</span>, </span></span><br><span class="line"><span class="params">        reuse=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">        logger=logger,</span></span><br><span class="line"><span class="params">        prefix = <span class="string">&#x27;&#x27;</span>, </span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            index_type(str): faiss index type</span></span><br><span class="line"><span class="string">            index_params(dict): faiss index create parameters</span></span><br><span class="line"><span class="string">            index_rtpath(str): faiss index rtpath</span></span><br><span class="line"><span class="string">            vector(np.ndarray, None): faiss index database</span></span><br><span class="line"><span class="string">            reuse(bool): always create index, whatever</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.logger = logger</span><br><span class="line">        self.reuse = reuse</span><br><span class="line">        self.index_type =  index_type</span><br><span class="line">        <span class="keyword">assert</span> (</span><br><span class="line">            index_type <span class="keyword">in</span> self.SUPPORT_INDEX_TYPE</span><br><span class="line">        ), <span class="string">f&quot;index type only support <span class="subst">&#123;self.SUPPORT_INDEX_TYPE&#125;</span> now!&quot;</span></span><br><span class="line">        self.vector = vector</span><br><span class="line">        self.img_name_ls = img_name_ls</span><br><span class="line">        <span class="keyword">if</span> self.vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            dim = vector.shape[<span class="number">1</span>] * <span class="number">8</span> <span class="keyword">if</span> <span class="string">&quot;binary&quot;</span> <span class="keyword">in</span> self.index_type <span class="keyword">else</span> vector.shape[<span class="number">1</span>]</span><br><span class="line">            index_params.update(<span class="built_in">dict</span>(dim=dim))</span><br><span class="line">        self.logger.info(<span class="string">f&quot;index params: <span class="subst">&#123;index_params&#125;</span>&quot;</span>)</span><br><span class="line">        self.index_save_rtpath = os.path.join(index_rtpath, index_type)</span><br><span class="line">        self.index_path = os.path.join(</span><br><span class="line">            self.index_save_rtpath,</span><br><span class="line">            <span class="string">f&quot;<span class="subst">&#123;prefix&#125;</span>_<span class="subst">&#123;<span class="string">&#x27;_&#x27;</span>.join([<span class="string">f&#x27;<span class="subst">&#123;k&#125;</span>_<span class="subst">&#123;v&#125;</span>&#x27;</span> <span class="keyword">for</span> k, v <span class="keyword">in</span> index_params.items()])&#125;</span>.index&quot;</span>,</span><br><span class="line">        )</span><br><span class="line">        self.index_params = index_params</span><br><span class="line">        checkdir(self.index_save_rtpath)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        self.check_index()</span><br><span class="line">        self.init_index_func(self.index_type)</span><br><span class="line">        self.index = self.build_index(</span><br><span class="line">            self.vector, index_params=self.index_params, index_path=self.index_path, reuse=self.reuse</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">check_index</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.reuse <span class="keyword">and</span> self.vector <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">assert</span> os.path.exists(</span><br><span class="line">                self.index_path</span><br><span class="line">            ), <span class="string">f&quot;there are no index file, you should input [vector] parameters to create it&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">convert_byte_vector_2_uint8</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span> </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_index_func</span>(<span class="params">self, index_type</span>):</span><br><span class="line">        <span class="keyword">if</span> index_type == <span class="string">&quot;binary_flat_ivf&quot;</span>:</span><br><span class="line">            self._index_func = self._binary_flat_ivf</span><br><span class="line">            self.write_index_func = faiss.write_index_binary</span><br><span class="line">            self.read_index_func = faiss.read_index_binary</span><br><span class="line">        <span class="keyword">elif</span> index_type == <span class="string">&quot;binary_flat&quot;</span>:</span><br><span class="line">            self._index_func = self._binary_flat</span><br><span class="line">            self.write_index_func = faiss.write_index_binary</span><br><span class="line">            self.read_index_func = faiss.read_index_binary</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">search</span>(<span class="params">self, query, search_params</span>):</span><br><span class="line">        D, I = self.index.search(query, **search_params)</span><br><span class="line">        <span class="keyword">return</span> D, I</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build_index</span>(<span class="params">self, vector, index_path, index_params=<span class="built_in">dict</span>(<span class="params"></span>), reuse=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;create faiss index&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> os.path.exists(index_path) <span class="keyword">and</span> reuse:</span><br><span class="line">            self.logger.info(<span class="string">f&quot;read index from exists file: <span class="subst">&#123;index_path&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> self.read_index_func(index_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            index_info = self._index_func(index_params)</span><br><span class="line">            vector = vector.astype(index_info.vec_dtype)</span><br><span class="line">            self.logger.info(<span class="string">f&quot;vector shape: <span class="subst">&#123;vector.shape&#125;</span>, dtype: <span class="subst">&#123;vector.dtype&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> index_info.need_train:</span><br><span class="line">                self.logger.info(<span class="string">f&quot;start train index, please wait...&quot;</span>)</span><br><span class="line">                _t = time.perf_counter()</span><br><span class="line">                index_info.index_func.train(vector)</span><br><span class="line">                self.logger.info(</span><br><span class="line">                    <span class="string">f&quot;train index finish, time consume: <span class="subst">&#123;time.perf_counter() - _t&#125;</span>s&quot;</span></span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.logger.info(<span class="string">f&quot;current index type need not to train!&quot;</span>)</span><br><span class="line">            index_info.index_func.add(vector)</span><br><span class="line">            self.save_id_map(self.index_path.replace(<span class="string">&quot;.index&quot;</span>, <span class="string">&quot;_id_map.txt&quot;</span>))</span><br><span class="line">            self.logger.info(<span class="string">f&quot;save index file to <span class="subst">&#123;index_path&#125;</span>&quot;</span>)</span><br><span class="line">            self.write_index_func(index_info.index_func, index_path)</span><br><span class="line">            <span class="keyword">return</span> index_info.index_func</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_binary_flat</span>(<span class="params">self, params</span>):</span><br><span class="line">        index = faiss.IndexBinaryFlat(params.get(<span class="string">&quot;dim&quot;</span>))</span><br><span class="line">        <span class="keyword">return</span> index_info(index, <span class="literal">False</span>, np.uint8)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_binary_flat_ivf</span>(<span class="params">self, params</span>):</span><br><span class="line">        quantizer = faiss.IndexBinaryFlat(params.get(<span class="string">&quot;dim&quot;</span>))</span><br><span class="line">        index = faiss.IndexBinaryIVF(quantizer, params.get(<span class="string">&quot;dim&quot;</span>), params.get(<span class="string">&quot;nlist&quot;</span>))</span><br><span class="line">        <span class="keyword">return</span> index_info(index, <span class="literal">True</span>, np.uint8)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, index, training_vector</span>):</span><br><span class="line">        self.logger.info(<span class="string">f&quot;start train index&quot;</span>)</span><br><span class="line">        _t = time.perf_counter()</span><br><span class="line">        index.train(training_vector)</span><br><span class="line">        self.logger.info(<span class="string">f&quot;train index succeed! time consume: <span class="subst">&#123;time.perf_counter() - _t:<span class="number">.4</span>f&#125;</span>s&quot;</span>)</span><br><span class="line">        <span class="keyword">assert</span> index.is_trained, <span class="string">f&quot;index not train!&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_id_map</span>(<span class="params">self, save_path</span>):</span><br><span class="line">        checkdir(os.path.split(save_path)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(save_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">&#x27;\n&#x27;</span>.join(self.img_name_ls))</span><br></pre></td></tr></table></figure>
<h3 id="3-3-指标及web-demo搭建"><a href="#3-3-指标及web-demo搭建" class="headerlink" title="3.3 指标及web demo搭建"></a>3.3 指标及web demo搭建</h3><h4 id="3-3-1-指标评估"><a href="#3-3-1-指标评估" class="headerlink" title="3.3.1 指标评估"></a>3.3.1 指标评估</h4><p>分别在灰度测试集和轮廓测试集来测试哈希检索的效果。baseline为SQ8量化 （目前线上的量化方式）</p>
<p>候选数据集：140W 外观专利图片数据</p>
<p>测试集：外观专利灰度测试集、外观专利轮廓测试集</p>
<h5 id="3-3-1-1-精度评估"><a href="#3-3-1-1-精度评估" class="headerlink" title="3.3.1.1 精度评估"></a>3.3.1.1 精度评估</h5><ul>
<li>灰度测试集的效果对比</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>topk</th>
<th>baseline</th>
<th>哈希检索（Dbhash）</th>
<th>哈希检索（ITQ）</th>
<th>哈希检索(OT)</th>
</tr>
</thead>
<tbody>
<tr>
<td>10</td>
<td>31.43%</td>
<td>17.30%</td>
<td>22.91%</td>
<td>25.73%</td>
</tr>
<tr>
<td>100</td>
<td>57.86%</td>
<td>39.95%</td>
<td>48.11%</td>
<td>50.54%</td>
</tr>
<tr>
<td>500</td>
<td>71.82%</td>
<td>56.28%</td>
<td>64.53%</td>
<td>64.09%</td>
</tr>
<tr>
<td>1000</td>
<td>77.35%</td>
<td>64.00%</td>
<td>70.85%</td>
<td>69.18%</td>
</tr>
<tr>
<td>3000</td>
<td>83.32%</td>
<td>72.78%</td>
<td>78.75%</td>
<td>76.12%</td>
</tr>
<tr>
<td>5000</td>
<td>86.57%</td>
<td>75.94%</td>
<td>81.47%</td>
<td>78.67%</td>
</tr>
<tr>
<td>10000</td>
<td>89.73%</td>
<td>81.21%</td>
<td>85.34%</td>
<td>82.53%</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p><img src="https://myhz0606blog.oss-cn-beijing.aliyuncs.com/image_hash_exp/GrayTestsetSearchResult.png"></p>
<ul>
<li>轮廓测试集的效果对比</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>topk</th>
<th>baseline</th>
<th>哈希检索（Dbhash）</th>
<th>哈希检索（ITQ）</th>
<th>哈希检索(OT)</th>
</tr>
</thead>
<tbody>
<tr>
<td>10</td>
<td>4.97%</td>
<td>4.67%</td>
<td>4.19%</td>
<td>5.51%</td>
</tr>
<tr>
<td>100</td>
<td>12.21%</td>
<td>12.33%</td>
<td>9.16%</td>
<td>14.00%</td>
</tr>
<tr>
<td>500</td>
<td>21.48%</td>
<td>22.20%</td>
<td>15.74%</td>
<td>26.03%</td>
</tr>
<tr>
<td>1000</td>
<td>27.53%</td>
<td>28.61%</td>
<td>20.59%</td>
<td>33.21%</td>
</tr>
<tr>
<td>3000</td>
<td>37.64%</td>
<td>38.78%</td>
<td>29.44%</td>
<td>42.85%</td>
</tr>
<tr>
<td>5000</td>
<td>41.17%</td>
<td>43.57%</td>
<td>33.45%</td>
<td>46.92%</td>
</tr>
<tr>
<td>10000</td>
<td>46.62%</td>
<td>52.00%</td>
<td>38.90%</td>
<td>52.24%</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<p><img src="https://myhz0606blog.oss-cn-beijing.aliyuncs.com/image_hash_exp/GrayTestsetSearchResult-4894374.png" height="500" alt="graytest"></p>
<p>从实验结果看，采用OT方法进行哈希量化能达到最优的效果。并且该方法实现简单，能够复用已刷的向量。</p>
<h5 id="3-3-3-2-向量存储评估"><a href="#3-3-3-2-向量存储评估" class="headerlink" title="3.3.3.2 向量存储评估"></a>3.3.3.2 向量存储评估</h5><p>以目前256维向量为例。线上采用SQ8量化相较float32存储占用少4倍。哈希量化存储量化在SQ8基础上还能少8倍。</p>
<h5 id="3-3-1-3-检索速度评估"><a href="#3-3-1-3-检索速度评估" class="headerlink" title="3.3.1.3 检索速度评估"></a>3.3.1.3 检索速度评估</h5><p>候选集大小：140W</p>
<p>测试数据量： 100条</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>检索类型</th>
<th>平均检索耗时</th>
</tr>
</thead>
<tbody>
<tr>
<td>SQ8检索</td>
<td>50.11m s</td>
</tr>
<tr>
<td>哈希检索</td>
<td>24.92ms</td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
</div>
<p><strong>哈希检索较SQ8速度提升50.31%</strong></p>
<h4 id="3-3-2-web-demo"><a href="#3-3-2-web-demo" class="headerlink" title="3.3.2 web demo"></a>3.3.2 web demo</h4><div class="table-container">
<table>
<thead>
<tr>
<th>检索类型</th>
<th>web demo 地址</th>
</tr>
</thead>
<tbody>
<tr>
<td>常规的SQ8搜索</td>
<td><a target="_blank" rel="noopener" href="http://192.168.18.240:20002/baseline">http://192.168.18.240:20002/baseline</a></td>
</tr>
<tr>
<td>哈希搜索</td>
<td><a target="_blank" rel="noopener" href="http://192.168.18.240:20002/binary_flat_ivf">http://192.168.18.240:20002/binary_flat_ivf</a></td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
</div>
<h3 id="3-4-结论"><a href="#3-4-结论" class="headerlink" title="3.4 结论"></a>3.4 结论</h3><p>本次POC调研了image hash的常用算法，并在专利图片检索中进行尝试。并对哈希搜索的精度、速度有了一定的认知。</p>
<p><strong>精度上：</strong></p>
<ul>
<li>灰度测试集在top1k召回上，哈希搜索较向量搜索降低8.17% （77.35% -&gt; 69.18%）。但是哈希检索top3K的召回能达到76.12%。若后续做重排的话，粗筛可用哈希搜索。</li>
<li>轮廓测试集在top1k召回上，哈希搜索较向量搜索提升4.68% (27.53% -&gt; 33.21%)</li>
</ul>
<p><strong>存储上：</strong></p>
<ul>
<li>哈希向量比原浮点型内存占用降低32倍，较SQ8向量内存占用降低8倍。</li>
</ul>
<p><strong>检索速度上：</strong></p>
<ul>
<li>哈希搜索相较SQ8提升50.13%（gallery 140w）</li>
</ul>
<p>后续可以应用的方向目前来看有2个：</p>
<ol>
<li>对于粗精排检索范式，可在粗排阶段用哈希做召回，精排阶段用浮点向量做排序。</li>
<li>精度要求不高的检索场景可用哈希检索。</li>
</ol>
<h2 id="4-附录：图片哈希检索的经典论文"><a href="#4-附录：图片哈希检索的经典论文" class="headerlink" title="4 附录：图片哈希检索的经典论文"></a>4 附录：图片哈希检索的经典论文</h2><h3 id="4-1-图片哈希检索经典论文"><a href="#4-1-图片哈希检索经典论文" class="headerlink" title="4.1 图片哈希检索经典论文"></a>4.1 图片哈希检索经典论文</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">Model</th>
<th>Learning Paradiam</th>
<th>Loss Function</th>
<th>Benchmark</th>
<th>Publish</th>
<th>Cite</th>
<th>year</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">CNNH<sup><a href="#fn_1" id="reffn_1">1</a></sup></td>
<td>有监督</td>
<td></td>
<td></td>
<td>AAAI</td>
<td>949</td>
<td>2014</td>
</tr>
<tr>
<td style="text-align:left">SDH<sup><a href="#fn_36" id="reffn_36">36</a></sup></td>
<td>有监督</td>
<td>标签语义损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE,MNIST,ImageNet100</td>
<td>CVPR</td>
<td>1121</td>
<td>2015</td>
</tr>
<tr>
<td style="text-align:left">DSH<sup><a href="#fn_2" id="reffn_2">2</a></sup></td>
<td>有监督</td>
<td>成对标签损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE</td>
<td>CVPR</td>
<td>774</td>
<td>2016</td>
</tr>
<tr>
<td style="text-align:left">DPSH<sup><a href="#fn_3" id="reffn_3">3</a></sup></td>
<td>有监督</td>
<td>成对标签损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE</td>
<td>IJCAI</td>
<td>607</td>
<td>2016</td>
</tr>
<tr>
<td style="text-align:left">DTSH<sup><a href="#fn_4" id="reffn_4">4</a></sup></td>
<td>有监督</td>
<td>三元组对损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE</td>
<td>-</td>
<td>168</td>
<td>2016</td>
</tr>
<tr>
<td style="text-align:left">DHN<sup><a href="#fn_5" id="reffn_5">5</a></sup></td>
<td>有监督</td>
<td>成对标签损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE,Flickr</td>
<td>AAAI</td>
<td>563</td>
<td>2016</td>
</tr>
<tr>
<td style="text-align:left">HashNet<sup><a href="#fn_6" id="reffn_6">6</a></sup></td>
<td>有监督</td>
<td>加权成对标签损失，量化损失</td>
<td>ImageNet100,NUS-WIDE,MS COCO</td>
<td>ICCV</td>
<td>503</td>
<td>2017</td>
</tr>
<tr>
<td style="text-align:left">DSDH<sup><a href="#fn_7" id="reffn_7">7</a></sup></td>
<td>有监督</td>
<td>成对标签损失，语义标签损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE</td>
<td>NIPS</td>
<td>243</td>
<td>2017</td>
</tr>
<tr>
<td style="text-align:left">LCDSH<sup><a href="#fn_8" id="reffn_8">8</a></sup></td>
<td>有监督</td>
<td>成对标签损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE</td>
<td>IJCAI</td>
<td>13</td>
<td>2017</td>
</tr>
<tr>
<td style="text-align:left">DAPH<sup><a href="#fn_32" id="reffn_32">32</a></sup></td>
<td>有监督</td>
<td>成对标签损失，平衡损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE</td>
<td>ACM</td>
<td>105</td>
<td>2017</td>
</tr>
<tr>
<td style="text-align:left">GreedyHash<sup><a href="#fn_9" id="reffn_9">9</a></sup></td>
<td>有监督</td>
<td>语义标签损失，量化损失</td>
<td>CIFAR-10,ImageNet100</td>
<td>NIPS</td>
<td>100</td>
<td>2018</td>
</tr>
<tr>
<td style="text-align:left">DCH<sup><a href="#fn_25" id="reffn_25">25</a></sup></td>
<td>有监督</td>
<td></td>
<td>CIFAR-10,NUS-WIDE,MS COCO</td>
<td>CVPR</td>
<td>258</td>
<td>2018</td>
</tr>
<tr>
<td style="text-align:left">DFH<sup><a href="#fn_10" id="reffn_10">10</a></sup></td>
<td>有监督</td>
<td>带margin的成对标签损失，语义标签损失，量化损失</td>
<td>CIFAR-10,ImageNet100</td>
<td>BMVC</td>
<td>15</td>
<td>2019</td>
</tr>
<tr>
<td style="text-align:left">IDHN<sup><a href="#fn_11" id="reffn_11">11</a></sup></td>
<td>有监督，多标签</td>
<td>成对多标签损失，量化损失</td>
<td>NUS-WIDE,Flickr,VOC2012,IAPRTC12</td>
<td>IEEE</td>
<td>82</td>
<td>2019</td>
</tr>
<tr>
<td style="text-align:left">DAGH<sup><a href="#fn_12" id="reffn_12">12</a></sup></td>
<td>有监督</td>
<td>成对标签损失，量化损失，平衡损失</td>
<td>CIFAR-10,NUS-WIDE,Fashion-MNIST</td>
<td>ICCV</td>
<td>43</td>
<td>2019</td>
</tr>
<tr>
<td style="text-align:left">DSHSD<sup><a href="#fn_13" id="reffn_13">13</a></sup></td>
<td>有监督</td>
<td>成对标签L2损失，语义标签损失</td>
<td>CIFAR-10,NUS-WIDE,ImageNet100</td>
<td>IEEE</td>
<td>11</td>
<td>2019</td>
</tr>
<tr>
<td style="text-align:left">DistillHash<sup><a href="#fn_30" id="reffn_30">30</a></sup></td>
<td>无监督</td>
<td></td>
<td></td>
<td>CVPR</td>
<td>105</td>
<td>2019</td>
</tr>
<tr>
<td style="text-align:left">SPDAQ<sup><a href="#fn_38" id="reffn_38">38</a></sup></td>
<td>有监督</td>
<td>相似度维持损失，平衡损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE-21,NUS-WIDE-81,MS-COCO</td>
<td>AAAI</td>
<td>12</td>
<td>2019</td>
</tr>
<tr>
<td style="text-align:left">DBDH<sup><a href="#fn_14" id="reffn_14">14</a></sup></td>
<td>有监督</td>
<td>成对标签损失，平衡损失</td>
<td>MNIST,CIFAR-10,CIFAR-20,Youtube Faces</td>
<td>-</td>
<td>31</td>
<td>2020</td>
</tr>
<tr>
<td style="text-align:left">CSQ<sup><a href="#fn_15" id="reffn_15">15</a></sup></td>
<td>有监督</td>
<td>平衡损失，基于聚类的量化损失</td>
<td>UCF101,HMDB51,ImageNet100, MS COCO,NUS-WIDE</td>
<td>CVPR</td>
<td>133</td>
<td>2020</td>
</tr>
<tr>
<td style="text-align:left">TBH<sup><a href="#fn_17" id="reffn_17">17</a></sup></td>
<td>无监督</td>
<td>重建损失，差异判别损失</td>
<td>CIFAR-10,NUS-WIDE,MS COCO</td>
<td>CVPR</td>
<td>67</td>
<td>2020</td>
</tr>
<tr>
<td style="text-align:left">DPAH<sup><a href="#fn_22" id="reffn_22">22</a></sup></td>
<td>有监督，多标签</td>
<td>差异正则损失，类间距离差异损失</td>
<td>NUS-WIDE,MS COCO,ImageNet100</td>
<td>WACV</td>
<td>13</td>
<td>2020</td>
</tr>
<tr>
<td style="text-align:left">ICICH<sup><a href="#fn_23" id="reffn_23">23</a></sup></td>
<td>有监督，跨模态</td>
<td>-</td>
<td>WIKI,MIRFlickr,NUS-WIDE</td>
<td>-</td>
<td>12</td>
<td>2020</td>
</tr>
<tr>
<td style="text-align:left">TSDH<sup><a href="#fn_24" id="reffn_24">24</a></sup></td>
<td>有监督</td>
<td>类内中心损失，相似矩阵一致性损失</td>
<td>CIFAR-10,NUS-WIDE,Flickr25K</td>
<td>TNNLS</td>
<td>73</td>
<td>2020</td>
</tr>
<tr>
<td style="text-align:left">DDDH<sup><a href="#fn_26" id="reffn_26">26</a></sup></td>
<td>有监督</td>
<td>成对标签损失，语义标签损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE,MS COCO</td>
<td>-</td>
<td>8</td>
<td>2020</td>
</tr>
<tr>
<td style="text-align:left">EDSH<sup><a href="#fn_27" id="reffn_27">27</a></sup></td>
<td>有监督，跨模态</td>
<td>-</td>
<td>WIKI,MIRFlickr25K,NUS-WIDE</td>
<td>-</td>
<td>21</td>
<td>2020</td>
</tr>
<tr>
<td style="text-align:left">SPLH<sup><a href="#fn_40" id="reffn_40">40</a></sup></td>
<td>有监督</td>
<td>相似度维持损失</td>
<td>CIFAR-10,MINIST,Places205</td>
<td>IEEE</td>
<td>30</td>
<td>2020</td>
</tr>
<tr>
<td style="text-align:left">Bi-Half Net<sup><a href="#fn_16" id="reffn_16">16</a></sup></td>
<td>无监督</td>
<td>量化损失</td>
<td>CIFAR-10,MS COCO,MNIST,UCF101,HMDB51</td>
<td>AAAI</td>
<td>24</td>
<td>2021</td>
</tr>
<tr>
<td style="text-align:left">CIBHash<sup><a href="#fn_18" id="reffn_18">18</a></sup></td>
<td>无监督，对比</td>
<td>对比损失</td>
<td>CIFAR-10,NUS-WIDE,MS COCO</td>
<td>-</td>
<td>13</td>
<td>2021</td>
</tr>
<tr>
<td style="text-align:left">CIMON<sup><a href="#fn_19" id="reffn_19">19</a></sup></td>
<td>有监督，对比</td>
<td>平行语义一致性损失，交叉语义一致性损失，对比一致损失</td>
<td>CIFAR-10,NUS-WIDE,Flickr25K</td>
<td>-</td>
<td>14</td>
<td>2021</td>
</tr>
<tr>
<td style="text-align:left">SPQ<sup><a href="#fn_20" id="reffn_20">20</a></sup></td>
<td>有监督，对比</td>
<td>交叉对比损失</td>
<td>CIFAR-10,NUS-WIDE,Flickr25K</td>
<td>ICCV</td>
<td>19</td>
<td>2021</td>
</tr>
<tr>
<td style="text-align:left">BNNH<sup><a href="#fn_28" id="reffn_28">28</a></sup></td>
<td>有监督</td>
<td>相似度维持损失，激活感知损失</td>
<td>CIFAR-10,MNIST,ImageNet100</td>
<td>-</td>
<td>6</td>
<td>2021</td>
</tr>
<tr>
<td style="text-align:left">DCDH<sup><a href="#fn_34" id="reffn_34">34</a></sup></td>
<td>有监督</td>
<td>成对标签损失，类间差异似然损失，语义标签回归损失</td>
<td>YouTube Faces,FaceScrub,CFW-60K,VGGFace2</td>
<td>PR</td>
<td>13</td>
<td>2021</td>
</tr>
<tr>
<td style="text-align:left">DATE<sup><a href="#fn_35" id="reffn_35">35</a></sup></td>
<td>无监督</td>
<td>语义维持损失，对比损失</td>
<td>CIFAR-10,Flickr25K,NUSWIDE-10,NUSWIDE-21</td>
<td>MM</td>
<td>7</td>
<td>2021</td>
</tr>
<tr>
<td style="text-align:left">SortedNCE<sup><a href="#fn_29" id="reffn_29">29</a></sup></td>
<td>有监督</td>
<td>排序损失</td>
<td>CIFAR-10,NUS-WIDE,MS COCO</td>
<td>-</td>
<td>3</td>
<td>2022</td>
</tr>
<tr>
<td style="text-align:left">MeCoQ<sup><a href="#fn_31" id="reffn_31">31</a></sup></td>
<td>无监督</td>
<td>对比量化损失</td>
<td>CIFAR-10,NUS-WIDE,Flickr25K</td>
<td>AAAI</td>
<td>7</td>
<td>2022</td>
</tr>
<tr>
<td style="text-align:left">DSPH<sup><a href="#fn_33" id="reffn_33">33</a></sup></td>
<td>有监督，多模态</td>
<td>-</td>
<td>MIRFlickr,NUS-WIDE,Websearch</td>
<td>-</td>
<td>0</td>
<td>2022</td>
</tr>
<tr>
<td style="text-align:left">Domino<sup><a href="#fn_37" id="reffn_37">37</a></sup></td>
<td>有监督，跨模态</td>
<td>-</td>
<td>CelebA,ImageNet,MIMIC-CXR,EEG</td>
<td>ICLR</td>
<td>27</td>
<td>2022</td>
</tr>
<tr>
<td style="text-align:left">VTS<sup><a href="#fn_39" id="reffn_39">39</a></sup></td>
<td>有监督</td>
<td>-</td>
<td>CIFAR-10,NUS-WIDE,MS COCO,ImageNet100</td>
<td>ICME</td>
<td>8</td>
<td>2022</td>
</tr>
<tr>
<td style="text-align:left">CLIP4hashing<sup><a href="#fn_21" id="reffn_21">21</a></sup></td>
<td>有监督</td>
<td>相似矩阵一致性损失</td>
<td>MSRVTT,DiDeMo,MSVD</td>
<td>ICMR</td>
<td>1</td>
<td>2022</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><blockquote id="fn_1">
<sup>1</sup>. <a target="_blank" rel="noopener" href="https://scholar.google.com/scholar?hl=zh-CN&amp;as_sdt=0%2C5&amp;q=Supervised+Hashing++for+Image+Retrieval+via+Image+Representation+Learning&amp;btnG=">Supervised Hashing  for Image Retrieval via Image Representation Learning</a><a href="#reffn_1" title="Jump back to footnote [1] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_2">
<sup>2</sup>. <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Liu_Deep_Supervised_Hashing_CVPR_2016_paper.pdf">Deep Supervised Hashing for Fast Image Retrieval</a><a href="#reffn_2" title="Jump back to footnote [2] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_3">
<sup>3</sup>. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1511.03855.pdf">Feature Learning based Deep Supervised Hashing with Pairwise Labels</a><a href="#reffn_3" title="Jump back to footnote [3] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_4">
<sup>4</sup>. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1612.03900.pdf">Deep Supervised Hashing with Triplet Labels</a><a href="#reffn_4" title="Jump back to footnote [4] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_5">
<sup>5</sup>. <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/10235/10094">Deep Hashing Network for Efficient Similarity Retrieval</a><a href="#reffn_5" title="Jump back to footnote [5] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_6">
<sup>6</sup>. <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Cao_HashNet_Deep_Learning_ICCV_2017_paper.pdf">HashNet: Deep Learning to Hash by Continuation</a><a href="#reffn_6" title="Jump back to footnote [6] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_7">
<sup>7</sup>. <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2017/file/e94f63f579e05cb49c05c2d050ead9c0-Paper.pdf">Deep Supervised Discrete Hashing</a><a href="#reffn_7" title="Jump back to footnote [7] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_8">
<sup>8</sup>. <a target="_blank" rel="noopener" href="https://www.ijcai.org/proceedings/2017/0499.pdf">Locality-Constrained Deep Supervised Hashing for Image Retrieval</a><a href="#reffn_8" title="Jump back to footnote [8] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_9">
<sup>9</sup>. <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2018/file/13f3cf8c531952d72e5847c4183e6910-Paper.pdf">Greedy Hash: Towards Fast Optimization for Accurate Hash Coding in CNN</a><a href="#reffn_9" title="Jump back to footnote [9] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_10">
<sup>10</sup>. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.00206.pdf">Push for Quantization: Deep Fisher Hashing</a><a href="#reffn_10" title="Jump back to footnote [10] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_11">
<sup>11</sup>. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.02987.pdf">Improved Deep Hashing with Soft Pairwise Similarity for Multi-label Image Retrieval</a><a href="#reffn_11" title="Jump back to footnote [11] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_12">
<sup>12</sup>. <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Deep_Supervised_Hashing_With_Anchor_Graph_ICCV_2019_paper.pdf">Deep Supervised Hashing with Anchor Graph</a><a href="#reffn_12" title="Jump back to footnote [12] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_13">
<sup>13</sup>. <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8648432/">Deep Supervised Hashing Based on Stable Distribution</a><a href="#reffn_13" title="Jump back to footnote [13] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_14">
<sup>14</sup>. <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0925231220306032">Deep balanced discrete hashing for image retrieval</a><a href="#reffn_14" title="Jump back to footnote [14] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_15">
<sup>15</sup>. <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Yuan_Central_Similarity_Quantization_for_Efficient_Image_and_Video_Retrieval_CVPR_2020_paper.pdf">Central Similarity Quantization for Efficient Image and Video Retrieval</a><a href="#reffn_15" title="Jump back to footnote [15] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_16">
<sup>16</sup>. <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/16296/16103">Deep Unsupervised Image Hashing by Maximizing Bit Entropy</a><a href="#reffn_16" title="Jump back to footnote [16] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_17">
<sup>17</sup>. <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Shen_Auto-Encoding_Twin-Bottleneck_Hashing_CVPR_2020_paper.pdf">Auto-Encoding twin bottleneck hashing</a><a href="#reffn_17" title="Jump back to footnote [17] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_18">
<sup>18</sup>. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2105.06138.pdf">Unsupervised Hashing with Contrastive Information Bottleneck</a><a href="#reffn_18" title="Jump back to footnote [18] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_19">
<sup>19</sup>. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2010.07804.pdf">CIMON: Towards High-quality Hash Codes</a><a href="#reffn_19" title="Jump back to footnote [19] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_20">
<sup>20</sup>. <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Jang_Self-Supervised_Product_Quantization_for_Deep_Unsupervised_Image_Retrieval_ICCV_2021_paper.pdf">Self-supervised Product Quantization for Deep Unsupervised Image Retrieval</a><a href="#reffn_20" title="Jump back to footnote [20] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_21">
<sup>21</sup>. <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/abs/10.1145/3512527.3531381">CLIP4Hashing: Unsupervised Deep Hashing for Cross-Modal Video-Text Retrieval</a><a href="#reffn_21" title="Jump back to footnote [21] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_22">
<sup>22</sup>. <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_WACV_2020/papers/Wang_Deep_Position-Aware_Hashing_for_Semantic_Continuous_Image_Retrieval_WACV_2020_paper.pdf">Deep Position-Aware Hashing for Semantic Continuous Image Retrieval</a><a href="#reffn_22" title="Jump back to footnote [22] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_23">
<sup>23</sup>. <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0306457319305357">Label consistent locally linear embedding based cross-modal hashing</a><a href="#reffn_23" title="Jump back to footnote [23] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_24">
<sup>24</sup>. <a target="_blank" rel="noopener" href="https://see.xidian.edu.cn/faculty/chdeng/Welcome%20to%20Cheng%20Deng&#39;s%20Homepage_files/Papers/Journal/TNNLS2020_Cheng.pdf">Two-Stream Deep Hashing With Class-Specific Centers for Supervised Image Search</a><a href="#reffn_24" title="Jump back to footnote [24] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_25">
<sup>25</sup>. <a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Cao_Deep_Cauchy_Hashing_CVPR_2018_paper.pdf">Deep Cauchy Hashing for Hamming Space Retrieval</a><a href="#reffn_25" title="Jump back to footnote [25] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_26">
<sup>26</sup>. <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0306457320307834">Discriminative dual-stream deep hashing for large-scale image retrieval</a><a href="#reffn_26" title="Jump back to footnote [26] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_27">
<sup>27</sup>. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.01304.pdf">Efficient Discrete Supervised Hashing for Large-scale Cross-modal Retrieval</a><a href="#reffn_27" title="Jump back to footnote [27] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_28">
<sup>28</sup>. <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3404835.3462896">Binary Neural Network Hashing for Image Retrieval</a><a href="#reffn_28" title="Jump back to footnote [28] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_29">
<sup>29</sup>. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2201.13322.pdf">Learning to Hash Naturally Sorts</a><a href="#reffn_29" title="Jump back to footnote [29] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_30">
<sup>30</sup>. <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Yang_DistillHash_Unsupervised_Deep_Hashing_by_Distilling_Data_Pairs_CVPR_2019_paper.pdf">DistillHash: Unsupervised Deep Hashing by Distilling Data Pairs</a><a href="#reffn_30" title="Jump back to footnote [30] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_31">
<sup>31</sup>. <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/download/20147/19906">Contrastive Quantization with Code Memory for Unsupervised Image Retrieval</a><a href="#reffn_31" title="Jump back to footnote [31] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_32">
<sup>32</sup>. <a target="_blank" rel="noopener" href="https://cfm.uestc.edu.cn/~fshen/DAPH.pdf">Deep Asymmetric Pairwise Hashing</a><a href="#reffn_32" title="Jump back to footnote [32] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_33">
<sup>33</sup>. <a target="_blank" rel="noopener" href="https://www.researchgate.net/profile/Shujuan-Ji/publication/359796301_An_efficient_dual_semantic_preserving_hashing_for_cross-modal_retrieval/links/625680cf328abe6281538210/An-efficient-dual-semantic-preserving-hashing-for-cross-modal-retrieval.pdf">An efficient dual semantic preserving hashing for cross-modal retrieval</a><a href="#reffn_33" title="Jump back to footnote [33] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_34">
<sup>34</sup>. <a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0031320321001631">Deep center-based dual-constrained hashing for discriminative face image retrieval</a><a href="#reffn_34" title="Jump back to footnote [34] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_35">
<sup>35</sup>. <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/abs/10.1145/3474085.3475570">A Statistical Approach to Mining Semantic Similarity for Deep Unsupervised Hashing</a><a href="#reffn_35" title="Jump back to footnote [35] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_36">
<sup>36</sup>. <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_cvpr_2015/papers/Shen_Supervised_Discrete_Hashing_2015_CVPR_paper.pdf">Supervised Discrete Hashing</a><a href="#reffn_36" title="Jump back to footnote [36] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_37">
<sup>37</sup>. <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.14960">Domino: Discovering systematic errors with cross-modal embeddings</a><a href="#reffn_37" title="Jump back to footnote [37] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_38">
<sup>38</sup>. <a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/4828">Similarity preserving deep asymmetric quantization for image retrieval</a><a href="#reffn_38" title="Jump back to footnote [38] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_39">
<sup>39</sup>. <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9859900/">Vision transformer hashing for image retrieval</a><a href="#reffn_39" title="Jump back to footnote [39] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_40">
<sup>40</sup>. <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9046296/">Similarity-preserving linkage hashing for online image retrieval</a><a href="#reffn_40" title="Jump back to footnote [40] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_41">
<sup>41</sup>. <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/1162229/">Vector quantization</a><a href="#reffn_41" title="Jump back to footnote [41] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_42">
<sup>42</sup>. <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/5432202/">Product quantization for nearest neighbor search</a><a href="#reffn_42" title="Jump back to footnote [42] in the text."> &#8617;</a>
</blockquote>
<blockquote id="fn_43">
<sup>43</sup>. <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/6296665/">Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval</a><a href="#reffn_43" title="Jump back to footnote [43] in the text."> &#8617;</a>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.myhz0606.com/2023/01/28/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blogs/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blogs/2023/01/28/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-01-28 10:26:35" itemprop="dateCreated datePublished" datetime="2023-01-28T10:26:35+08:00">2023-01-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-20 13:46:40" itemprop="dateModified" datetime="2023-02-20T13:46:40+08:00">2023-02-20</time>
              </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>78</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.myhz0606.com/2016/01/02/2016-01-02-Notes-On-Creating-A-Hexo-Theme/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blogs/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blogs/2016/01/02/2016-01-02-Notes-On-Creating-A-Hexo-Theme/" class="post-title-link" itemprop="url">Notes On Creating A Hexo Theme</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-01-02 00:00:00" itemprop="dateCreated datePublished" datetime="2016-01-02T00:00:00+08:00">2016-01-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-20 13:46:22" itemprop="dateModified" datetime="2023-02-20T13:46:22+08:00">2023-02-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blogs/categories/Hexo/" itemprop="url" rel="index"><span itemprop="name">Hexo</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>414</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <div class="image-strip">
<img src="https://s3.amazonaws.com/ptsteadman-images/hexo.png" class>
</div>

<h2 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h2><p>To Update NPM: <code>npm install npm@latest -g</code>.</p>
<p>In 2015 it makes sense to use NVM.  <a target="_blank" rel="noopener" href="http://linoxide.com/ubuntu-how-to/install-node-js-ubuntu">NVM Installation<br>Instructions</a>.</p>
<p>Update NPM: <code>npm install npm@latest -g</code></p>
<p>Hexo: why can’t you use helper functions in source code?<br>This should be in docs.</p>
<h2 id="Creating-a-Custom-Index-File-in-Hexo"><a href="#Creating-a-Custom-Index-File-in-Hexo" class="headerlink" title="Creating a Custom Index File in Hexo"></a>Creating a Custom Index File in Hexo</h2><p>Trying to generate a custom index file in source, hexo would ignore<br><code>source/index.md</code> no matter what I did.  What I had to do was uninstall<br><code>hexo-generator-index</code>.  <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues/1077">See<br>here</a>.  Then it works.  So, that<br>will be part of the setup for my theme.  But, it’s worth it in order to properly<br>seperate the theme from the content, I think.  Having everyone edit the theme<br>index.ejs template is no good.</p>
<h2 id="Hexo-Rendering-Raw-EJS-File-Problem-I-Encountered"><a href="#Hexo-Rendering-Raw-EJS-File-Problem-I-Encountered" class="headerlink" title="Hexo Rendering Raw EJS File Problem I Encountered"></a>Hexo Rendering Raw EJS File Problem I Encountered</h2><p>Sometimes the server would keep rendering an old version of my code, but as<br>text.  So I’d see stuff like</p>
<pre><code>&lt;% if (site.tags.length)&#123; %&gt;
</code></pre><p>The raw ejs, essentially.  Restarting the server or running <code>hexo clean</code> didn’t<br>do anything.</p>
<p>After some time, I realized it was due to the gedit swap files being read by<br>hexo as the actual layout files: for example, <code>tag.ejs~</code>.  My <code>partial</code> helpers<br>looked like: <code>&lt;%- partial(&#39;_partials/tag&#39;) %&gt;</code>, and apparently hexo was reading<br>in <code>tag.ejs~</code> instead of <code>tag.ejs</code>.  And therefore, the ejs wasn’t rendering.</p>
<p>To fix this, I simply changed my partial helper to <code>&lt;%-
partial(&#39;_partials/tag.ejs&#39;) %&gt;</code>.  Problem solved.</p>
<h2 id="Hexo-Excerpt-Variable"><a href="#Hexo-Excerpt-Variable" class="headerlink" title="Hexo Excerpt Variable"></a>Hexo Excerpt Variable</h2><p>I was confused by the behavior of the hexo <code>excerpt</code> variable.  If you define<br><code>excerpt: something</code> in the front matter, hexo ignores that.  Instead, to get it<br>to work, one needs to add a <code>&lt;!-- more --&gt;</code> comment in the source of the post.<br>Or, you can install a plugin that allows you to define custom excerpt in the<br>front matter.</p>
<h2 id="Scripts-Directory"><a href="#Scripts-Directory" class="headerlink" title="Scripts Directory"></a>Scripts Directory</h2><p>One of the things I really discovered too late is the “Scripts” directory in the<br>theme folder.  In Hexo, the various plugins drive the structure of the site, as<br>opposed to the placement of different files and directories, as in Jekyll.  The<br>plugins programatically create folder structure, etc, where in Jekyll I mostly<br>used the liquid markup to structure the site.  </p>
<p>The problem is, then, that the user wants to extend hexo to do some sort of<br>custom thing.  If one had to publish a new plugin, that’d be too much work.  But<br>the theme level scripts folder allows one to extend the base hexo functionality<br>in ‘user space’ effectively.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.myhz0606.com/2015/05/02/2015-05-02-How-To-Impress/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blogs/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blogs/2015/05/02/2015-05-02-How-To-Impress/" class="post-title-link" itemprop="url">How To Impress Employers at Infosessions</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2015-05-02 00:00:00" itemprop="dateCreated datePublished" datetime="2015-05-02T00:00:00+08:00">2015-05-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-20 13:45:55" itemprop="dateModified" datetime="2023-02-20T13:45:55+08:00">2023-02-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blogs/categories/Hexo/" itemprop="url" rel="index"><span itemprop="name">Hexo</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>462</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Top tech talent knows that industry recruiters often bring a stack of<br>pre-negotiated offers to university infosessions, so that they can snag<br>programmers and UX designers who really stand out.  Instead of spending valuable<br>time validating a particularly promising candidate’s skillset through a<br>protracted series of interviews, it’s often more efficient to simply <strong>give the<br>individual an offer right then and there</strong>.  Internal studies at Google have shown<br>that experienced recruiters can usually tell if a programmer has ‘what it takes’<br>just from how they act at infosessions: the insightful questions they ask, the<br>stickers on their laptop, and how they comport themselves in general.</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/blogs/2015/05/02/2015-05-02-How-To-Impress/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.myhz0606.com/2015/04/08/2015-04-08-NAV-Programming-Resources/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blogs/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blogs/2015/04/08/2015-04-08-NAV-Programming-Resources/" class="post-title-link" itemprop="url">NAV Web Service Programming Resources</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2015-04-08 00:00:00" itemprop="dateCreated datePublished" datetime="2015-04-08T00:00:00+08:00">2015-04-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-20 13:45:47" itemprop="dateModified" datetime="2023-02-20T13:45:47+08:00">2023-02-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blogs/categories/Hexo/" itemprop="url" rel="index"><span itemprop="name">Hexo</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>375</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Here are some of the resources I found helpful for learning to develop Dynamics NAV web service based applications.</p>
<h4 id="C-AL-Programming"><a href="#C-AL-Programming" class="headerlink" title="C/AL Programming:"></a>C/AL Programming:</h4><p><a target="_blank" rel="noopener" href="http://www.consultec.es/DocTutoriales/Introduction_to_CAL_Programming.pdf">Introduction to CAL Programming</a><br>This provides a good overview of the basics of CAL programming, which can become necessary in building a web service applications when a custom codeunit or page extension is required.</p>
<h4 id="Setting-up-Web-Services"><a href="#Setting-up-Web-Services" class="headerlink" title="Setting up Web Services:"></a>Setting up Web Services:</h4><p><a target="_blank" rel="noopener" href="http://vjeko.com/blog/connecting-to-nav-through-web-services-recorded-session">Vjecko Web Service Recorded Session</a><br>Vjecko.com has a lot of detailed articles about web service programming, but this older post has a pdf and recorded session that shows how to expose and connect to web services from a .NET application.  Unfortunately, he shows how to create Web Service references in .NET using the now-deprecated Web Refrence method (from .NET 2) instead of the more current Service Reference method.</p>
<p><a target="_blank" rel="noopener" href="http://blogs.msdn.com/b/freddyk/archive/2010/01/20/connecting-to-nav-web-services-from-c-using-service-reference-config-file-version.aspx">Using Service Reference to Connect to Web Services</a><br>This explains how to use Service Reference, using code instead of XML web.config configuration, which I found difficult to configure.  (Each time I updated the service reference, I would have to reconfigure the XML).</p>
<h4 id="NAV-Upgrade-Process"><a href="#NAV-Upgrade-Process" class="headerlink" title="NAV Upgrade Process:"></a>NAV Upgrade Process:</h4><p><a target="_blank" rel="noopener" href="http://saurav-nav.blogspot.com/2012/12/nav-2013-upgrade-part-iv-sql-migration.html">Migration to SQL Server from C/SIDE Database</a><br>In order to use web services, you don’t need to be using the Role Tailored Client, but you must be using the a SQL server based NAV database.  Web Services can be configured and exposed using the Classic Client for SQL Server Databases.</p>
<p><a target="_blank" rel="noopener" href="http://blogs.msdn.com/b/nav/archive/2012/03/05/rtc-debugging.aspx">Debugging Code Called by Web Services</a><br>C/AL code won’t necessarily execute the same as it did in the Classic Client when called  as a Web Service.  C/AL code called as web service execute in the NAV Server tier, instead of the client.  <a target="_blank" rel="noopener" href="http://msdn.microsoft.com/en-us/library/ff477107.aspx">Certain functions</a> aren’t available for code running in the NAV Server, and some design changes need to be made (for example, CONFIRM dialogue boxes don’t make sense in the context of a web service).  To debug the codeunits called through web services (or the Role Tailored Client), you will need to use Visual Studio.<br><a target="_blank" rel="noopener" href="http://msdn.microsoft.com/en-us/library/dd338765.aspx#SU">More information.</a></p>
<h4 id="Deploying-a-NET-Application"><a href="#Deploying-a-NET-Application" class="headerlink" title="Deploying a .NET Application:"></a>Deploying a .NET Application:</h4><p><a target="_blank" rel="noopener" href="http://www.asp.net/mvc/overview/deployment/visual-studio-web-deployment/deploying-to-iis">Deploying to IIS</a>  After you’ve built a .NET application that consumes .NET web services, you’ll have to find a way to deploy it on your servers, or Azure.  Connection strings can be used to specify different NAV servers for different environments (like development, QA, and prod).</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.myhz0606.com/2015/04/05/2015-04-05-Lookup-on-Page/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blogs/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blogs/2015/04/05/2015-04-05-Lookup-on-Page/" class="post-title-link" itemprop="url">Adding Lookup Field to a Page in Dynamics NAV</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2015-04-05 00:00:00" itemprop="dateCreated datePublished" datetime="2015-04-05T00:00:00+08:00">2015-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-20 13:45:35" itemprop="dateModified" datetime="2023-02-20T13:45:35+08:00">2023-02-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blogs/categories/Hexo/" itemprop="url" rel="index"><span itemprop="name">Hexo</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>451</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>One of the problems I faced in building a non-trivial application that consumed<br>NAV Web Services was figuring out how to “join” fields from different tables.<br>For example, when exposing a list of jobs from a job table which includes a<br>resource needed for the job, you might need more than just the resource id<br>that’s a field in the table: you might also need the resource name and<br>description.  While this is easy to get for one record, what about when you<br>need a few hundred records in a table that has been dynamically filtered?  When<br>exposing a Page as a web service, it’s easy to include the fields of the table<br>that the page is based on, but it’s less clear how to include fields from<br>another table.</p>
<p>Forum posts like <a target="_blank" rel="noopener" href="http://dynamicsuser.net/forums/p/32550/170843.aspx">this</a> led me to believe that I couldn’t expose flow fields in a Page web service, and I would get exceptions when I tried to expose all the fields of a table.  In fact, it’s perfectly possible to expose a flow field: it’s <strong>flow filters</strong> that don’t work with web services.  But, I also didn’t want to modify the underlying [job] table to add a flow field, and didn’t see an easy way of adding a flow field to a Page.  I tried “joining” the data in the C# application, but found network overhead made the application unusuably slow.</p>
<p>The solution to this problem was to use C/AL code to the Page to effectively create a lookup / flow field.  This way, the data is “pre-joined” before leaving the NAV Server, which is fast and clean, but you didn’t modify any tables.  Here’s how it’s done:</p>
<p>Step 1. <strong>Add a Field with SourceExpression Set to a Function Name</strong></p>
<p>To start, we create a Page using the wizard that includes all of the fields of an underlying table.  Then, we create manually add fields that will contain the lookup data from other tables.  The text in the SourceExpression column will be the name of the function that populates this field.<br><img src="http://ptsteadman.github.io/images/lookup-1.PNG" alt="Add a Field with SourceExpression Set to a Function Name"></p>
<p>Step 2. <strong>Create Function in the Page’s C/AL Code</strong></p>
<p>With the Page field designer open, go to the functions tab of C/AL Globals form, and add a function with the name of the text in the SourceExpression column.  Set the return type of the function with the “Locals” button, and a function trigger will appear in the C/AL code editor for your page.  Add code to the body of the function trigger that will be called for each record to provide a value for the field.<br><img src="http://ptsteadman.github.io/images/lookup-2.PNG" alt="Create Function in the Page&#39;s C/AL Code"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.myhz0606.com/2014/02/23/2014-02-23-hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blogs/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blogs/2014/02/23/2014-02-23-hello-world/" class="post-title-link" itemprop="url">Welcome To Hexo</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2014-02-23 00:00:00" itemprop="dateCreated datePublished" datetime="2014-02-23T00:00:00+08:00">2014-02-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-20 13:46:31" itemprop="dateModified" datetime="2023-02-20T13:46:31+08:00">2023-02-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blogs/categories/Hexo/" itemprop="url" rel="index"><span itemprop="name">Hexo</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>79</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a target="_blank" rel="noopener" href="http://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="http://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="http://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/blogs/2014/02/23/2014-02-23-hello-world/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">wwjiang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blogs/archives/">
        
          <span class="site-state-item-count">8</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blogs/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/blogs/tags/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wwjiang</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">12k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">45 分钟</span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>
-->

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/blogs/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/blogs/lib/velocity/velocity.min.js"></script>
  <script src="/blogs/lib/velocity/velocity.ui.min.js"></script>

<script src="/blogs/js/utils.js"></script>

<script src="/blogs/js/motion.js"></script>


<script src="/blogs/js/schemes/muse.js"></script>


<script src="/blogs/js/next-boot.js"></script>

<script src="/blogs/js/bookmark.js"></script>




  




  
<script src="/blogs/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
