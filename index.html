<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/myhz0606/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/myhz0606/images/favicon.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/myhz0606/images/favicon.ico">
  <link rel="mask-icon" href="/myhz0606/images/favicon.ico" color="#222">

<link rel="stylesheet" href="/myhz0606/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/myhz0606/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"github.com","root":"/myhz0606/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null,"valine":{"enable":true,"appId":null,"appKey":null,"serverURLs":null,"placeholder":"Just go go","avatar":"mm","meta":["nick","mail","link"],"pageSize":10,"visitor":true,"comment_count":true,"recordIP":false}},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="莫叶何竹">
<meta property="og:url" content="https://github.com/myhz0606/index.html">
<meta property="og:site_name" content="莫叶何竹">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="wwjiang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://github.com/myhz0606/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>莫叶何竹</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/myhz0606/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">莫叶何竹</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/myhz0606/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/myhz0606/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/myhz0606/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/myhz0606/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/myhz0606" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://github.com/myhz0606/2023/02/20/DDPM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/myhz0606/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/myhz0606/2023/02/20/DDPM/" class="post-title-link" itemprop="url">DDPM(denoising diffusion probabilistic)技术小结</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-02-20 11:13:00" itemprop="dateCreated datePublished" datetime="2023-02-20T11:13:00+08:00">2023-02-20</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-03-14 13:41:20" itemprop="dateModified" datetime="2023-03-14T13:41:20+08:00">2023-03-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/myhz0606/categories/diffusion-model/" itemprop="url" rel="index"><span itemprop="name">diffusion model</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.4k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>16 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="ddpm技术小结-denoising-diffusion-probabilistic">DDPM技术小结
(denoising diffusion probabilistic)</h1>
<h2 id="从直觉上理解ddpm">1 从直觉上理解DDPM</h2>
<p>在详细推到公式之前，我们先从直觉上理解一下什么是扩散</p>
<p>对于常规的生成模型，如GAN，VAE，它直接从噪声数据生成图像，我们不妨记噪声数据为<span class="math inline">\(z\)</span>,其生成的图片为<span class="math inline">\(x\)</span></p>
<p><strong>对于常规的生成模型</strong>：</p>
<p>学习一个解码函数(即我们需要学习的模型)<span class="math inline">\(p\)</span>，实现 $p(z)=x $ <span class="math display">\[
z \stackrel{p} \longrightarrow x
\]</span>
常规方法只需要一次预测即能实现噪声到目标的映射，虽然速度快，但是效果不稳定。</p>
<p>常规生成模型的训练过程（以VAE为例） <span class="math display">\[
x \stackrel{q} \longrightarrow z \stackrel{p} \longrightarrow
\widehat{x}
\]</span> <strong>对于diffusion model</strong></p>
<p>它将噪声到目标的过程进行了多步拆解。不妨假设一共有<span class="math inline">\(T+1\)</span>个时间步，第<span class="math inline">\(T\)</span>个时间步 <span class="math inline">\(x_T\)</span>是噪声数据，第0个时间步的输出是目标图片<span class="math inline">\(x_0\)</span>。其过程可以表述为： <span class="math display">\[
z = x_T \stackrel{p} \longrightarrow x_{T-1} \stackrel{p}
\longrightarrow \cdots \stackrel{p} \longrightarrow  x_{1} \stackrel{p}
\longrightarrow x_0
\]</span>
对于DDPM它采用的是一种自回归式的重建方法，每次的输入是当前的时刻及当前时刻的噪声图片。也就是说它把噪声到目标图片的生成分成了T步，这样每一次的预测相当于是对残差的预测。优势是重建效果稳定，但速度较慢。</p>
<p>训练整体pipeline包含两个过程</p>
<h2 id="diffusion-pipeline">2 diffusion pipeline</h2>
<h3 id="前置知识">2.1前置知识:</h3>
<p>高斯分布的一些性质</p>
<p>（1）如果<span class="math inline">\(X \sim \mathcal{N}(\mu,
\sigma^2)\)</span>,且<span class="math inline">\(a\)</span>与<span class="math inline">\(b\)</span>是实数,那么<span class="math inline">\(aX+b \sim \mathcal{N}(a\mu+b,
(a\sigma)^2)\)</span></p>
<p>（2）如果$X ((x), ^2(x)) <span class="math inline">\(,\)</span>Y
((y), ^2(y))<span class="math inline">\(,且\)</span>X,Y$是统计独立的正态随机变量,则它们的和也满足高斯分布(高斯分布可加性).
<span class="math display">\[
X+Y \sim \mathcal{N}(\mu(x)+\mu{(y), \sigma^2(x) + \sigma^2(y)}) \\
X-Y \sim \mathcal{N}(\mu(x)-\mu{(y), \sigma^2(x) + \sigma^2(y)})
\]</span> 均值为<span class="math inline">\(\mu\)</span>方差为<span class="math inline">\(\sigma\)</span>的高斯分布的概率密度函数为 <span class="math display">\[
\begin{eqnarray}
f(x) &amp;=&amp; \frac{1}{\sqrt{2\pi} \sigma } \exp \left ({- \frac{(x -
\mu)^2}{2\sigma^2} } \right) \nonumber \\
&amp;=&amp; \frac{1}{\sqrt{2\pi} \sigma } \exp \left[ -\frac{1}{2}
\left( \frac{1}{\sigma^2}x^2 - \frac{2\mu}{\sigma^2}x +
\frac{\mu^2}{\sigma^2}  \right )  \right]
\end{eqnarray}
\]</span></p>
<h3 id="加噪过程">2.2 加噪过程</h3>
<p>1 前向过程：将图片数据映射为噪声</p>
<p>每一个时刻都要添加高斯噪声，后一个时刻都是由前一个时刻加噪声得到。（其实每一个时刻加的噪声就是训练所用的标签）。即
<span class="math display">\[
x_0 \stackrel{q} \longrightarrow x_1 \stackrel{q} \longrightarrow x_{2}
\stackrel{q} \longrightarrow \cdots \stackrel{q}
\longrightarrow  x_{T-1} \stackrel{q} \longrightarrow x_T=z
\]</span> 下面我们详细来看</p>
<p>记<span class="math inline">\(\beta_t = 1 - \alpha_t\)</span>，<span class="math inline">\(\beta_t\)</span>随t的增加而增大(论文中<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>时从0.0001 -&gt; 0.02)
(这是因为一开始加一点噪声就很明显,后面需要增大噪声的量才明显).DDPM将加噪声过程建模为(这个是定义式,当然也可以定义成别的!)
<span class="math display">\[
\begin{eqnarray}
x_t &amp;=&amp; \sqrt{\alpha_t}x_{t-1} + \sqrt{(1 - \alpha_t)}z_t
\nonumber \\
&amp;=&amp;  \sqrt{\alpha_t}x_{t-1} + \sqrt{\beta_t}z_t
\end{eqnarray}
\]</span> <span class="math inline">\(x_t\)</span>为在<span class="math inline">\(t\)</span>时刻的图片，当<span class="math inline">\(t=0\)</span>时为原图；<span class="math inline">\(z_t\)</span>为在<span class="math inline">\(t\)</span>时刻所加的噪声，服从标准正态分布<span class="math inline">\(z_t \sim \mathcal{N}(0, \textbf{I})\)</span>;<span class="math inline">\(\alpha_t\)</span>是常数,是自己定义的变量;根据高斯分布的定义,<span class="math inline">\(x_t\)</span>的分布<span class="math inline">\(q(x_t|x_{t-1})=\mathcal{N}(x_t;
\sqrt{\alpha_t}x_{t-1}, (1 - \alpha_t) \textbf{I})\)</span>随着<span class="math inline">\(T\)</span>增大,<span class="math inline">\(x_t\)</span>越来越接近纯高斯分布.</p>
<p>同理: <span class="math display">\[
x_{t-1} = \sqrt{\alpha_{t-1} }x_{t-2} + \sqrt{1 - \alpha_{t-1} }z_{t-1}
\]</span> 将式(9)代入式(8)可得: <span class="math display">\[
\begin{eqnarray}
x_t &amp;=&amp; \sqrt{\alpha_t} (\sqrt{\alpha_{t-1} }x_{t-2} + \sqrt{1 -
\alpha_{t-1} }z_{t-1}) + \sqrt{1 - \alpha_t}z_t  \nonumber\\
    &amp;=&amp; \sqrt{\alpha_t \alpha_{t-1} }x_{t-2} + (\sqrt{\alpha_t
(1 - \alpha_{t-1})} z_{t-1}  + \sqrt{1 - \alpha_t}z_t)
\end{eqnarray}
\]</span> 由于<span class="math inline">\(z_{t-1}\)</span>服从均值为0,方差为1的高斯分布(即标准正态分布),根据定义<span class="math inline">\(\sqrt{\alpha_t (1 - \alpha_{t-1})}
z_{t-1}\)</span>服从的是均值为0,方差为<span class="math inline">\(\alpha_t (1 -
\alpha_{t-1})\)</span>的高斯分布.即<span class="math inline">\(\sqrt{\alpha_t (1 - \alpha_{t-1})} z_{t-1} \sim
\mathcal{N}(0, \alpha_t (1 -
\alpha_{t-1})\textbf{I})\)</span>.同理可得<span class="math inline">\(\sqrt{1 - \alpha_t}z_t \sim \mathcal{N}(0, (1 -
\alpha_t)\textbf{I})\)</span>.则<strong>(高斯分布可加性,可以通过定义推得,不赘述)</strong>
<span class="math display">\[
\begin{eqnarray}
(\sqrt{\alpha_t (1 - \alpha_{t-1})} , z_{t-1}  + \sqrt{1 - \alpha_t}z_t)
\sim \mathcal{N}(0, \alpha_t (1 - \alpha_{t-1}) + 1 - \alpha_t)
&amp;=&amp;  \mathcal{N}(0, 1 - \alpha_t \alpha_{t-1})
\end{eqnarray}
\]</span> 我们不妨记<span class="math inline">\(\overline{z}_{t-2} \sim
\mathcal{N}(0, \textbf{I})\)</span>,则<span class="math inline">\(\sqrt{1 - \alpha_t \alpha_{t-1} }
\overline{z}_{t-2} \sim \mathcal{N}(0, (1 - \alpha_t
\alpha_{t-1})\textbf{I})\)</span>则式(10)最终可改写为 <span class="math display">\[
x_t = \sqrt{\alpha_t \alpha_{t-1} } x_{t-2} +  \sqrt{1 - \alpha_t
\alpha_{t-1} } \overline{z}_{t-2}
\]</span> 通过递推,容易得到 $$ <span class="math display">\[\begin{eqnarray}
x_t &amp;=&amp; \sqrt{\alpha_t \alpha_{t-1} \cdots \alpha_1} x_0
+  \sqrt{1 - \alpha_t \alpha_{t-1} \dots \alpha_1} \overline{z}_0
\nonumber\\
&amp;=&amp; \sqrt{\prod_{i=1}^{t} {\alpha_i} }x_0 + \sqrt{1 -
\prod_{i=1}^{t} {\alpha_i} } \overline {z}_0 \nonumber \\

&amp;\stackrel{\mathrm{令} \overline{\alpha}_{t}  \prod_{i=1}^{t}
{\alpha_i} } = &amp; \sqrt{\overline{\alpha}_{t} }x_0+\sqrt{1 -
\overline{\alpha}_{t} }\overline{z}_{0}
\end{eqnarray}\]</span> <span class="math display">\[
其中$\overline{z}_{0} \sim \mathcal{N}(0,
\mathrm{I})$,$x_0$为原图.从式(13)可见,**我们可以从$x_0$得到任意时刻的$x_t$的分布(14),**而无需按照时间顺序递推!这极大提升了计算效率.
\]</span> <span class="math display">\[\begin{eqnarray}
q(x_t|x_0) &amp;=&amp;  \mathcal{N}(x_t; \mu{(x_t, t)},\sigma^2{(x_t,
t)}{}\textbf{I})
\nonumber\\
&amp;=&amp; \mathcal{N}(x_t; \sqrt{\overline{\alpha}_{t} }x_0,(1 -
\overline{\alpha}_{t})\textbf{I})
\end{eqnarray}\]</span> $$
⚠️<strong><font color="#DC143C">加噪过程是确定的,没有模型的介入</font>.</strong>
其目的是制作训练时标签</p>
<h3 id="去噪过程">2.3 去噪过程</h3>
<p>给定<span class="math inline">\(x_T\)</span>如何求出<span class="math inline">\(x_0\)</span>呢?直接求解是很难的,作者给出的方案是:我们可以一步一步求解.即学习一个解码函数<span class="math inline">\(p\)</span>,这个<span class="math inline">\(p\)</span>能够知道<span class="math inline">\(x_{t}\)</span>到<span class="math inline">\(x_{t-1}\)</span>的映射规则.如何定义这个<span class="math inline">\(p\)</span>是问题的关键.有了<span class="math inline">\(p\)</span>,只需从<span class="math inline">\(x_{t}\)</span>到<span class="math inline">\(x_{t-1}\)</span>逐步迭代,即可得出<span class="math inline">\(x_0\)</span>. <span class="math display">\[
z = x_T \stackrel{p} \longrightarrow x_{T-1} \stackrel{p}
\longrightarrow \cdots \stackrel{p} \longrightarrow  x_{1} \stackrel{p}
\longrightarrow x_0
\]</span> 去噪过程是加噪过程的逆向.如果说加噪过程是求给定初始分布<span class="math inline">\(x_0\)</span>求任意时刻的分布<span class="math inline">\(x_t\)</span>,即<span class="math inline">\(q(x_t|x_0)\)</span>那么去噪过程所求的分布就是给定任意时刻的分布<span class="math inline">\(x_t\)</span>求其初始时刻的分布<span class="math inline">\(x_0\)</span>,即<span class="math inline">\(p(x_0|x_t)\)</span>
,通过马尔可夫假设,可以对上述问题进行化简 <span class="math display">\[
\begin{eqnarray}
p(x_0|x_t) &amp;=&amp; p(x_0|x1)p(x1|x2)\cdots p(x_{t-1}| x_t)
\nonumber \\
&amp;=&amp; \prod_{i=0}^{t-1}{p(x_i|x_{i+1})}
\end{eqnarray}
\]</span> 如何求<span class="math inline">\({p(x_{t-1}|x_{t})}\)</span>呢?前面的加噪过程我们大力气推到出了<span class="math inline">\({q(x_{t}|x_{t-1})}\)</span>,我们可以通过贝叶斯公式把它利用起来
<span class="math display">\[
p(x_{t-1}|x_t) = \frac{p(x_{t}|x_{t-1})p(x_{t-1})}{p(x_t)}
\]</span> ⚠️<font color="#DC143C"><strong>这里的(去噪)<span class="math inline">\(p\)</span>和上面的(加噪)<span class="math inline">\(q\)</span>只是对分布的一种符号记法,它们是等价的.</strong></font></p>
<p>有了式(17)还是一头雾水,<span class="math inline">\(p(x_t)\)</span>和<span class="math inline">\(p(x_{t-1})\)</span>都不知道啊!该怎么办呢?这就要借助模型的威力了.下面来看如何构建我们的模型.</p>
<p>延续加噪过程的推导<span class="math inline">\(p(x_t|x_0)\)</span>和<span class="math inline">\(p(x_{t-1}|x_0)\)</span>我们是可以知道的.因此若我们知道初始分布<span class="math inline">\(x_0\)</span>,则 $$ <span class="math display">\[\begin{eqnarray}

p(x_{t-1}|x_t,x_0) &amp;=&amp; \frac{p(x_{t}|x_{t-1},
x_0)p(x_{t-1}|x_0)}{p(x_t|x_0)}
\\
&amp;=&amp; \frac{\mathcal{N}(x_t; \sqrt{\alpha_t}x_{t-1}, (1 -
\alpha_t) \textbf{I} )
\mathcal{N}(x_{t-1}; \sqrt{\overline{\alpha}_{t-1} }x_0,(1 -
\overline{\alpha}_{t-1}) \textbf{I})}

{ \mathcal{N}(x_t; \sqrt{\overline{\alpha}_{t} }x_0,(1 -
\overline{\alpha}_{t}) \textbf{I} )} \\
&amp;\stackrel{将式(6)代入} \propto &amp;  

\frac{
    \exp \left ({- \frac{(x_t - \sqrt{\alpha_t}x_{t-1} )^2}{2 (1 -
\alpha_t)} } \right)
  \exp \left ({- \frac{(x_{t-1} - \sqrt{\overline{\alpha}_{t-1} }x_0
)^2}{2 (1 - \overline{\alpha}_{t-1})} } \right)
  }
{
  \exp \left ({- \frac{(x_{t} - \sqrt{\overline{\alpha}_{t} }x_0 )^2}{2
(1 - \overline{\alpha}_{t})} }   \right)
} \\
  &amp;=&amp;
\exp \left [-\frac{1}{2} \left (  
\frac{(x_t - \sqrt{\alpha_t}x_{t-1} )^2}{1 - \alpha_t} +
\frac{(x_{t-1} - \sqrt{\overline{\alpha}_{t-1} }x_0 )^2}{1 -
\overline{\alpha}_{t-1} } -
\frac{(x_{t} - \sqrt{\overline{\alpha}_{t} }x_0 )^2}{1 -
\overline{\alpha}_{t} }
\right)   \right] \\
&amp;=&amp; \exp \left [
-\frac{1}{2} \left(  
\left( \frac{\alpha_t}{1-\alpha_t} + \frac{1}{1 -
\overline{\alpha}_{t-1} } \right)x^2_{t-1} -
\left ( \frac{2\sqrt{\overline{\alpha_{t} } } }{1 - \alpha_t}x_t +
\frac{2 \sqrt{\overline{\alpha}_{t-1} } }  {1 - \overline{\alpha}_{t-1}
}x_0  \right)x_{t-1} + C(x_t, x_0)
\right)
\right]


\end{eqnarray}\]</span> $$</p>
<p>结合高斯分布的定义(6)来看式(22),不难发现<span class="math inline">\(p(x_{t-1}|x_t,x_0)\)</span>也是服从高斯分布的.并且结合式(6)我们可以求出其方差和均值
<span class="math display">\[
\begin{eqnarray}
\frac{1}{\sigma_2} &amp;=&amp;  \frac{\alpha_t}{1-\alpha_t} + \frac{1}{1
- \overline{\alpha}_{t-1} } \\
\frac{2\mu}{\sigma^2} &amp;=&amp; \frac{2\sqrt{\overline{\alpha_{t} } }
}{1 - \alpha_t}x_t + \frac{2 \sqrt{\overline{\alpha}_{t-1} } }  {1 -
\overline{\alpha}_{t-1} }x_0
\end{eqnarray}
\]</span> 可以求得: <span class="math display">\[
\begin{eqnarray}
\sigma^2 &amp;=&amp; \frac{1 - \overline{\alpha}_{t-1} }{1 -
\overline{\alpha}_{t} } (1 - \alpha_t) \nonumber \\
\mu &amp;=&amp; \frac{\sqrt{\alpha_t} (1 - \overline{\alpha}_{t-1})}  {1
- \overline{\alpha}_t}x_t +
\frac{\sqrt{\overline{\alpha}_{t-1} } (1 - \alpha_t) }{1 -
\overline{\alpha}_t}x_0
\end{eqnarray}
\]</span> 通过上式,我们可得 <span class="math display">\[
p(x_{t-1}|x_t,x_0) = \mathcal{N}(x_{t-1}; \frac{\sqrt{\alpha_t} (1 -
\overline{\alpha}_{t-1})}  {1 - \overline{\alpha}_t}x_t +
\frac{\sqrt{\overline{\alpha}_{t-1} } (1 - \alpha_t) }{1 -
\overline{\alpha}_t}x_0 ,
(\frac{1 - \overline{\alpha}_{t-1} }{1 - \overline{\alpha}_{t} } (1 -
\alpha_t)) \textbf{I})
\]</span> 该式是真实的条件分布.我们目标是让模型学到的条件分布<span class="math inline">\(p_\theta(x_{t-1}|x_t)\)</span>尽可能的接近真实的条件分布<span class="math inline">\(p(x_{t-1}|x_t,
x_0)\)</span>.从上式可以看到方差是个固定量,那么我们要做的就是让<span class="math inline">\(p(x_{t-1}|x_t, x_0)\)</span>与<span class="math inline">\(p_\theta(x_{t-1}|x_t)\)</span>的均值尽可能的对齐,即</p>
<p>(这个结论也可以通过最小化上述两个分布的KL散度推得) <span class="math display">\[
\mathrm{arg} \mathop{min}_\theta \parallel u(x_0, x_t), u_\theta(x_t, t)
\parallel
\]</span> 下面的问题变为:<strong><font color="#DC143C ">如何构造<span class="math inline">\(u_\theta(x_t,
t)\)</span>来使我们的优化尽可能的简单 </font></strong></p>
<p>我们注意到<span class="math inline">\(\mu(x_0, x_t)\)</span>与<span class="math inline">\(\mu_\theta(x_t, t)\)</span>都是关于<span class="math inline">\(x_t\)</span>的函数,不妨让他们的<span class="math inline">\(x_t\)</span>保持一致,则可将<span class="math inline">\(\mu_\theta(x_t, t)\)</span>写成 <span class="math display">\[
\mu_\theta(x_t, t) = \frac{\sqrt{\alpha_t} (1 -
\overline{\alpha}_{t-1})}  {1 - \overline{\alpha}_t}x_t +
\frac{\sqrt{\overline{\alpha}_{t-1} } (1 - \alpha_t) }{1 -
\overline{\alpha}_t} f_\theta(x_t, t)
\]</span> <span class="math inline">\(f_\theta(x_t,
t)\)</span>是我们需要训练的模型.这样对齐均值的问题就转化成了:
<strong>给定<span class="math inline">\(x_t,
t\)</span>来预测原始图片输入<span class="math inline">\(x_0\)</span>.</strong>根据上文的加噪过程,我们可以很容易制造训练所需的数据对!
(Dalle2的训练采用的是这个方式,可能这就是大力出奇迹吧).事情到这里就结束了吗?</p>
<p>DDPM作者表示直接从<span class="math inline">\(x_t\)</span>到<span class="math inline">\(x_0\)</span>的预测数据跨度太大了,且效果一般.我们可以将式(12)做一下变形
<span class="math display">\[
\begin{eqnarray}
x_t &amp;=&amp;  \sqrt{\overline{\alpha}_{t} }x_0+\sqrt{1 -
\overline{\alpha}_{t} }\overline{z}_{0} \nonumber \\
x_0 &amp;=&amp; \frac{1}{\sqrt{\overline{\alpha}_{t} } }(x_t - \sqrt{1 -
\overline{\alpha}_{t} }\overline{z}_{0})
\end{eqnarray}
\]</span> 代入到式(24)中 $$ <span class="math display">\[\begin{eqnarray}
\mu &amp;=&amp; \frac{\sqrt{\alpha_t} (1 - \overline{\alpha}_{t-1})}  {1
- \overline{\alpha}_t}x_t +
\frac{\sqrt{\overline{\alpha}_{t-1} } (1 - \alpha_t) }{1 -
\overline{\alpha}_t} \frac{1}{\sqrt{\overline{a}_{t} } }(x_t - \sqrt{1 -
\overline{a}_{t} }\overline{z}_{0}) \nonumber \\

&amp;=&amp; \frac{\sqrt{\alpha_t} (1 - \overline{\alpha}_{t-1})}  {1 -
\overline{\alpha}_t}x_t +
\frac{(1 - \alpha_t) }{1 - \overline{\alpha}_t}
\frac{1}{\sqrt{\alpha}_{t} }(x_t - \sqrt{1 - \overline{\alpha}_{t}
}\overline{z}_{0}) \nonumber \\

&amp;\stackrel{合并x_t} =&amp; \frac{\alpha_t(1 -
\overline{\alpha}_{t-1}) + (1 - \alpha_t)  }{\sqrt{\alpha}_t (1 -
\overline{\alpha}_t)}x_t - \frac{\sqrt{1 - \overline{\alpha}_t}(1 -
\alpha_t) }{\sqrt{\alpha_t}(1 - \overline{\alpha}_t)}\overline{z}_0
\nonumber \\
&amp;=&amp; \frac{1 - \overline{\alpha}_t}{\sqrt{\alpha}_t (1 -
\overline{\alpha}_t)}x_t -
\frac{1 - \alpha_t }{\sqrt{\alpha_t}\sqrt{1 - \overline{\alpha}_t}
}\overline{z}_0 \nonumber \\
&amp;=&amp; \frac{1}{\sqrt{\alpha}_t}x_t -
\frac{1 - \alpha_t }{\sqrt{\alpha_t}\sqrt{1 - \overline{\alpha}_t}
}\overline{z}_0

\end {eqnarray}\]</span> <span class="math display">\[
经过这次化简,我们将$\mu{(x_0, x_t)} \Rightarrow \mu{(x_t,
\overline{z}_0)}$,其中$\overline{z}_0 \sim \mathcal{N}(0,
\textbf{I})$,可以将式(29)转变为
\]</span> <em>(x_t, t) = x_t - f</em>(x_t, t) $$
<font color="#DC143C"><strong>此时对齐均值的问题就转化成:给定<span class="math inline">\(x_t, t\)</span>预测<span class="math inline">\(x_t\)</span>加入的噪声<span class="math inline">\(\overline{z}_0\)</span>,</strong>
</font>也就是说我们的模型预测的是噪声<span class="math inline">\(f_\theta{(x_t, t)} \simeq
\overline{z}_0\)</span></p>
<h4 id="训练与采样过程">2.3.1 训练与采样过程</h4>
<p>训练的目标就是这两个噪声的尽可能的相近(用MSE或L1-loss). <span class="math display">\[
L = \mathrm{arg} \mathop{min}_\theta \parallel \epsilon -
\epsilon_{\theta}(x_t, t)\parallel ^2
\]</span> 下图为论文提供的训练和采样过程</p>
<!-- ![](/images/DDPM/algorithm.png) -->
<!-- ![](/images/DDPM/algorithm.png) -->
<p><img src="./images/DDPM/algorithm.png"> <img src="/images/DDPM/algorithm.png">
<!-- ![](source/images/DDPM/algorithm.png) -->
<!-- ![](/source/images/DDPM/algorithm.png)
![](./source/images/DDPM/algorithm.png)
<img src="/images/DDPM技术小结 (denoising diffusion probabilistic)/DDPM_algorithm.png"  height = "500" alt="图片名称"/>
<img src="./images/DDPM/DDPM_algorithm.png"  height = "500" alt="图片名称"/> --></p>
<h4 id="采样过程">2.3.2 采样过程</h4>
<p>通过以上讨论,我们推导出<span class="math inline">\(p_\theta(x_{t-1}|x_t)\)</span>高斯分布的均值和方差.<span class="math inline">\(p_\theta(x_{t-1}|x_t)=\mathcal{N}(x_{t-1};
\mu_{\theta}(x_t, t), \sigma^2(t) \textbf{I})\)</span>,根据文献<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>从一个高斯分布中采样一个随机变量可用一个重参数化技巧进行近似
$$ <span class="math display">\[\begin{eqnarray}
x_{t-1} &amp;=&amp; \mu_{\theta}(x_t, t) + \sigma(t) \epsilon,其中
\epsilon \in \mathcal{N}(\epsilon; 0, \textbf{I}) \\
&amp; = &amp; \frac{1}{\sqrt{\alpha_t} } (x_t -
\frac{1 - \alpha_t }{\sqrt{1 - \overline{\alpha}_t} }f_\theta(x_t, t)) +
\sigma(t) \epsilon

\end{eqnarray}\]</span> $$ 式(39)和论文给出的采样递推公式一致.</p>
<p>至此,已完成DDPM整体的pipeline.</p>
<p>还没想明白的点,为什么不能根据(7)的变形来进行采样计算呢? <span class="math display">\[
x_{t-1} = \frac{1}{\sqrt{\alpha_t} }x_t - \sqrt{\frac{1 -
\alpha_t}{\alpha_t} } f_\theta(x_t, t)
\]</span></p>
<h2 id="从代码理解训练预测过程">3 从代码理解训练&amp;预测过程</h2>
<h3 id="训练过程">3.1 训练过程</h3>
<p>参考代码仓库:
https://github.com/lucidrains/denoising-diffusion-pytorch/tree/main/denoising_diffusion_pytorch</p>
<p>已知项: 我们假定有一批<span class="math inline">\(N\)</span>张图片<span class="math inline">\(\{x_i
|i=1, 2, \cdots, N\}\)</span></p>
<p><strong>第一步</strong>: 随机采样<span class="math inline">\(K\)</span>组成batch,如<span class="math inline">\(\mathrm{x\_start}= \{ x_k|k=1,2, \cdots, K
\}\)</span>, <span class="math inline">\(\mathrm{Shape}(\mathrm{x\_start}) = (K, C, H,
W)\)</span></p>
<p><strong>第二步</strong>: 随机采样一些时间步</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t = torch.randint(<span class="number">0</span>, self.num_timesteps, (b,), device=device).long()  <span class="comment"># 随机采样时间步</span></span><br></pre></td></tr></table></figure>
<p>第三步: 随机采样噪声</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">noise = default(noise, <span class="keyword">lambda</span>: torch.randn_like(x_start))  <span class="comment"># 基于高斯分布采样噪声</span></span><br></pre></td></tr></table></figure>
<p><strong>第四步</strong>: 计算<span class="math inline">\(\mathrm{x\_start}\)</span>在所采样的时间步的输出<span class="math inline">\(x_T\)</span>(即加噪声).(根据公式12)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">linear_beta_schedule</span>(<span class="params">timesteps</span>):</span><br><span class="line">    scale = <span class="number">1000</span> / timesteps</span><br><span class="line">    beta_start = scale * <span class="number">0.0001</span></span><br><span class="line">    beta_end = scale * <span class="number">0.02</span></span><br><span class="line">    <span class="keyword">return</span> torch.linspace(beta_start, beta_end, timesteps, dtype = torch.float64)</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line">betas = linear_beta_schedule(timesteps)</span><br><span class="line">alphas = <span class="number">1.</span> - betas</span><br><span class="line">alphas_cumprod = torch.cumprod(alphas, dim=<span class="number">0</span>)</span><br><span class="line">sqrt_one_minus_alphas_cumprod = torch.sqrt(<span class="number">1.</span> - alphas_cumprod)</span><br><span class="line">sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract</span>(<span class="params">a, t, x_shape</span>):</span><br><span class="line">    b, *_ = t.shape</span><br><span class="line">    out = a.gather(-<span class="number">1</span>, t)</span><br><span class="line">    <span class="keyword">return</span> out.reshape(b, *((<span class="number">1</span>,) * (<span class="built_in">len</span>(x_shape) - <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">q_sample</span>(<span class="params">x_start, t, noise=<span class="literal">None</span></span>):</span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  \begin&#123;eqnarray&#125;</span></span><br><span class="line"><span class="string">    x_t &amp;=&amp; \sqrt&#123;\alpha_t&#125;x_&#123;t-1&#125; + \sqrt&#123;(1 - \alpha_t)&#125;z_t \nonumber \\</span></span><br><span class="line"><span class="string">    &amp;=&amp;  \sqrt&#123;\alpha_t&#125;x_&#123;t-1&#125; + \sqrt&#123;\beta_t&#125;z_t</span></span><br><span class="line"><span class="string">  \end&#123;eqnarray&#125;</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> (</span><br><span class="line">        extract(sqrt_alphas_cumprod, t, x_start.shape) * x_start +</span><br><span class="line">        extract(sqrt_one_minus_alphas_cumprod, t, x_start.shape) * noise</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">x = q_sample(x_start = x_start, t = t, noise = noise)  <span class="comment"># 这就是x0在时间步T的输出</span></span><br></pre></td></tr></table></figure>
<p><strong>第五步</strong>: 预测噪声.输入<span class="math inline">\(x_T,t\)</span>到噪声预测模型,来预测此时的噪声<span class="math inline">\(\hat{z}_t = \epsilon_\theta(x_T,
t)\)</span>.论文用到的模型结构是Unet,与传统Unet的输入有所不同的是增加了一个时间步的输入.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_out = self.model(x, t, x_self_cond=<span class="literal">None</span>)  <span class="comment"># 预测噪声</span></span><br></pre></td></tr></table></figure>
<p><strong>这里面有一个需要注意的点:模型是如何对时间步进行编码并使用的</strong></p>
<ul>
<li>首先会对时间步进行一个编码,将其变为一个向量,以正弦编码为例</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SinusoidalPosEmb</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">      	<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">      	Args:</span></span><br><span class="line"><span class="string">      		x (Tensor), shape like (B,)</span></span><br><span class="line"><span class="string">      	&quot;&quot;&quot;</span></span><br><span class="line">        device = x.device</span><br><span class="line">        half_dim = self.dim // <span class="number">2</span></span><br><span class="line">        emb = math.log(<span class="number">10000</span>) / (half_dim - <span class="number">1</span>)</span><br><span class="line">        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)</span><br><span class="line">        emb = x[:, <span class="literal">None</span>] * emb[<span class="literal">None</span>, :]</span><br><span class="line">        emb = torch.cat((emb.sin(), emb.cos()), dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> emb</span><br><span class="line">      </span><br><span class="line"><span class="comment"># 时间步的编码pipeline如下,本质就是将一个常数映射为一个向量</span></span><br><span class="line">self.time_mlp = nn.Sequential(</span><br><span class="line">    SinusoidalPosEmb(dim),</span><br><span class="line">    nn.Linear(fourier_dim, time_dim),</span><br><span class="line">    nn.GELU(),</span><br><span class="line">    nn.Linear(time_dim, time_dim)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li>将时间步的embedding嵌入到Unet的block中,使模型能够学习到时间步的信息</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, dim_out, groups = <span class="number">8</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.proj = WeightStandardizedConv2d(dim, dim_out, <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        self.norm = nn.GroupNorm(groups, dim_out)</span><br><span class="line">        self.act = nn.SiLU()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, scale_shift = <span class="literal">None</span></span>):</span><br><span class="line">        x = self.proj(x)</span><br><span class="line">        x = self.norm(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> exists(scale_shift):</span><br><span class="line">            scale, shift = scale_shift</span><br><span class="line">            x = x * (scale + <span class="number">1</span>) + shift  <span class="comment"># 将时间向量一分为2,一份用于提升幅值,一份用于修改相位</span></span><br><span class="line"></span><br><span class="line">        x = self.act(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">      </span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResnetBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, dim_out, *, time_emb_dim = <span class="literal">None</span>, groups = <span class="number">8</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.mlp = nn.Sequential(</span><br><span class="line">            nn.SiLU(),</span><br><span class="line">            nn.Linear(time_emb_dim, dim_out * <span class="number">2</span>)</span><br><span class="line">        ) <span class="keyword">if</span> exists(time_emb_dim) <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        self.block1 = Block(dim, dim_out, groups = groups)</span><br><span class="line">        self.block2 = Block(dim_out, dim_out, groups = groups)</span><br><span class="line">        self.res_conv = nn.Conv2d(dim, dim_out, <span class="number">1</span>) <span class="keyword">if</span> dim != dim_out <span class="keyword">else</span> nn.Identity()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, time_emb = <span class="literal">None</span></span>):</span><br><span class="line"></span><br><span class="line">        scale_shift = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> exists(self.mlp) <span class="keyword">and</span> exists(time_emb):</span><br><span class="line">            time_emb = self.mlp(time_emb)</span><br><span class="line">            time_emb = rearrange(time_emb, <span class="string">&#x27;b c -&gt; b c 1 1&#x27;</span>)</span><br><span class="line">            scale_shift = time_emb.chunk(<span class="number">2</span>, dim = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        h = self.block1(x, scale_shift = scale_shift)</span><br><span class="line"></span><br><span class="line">        h = self.block2(h)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> h + self.res_conv(x)</span><br></pre></td></tr></table></figure>
<p><strong>第六步</strong>:计算损失,反向传播.计算预测的噪声与实际的噪声的损失,损失函数可以是L1或mse</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@property</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_fn</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">if</span> self.loss_type == <span class="string">&#x27;l1&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> F.l1_loss</span><br><span class="line">    <span class="keyword">elif</span> self.loss_type == <span class="string">&#x27;l2&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> F.mse_loss</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">f&#x27;invalid loss type <span class="subst">&#123;self.loss_type&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>通过不断迭代上述6步即可完成模型的训练</p>
<h3 id="采样过程-1">3.2采样过程</h3>
<p>第一步:随机从高斯分布采样一张噪声图片,并给定采样时间步</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img = torch.randn(shape, device=device)</span><br></pre></td></tr></table></figure>
<p>第二步:
根据预测的当前时间步的噪声,通过公式计算当前时间步的均值和方差</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">posterior_mean_coef1 = betas * torch.sqrt(alphas_cumprod_prev) / (<span class="number">1.</span> - alphas_cumprod) <span class="comment"># 式(24)x_0的系数</span></span><br><span class="line">posterior_mean_coef = (<span class="number">1.</span> - alphas_cumprod_prev) * torch.sqrt(alphas) / (<span class="number">1.</span> - alphas_cumprod)  <span class="comment"># 式(24) x_t的系数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract</span>(<span class="params">a, t, x_shape</span>):</span><br><span class="line">  b, *_ = t.shape</span><br><span class="line">  out = a.gather(-<span class="number">1</span>, t)</span><br><span class="line">  <span class="keyword">return</span> out.reshape(b, *((<span class="number">1</span>,) * (<span class="built_in">len</span>(x_shape) - <span class="number">1</span>)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">q_posterior</span>(<span class="params">self, x_start, x_t, t</span>):</span><br><span class="line">  posterior_mean = (</span><br><span class="line">      extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +</span><br><span class="line">      extract(self.posterior_mean_coef2, t, x_t.shape) * x_t</span><br><span class="line">  )  <span class="comment"># 求出此时的均值</span></span><br><span class="line">  posterior_variance = extract(self.posterior_variance, t, x_t.shape)  <span class="comment"># 求出此时的方差</span></span><br><span class="line">  posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape) <span class="comment"># 对方差取对数,可能为了数值稳定性</span></span><br><span class="line">  <span class="keyword">return</span> posterior_mean, posterior_variance, posterior_log_variance_clipped  </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">p_mean_variance</span>(<span class="params">self, x, t, x_self_cond = <span class="literal">None</span>, clip_denoised = <span class="literal">True</span></span>):</span><br><span class="line">    preds = self.model_predictions(x, t, x_self_cond)  <span class="comment"># 预测噪声</span></span><br><span class="line">    x_start = preds.pred_x_start  <span class="comment"># 模型预测的是在x_t时间步噪声,x_start是根据公式(12)求</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> clip_denoised:</span><br><span class="line">        x_start.clamp_(-<span class="number">1.</span>, <span class="number">1.</span>)</span><br><span class="line"></span><br><span class="line">    model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start = x_start, x_t = x, t = t)</span><br><span class="line">    <span class="keyword">return</span> model_mean, posterior_variance, posterior_log_variance, x_start</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>第三步: 根据公式(33)计算得到前一个时刻图片<span class="math inline">\(x_{t-1}\)</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@torch.no_grad()</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">p_sample</span>(<span class="params">self, x, t: <span class="built_in">int</span>, x_self_cond = <span class="literal">None</span>, clip_denoised = <span class="literal">True</span></span>):</span><br><span class="line">    b, *_, device = *x.shape, x.device</span><br><span class="line">    batched_times = torch.full((x.shape[<span class="number">0</span>],), t, device = x.device, dtype = torch.long)</span><br><span class="line">    model_mean, _, model_log_variance, x_start = self.p_mean_variance(x = x, t = batched_times, x_self_cond = x_self_cond, clip_denoised = clip_denoised)  <span class="comment"># 计算当前分布的均值和方差</span></span><br><span class="line">    noise = torch.randn_like(x) <span class="keyword">if</span> t &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0.</span> <span class="comment"># 从高斯分布采样噪声</span></span><br><span class="line">    pred_img = model_mean + (<span class="number">0.5</span> * model_log_variance).exp() * noise  <span class="comment"># 根据</span></span><br><span class="line">    <span class="keyword">return</span> pred_img, x_start</span><br></pre></td></tr></table></figure>
<p>通过迭代以上三步,直至<span class="math inline">\(T=0\)</span>完成采样.</p>
<h2 id="思考和讨论">思考和讨论</h2>
<h2 id="参考文献">参考文献</h2>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.11239">Denoising
Diffusion Probabilistic Models</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2208.11970.pdf">Understanding Diffusion
Models: A Unified Perspective</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://github.com/myhz0606/2023/01/28/image_hash_exp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/myhz0606/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/myhz0606/2023/01/28/image_hash_exp/" class="post-title-link" itemprop="url">Image Hash Roadmap</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-01-28 16:05:00" itemprop="dateCreated datePublished" datetime="2023-01-28T16:05:00+08:00">2023-01-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-03-14 14:02:37" itemprop="dateModified" datetime="2023-03-14T14:02:37+08:00">2023-03-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/myhz0606/categories/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/" itemprop="url" rel="index"><span itemprop="name">图像检索</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>23 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="问题引出">1 问题引出</h2>
<h3 id="从最近邻搜索谈起nearest-neighbor-search-nn">1.1
从最近邻搜索谈起(nearest neighbor search, NN)</h3>
<p>最近邻检索：给定一张查询图片q(即query)（或文本），从数据库<span class="math inline">\(\mathcal{X}\)</span>中找到与之最相近的N张图片（或文本）。在实际的检索场景中，我们会用一条向量来作为图片(或文本)的表征。</p>
<p>用公式表达最近邻检索： <span class="math display">\[
\mathrm{NN}(q)=\mathrm{arg}\mathop{min}\limits_{x\in \mathcal{X} } \
\mathrm{dist}(q, x)
\]</span> dist 是某一种距离计算公式（如欧式距离、余弦距离）</p>
<p>直觉来看，最近邻问题很简单，<strong>只要计算query和库中所有向量的距离，再按照距离的大小排序返回最相近样本的索引即可。</strong>但是当数据规模过大时这就成为了一个问题。假设查询图片的向量维度为256（即<span class="math inline">\(d\in
\mathbb{R}^{256}\)</span>）,数据了类型为float64，一条向量的数据大小为
256 * 64 / 8 =
2KB。此时采用这种暴力搜索的方法进行检索，代价会非常大。</p>
<p>（实验CPU：Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz）</p>
<table>
<thead>
<tr class="header">
<th>数据库规模</th>
<th>距离计算耗时</th>
<th>向量数据库大小</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>一百万</td>
<td><span class="math inline">\(\sim\)</span> 24.13s秒</td>
<td><span class="math inline">\(\sim\)</span> 2GB</td>
</tr>
<tr class="even">
<td>一千万</td>
<td><span class="math inline">\(\sim\)</span> 4分钟</td>
<td><span class="math inline">\(\sim\)</span> 20GB</td>
</tr>
<tr class="odd">
<td>一亿</td>
<td><span class="math inline">\(\sim\)</span> 40分钟</td>
<td><span class="math inline">\(\sim\)</span> 200GB</td>
</tr>
</tbody>
</table>
<p>可见当数据量较大时，无论是从向量存储还是从搜索时延都无法满足实际应用需求。在工程中，当向量维度较低时，我们常用Kd-tree来加速搜索。当数据规模过大是（亿级），我们往往用到近似最近邻搜索技术(approximate
nearest neighbor
search，ANN)，ANN技术的核心技术之一就是向量量化技术(vector quantization,
VQ<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>)，常用的方法有乘积量化（product
quantization，PQ<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>）,哈希等。</p>
<h3 id="图片向量哈希是啥有啥难点">1.2 图片向量哈希是啥，有啥难点</h3>
<h4 id="图片向量哈希是啥">1.2.1 图片向量哈希是啥</h4>
<p>向量哈希是ANN技术中向量量化技术的一种常用方法。其目标是学习一个哈希量化函数将一个浮点型或整型的向量量化为一个哈希向量（仅含有两个值，0/1或-1/1）且尽可能的保证搜索结果能够维持（即
similarity preserving）。此时公式（1）可转化为： <span class="math display">\[
\mathrm{HashNN}(q)=\mathrm{arg}\mathop{min}\limits_{x\in \mathcal{X} } \
\mathrm{HammingDist}(q, x)
\]</span></p>
<p><span class="math display">\[
\mathrm{HammingDist}(x_1, x_2)=\mathrm{sum}( x1 \oplus x2)
\]</span></p>
<p>通过上面可以看出图片哈希检索与经典的NN检索有两个主要的不同点：</p>
<ol type="1">
<li><p>图片向量数据类型不同。哈希向量数域集合只有两个值{-1,
1}，浮点向量的数域集合接近无穷。这个特性能够大大降低向量检索任务的内存消耗。以上文256位的向量为例，数据类型为float64时一条向量占用2KB。但为哈希向量时一条数据类型仅为
256 * 1 / 8 =
32B,降低64倍的存储空间。可见哈希能够大幅度降低磁盘、内存的消耗。</p>
<table>
<thead>
<tr class="header">
<th>数据库规模</th>
<th>float64向量数据库大小</th>
<th>哈希向量数据库大小</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>一百万</td>
<td><span class="math inline">\(\sim\)</span> 2GB</td>
<td><span class="math inline">\(\sim\)</span> 31 MB</td>
</tr>
<tr class="even">
<td>一千万</td>
<td><span class="math inline">\(\sim\)</span> 20GB</td>
<td><span class="math inline">\(\sim\)</span> 310 MB</td>
</tr>
<tr class="odd">
<td>一亿</td>
<td><span class="math inline">\(\sim\)</span> 200GB</td>
<td><span class="math inline">\(\sim\)</span> 3GB</td>
</tr>
</tbody>
</table></li>
<li><p>距离计算公式不同。哈希检索用hamming距离作为其距离计算指标。即对两个向量按位求异或后相加。<strong>相对浮点数欧式距离、余弦距离的计算更快。</strong></p></li>
</ol>
<h4 id="图片向量哈希的主要难点要解决什么问题">1.2.2
图片向量哈希的主要难点（要解决什么问题）</h4>
<p>难点1: <strong>如何解决相似度维持问题（similarity
preserving</strong>）。即如何保证哈希后的检索结果和原向量的检索结果尽可能的一致。
<span class="math display">\[
\mathrm{NN}(q) \simeq \mathrm{HashNN}(q)
\]</span> 难点2:
向量哈希需要将向量从浮点数（或整数）映射到只包含两个值的数域空间（0/1或-1/1），这往往会用到符号函数。<strong>但符号函数不可导，如何用梯度下降进行优化？</strong>（针对用深度学习的哈希方法）。</p>
<h2 id="图片向量哈希方法">2 图片向量哈希方法</h2>
<h3 id="相似度维持的解决方案">2.1 相似度维持的解决方案</h3>
<p>在深度哈希任务中，主要通过<strong>设计特定的损失函数来解决相似度维持问题</strong>。</p>
<h4 id="基于成对标签">2.1.1 基于成对标签</h4>
<p>比较有代表性的是DSH<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>,DSDH<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>,DPSH<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>等。假定网络输入的图片<span class="math inline">\(x_1, x_2\)</span>,经过网络输出的浮点向量为<span class="math inline">\(f_1, f_2\)</span>，
经过哈希层后得到的哈希向量分别为<span class="math inline">\(b_1, b_2,
b_i \in \{-1, 1\}^c\)</span>，c是哈希向量的维度。成对标签规则如下：</p>
<ul>
<li>若<span class="math inline">\(x_1,
x_2\)</span>归属同一个类别（或认为相似），则认为其成对标签<span class="math inline">\(s_{12}=1\)</span></li>
<li>若<span class="math inline">\(x_1,
x_2\)</span>归属同不同类别否则为<span class="math inline">\(s_{12}=0\)</span>。</li>
</ul>
<p>对于任意两个数据点<span class="math inline">\(i,j\)</span>其似然概率定义如下</p>
<p><span class="math display">\[
p(s_{ij} | \mathcal{B}) =
\left \{
\begin{aligned}
&amp; \sigma(\Omega_{ij})   \, &amp; s_{ij} = 1 \\
&amp; 1 - \sigma(\Omega_{ij}) \, &amp; s_{ij} = 0
\end{aligned}
\right.
\]</span> 其中 <span class="math inline">\(\Omega_{ij}=\frac{1}{2}b_i^Tb_j\)</span>，<span class="math inline">\(\sigma(\Omega_{ij})=\frac{1}{1+e^{-\Omega_{ij} }
}\)</span></p>
<p>其目标函数为 <span class="math display">\[
\mathop{min}\limits_{\mathcal{B} }=- \mathop{log}
p(\mathcal{S}|\mathcal{B})=-\sum \limits_{s_{ij} \in \mathcal{S} }
\mathop{log} p(s_{ij}| \mathcal{B})=-\sum \limits_{s_{ij} \in
\mathcal{S} } (s_{ij} \Omega_{ij} - log(1 + e^{\Omega_{ij} }))
\]</span>
<strong>此类方法的扩展有</strong>：引入margin来优化类内方差与类间方差<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>、扩展到三元组<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>、基于类别分布进行加权<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>、亦或是扩展到多标签<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a></p>
<h4 id="基于语义标签">2.1.2 基于语义标签</h4>
<p>这类方法很多时候和成对标签损失一起用<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>。主要思想是：当我们有图片的标签时，只考虑pairwise信息没有充分利用到标签信息，故增加一个分类的损失来协助训练。
<span class="math display">\[
  \sum_{i=1}^{N}L(y_i, W^Tb_i)
\]</span>
主流的分类损失有3种：1）交叉熵损失；2）浮点向量投影得到的概率向量与哈希向量投影得到的二值向量的KL散度；3）L2损失。</p>
<h4 id="基于相似度一致">2.1.3 基于相似度一致</h4>
<p>假定<span class="math inline">\(f\)</span>输入图片的浮点特征向量，<span class="math inline">\(b\)</span>是输入图片的哈希向量。对于一个batch的浮点向量为<span class="math inline">\([f_1, f_2, ..,, f_N]\)</span>，哈希向量为<span class="math inline">\([b_1, b_2, ...,
b_N]\)</span>浮点向量构成的相似度矩阵<span class="math inline">\(S_f=[[f_1f_1^T, f_1f_2^T, ..., f_1f_N^T]; ...;
[f_Nf_1^T, f_Nf_2^T, ...,
f_Nf_N^T]]\)</span>。哈希向量构成的相似度矩阵<span class="math inline">\(S_b=[[b_1b_1^T, b_1b_2^T, ..., b_1b_N^T]; ...;
[b_Nb_1^T, b_Nb_2^T, ..., b_Nb_N^T]]\)</span></p>
<p>在实际的应用中有直接用MSE来使相似度矩阵最小化；也有利用对比学习思想构造相似度矩阵用交叉语义一致性来优化<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>。也有直接利用Batch本身标签的相似度矩阵<span class="math inline">\(S\)</span>来和哈希形成相似度矩阵<span class="math inline">\(S_b\)</span>进行优化<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>。</p>
<h4 id="基于重建">2.1.4 基于重建</h4>
<p>此类方法一般基于VAE架构。其核心思想是：将浮点向量进行哈希量化后，再用哈希向量进行重建，优化目标是重建后与重建前的feature
map尽可能的接近。</p>
<p>比较有代表性的工作是TBH<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>，相较基础的VAE架构同时引入了图卷积来进一步同步哈希向量和浮点向量的特征。</p>
<h4 id="其它相似度维持损失函数">2.1.5 其它相似度维持损失函数</h4>
<p>如优化检索排序的 SortedNCE<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a>，优化哈希码聚类分布的
CSQ<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a>，基于优化对比量化损失的MeCoQ<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>等。</p>
<h4 id="优化哈希码一些约束">2.1.6 优化哈希码一些约束</h4>
<p>为了避免过拟合往往会增加一个量化损失，使得生成的哈希向量与原向量量化误差别太大。一版采用L2损失或SmoothL1。
<span class="math display">\[
L_{quan} = \sum_i ^ N{ \parallel b_i - f_i \parallel ^2 }
\]</span>
为了使得生成的哈希向量差异性更大往往会增加一个平衡损失使得生成的哈希向量1/-1的个数差不多。
<span class="math display">\[
L_{balance}=\frac{1}{N} \parallel BB^T - I \parallel ^2
\]</span></p>
<h3 id="符号函数不可导的解决方案">2.2 符号函数不可导的解决方案</h3>
<h4 id="改写梯度更新规则">2.2.1 改写梯度更新规则</h4>
<p>Pytorch提供了自定义梯度更新的接口。有代表性的GreedyHash<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a>所用的方法前向过程调用符号函数，反向过程不计算符号函数的梯度。实现的关键是Pytorch中的<code>torch.autograd.Function</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GreedyHashLayer</span>(torch.autograd.Function):</span><br><span class="line"> </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, <span class="built_in">input</span></span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">input</span>.sign()</span><br><span class="line"> </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_output</span>):</span><br><span class="line">        <span class="keyword">return</span> grad_output</span><br></pre></td></tr></table></figure>
<h4 id="基于松弛relaxation思想训练中替代符号函数为其它可导函数">2.2.2
基于“松弛”（relaxation）思想训练中替代符号函数为其它可导函数</h4>
<p>此类方法是image
hash最为常用的方法。核心思想是：在训练过程将二值化函数用一个可微的函数替代，在推理过程中再用符号函数进行二值化。</p>
<p><img src="./images/image_hash_exp/HashNet_1.jpeg"> <img src="/images/image_hash_exp/HashNet_1.jpeg">
<!-- <img src="./images/image_hash_exp/HashNet_1.jpeg" width = "300" height = "200" alt="图片名称"/> --></p>
<h2 id="构建专利图片哈希检索系统">3 构建专利图片哈希检索系统</h2>
<h3 id="问题分析及技术选型">3.1 问题分析及技术选型</h3>
<p>目前线上已刷1亿+外观向量，1亿+实用新型向量，4亿+发明专利向量。<strong>现阶段我们所用image2vector的pipeline为</strong>
图像 -&gt; 去白边 -&gt; （提轮廓, shape-only）-&gt; resize -&gt;
特征提取 -&gt;
PCA降维。若采用全量训练的方式更新image2vector模型需要全量重刷已有的向量，代价很大。并且目前自训的模型还达不到Facebook在数十亿规模数据训练的基础模型。</p>
<p>本实验采用的image2hash架构为：固定特征提取模块，在已有pipeline上增加一个哈希层达到image2hash的效果。通过对论文的调研，可以尝试的方向有两大类，一类基于模型，一类基于统计。</p>
<p><img src="./images/image_hash_exp/arch.png"> <img src="/images/image_hash_exp/arch.png">
<!-- <img src="./images/image_hash_exp/arch.png" height = "500" alt="arch"/> --></p>
<h4 id="采用模型训练向量哈希参数">3.1.1 采用模型训练向量哈希参数</h4>
<p>与论文场景不同，此处需要将特征提取模块（backbone）的权重全部冻结，只训练哈希层的权重。主要有三类可行的方法：</p>
<p>1）可用公开数据结合标签语义损失+量化损失+平衡损失等进行训练。</p>
<p>2）用专利数据采用自监督的方法进行训练。</p>
<p>3）亦或者直接用最小化浮点向量和哈希向量的量化误差进行训练。</p>
<h5 id="基于开源数据训练哈希参数">3.1.1.1基于开源数据训练哈希参数</h5>
<p>为了快速验证模型效果，首先在imagenet100上进行验证。复现了几个主流的基于深度学习训练哈希层的方法，并在imagenet100上进行测试。（Dbhash是参考Dbnet思想构建的方法）。从结果上，当模型收敛，几类方法的mAP差距不大，但Dbhash的收敛速度特别快，<strong>故采用Dbhash架构来训练哈希层</strong>。</p>
<table>
<thead>
<tr class="header">
<th>epoch</th>
<th>Dbhash</th>
<th>GreedyHash<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></th>
<th>CSQ<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a></th>
<th>DHN<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a></th>
<th>DPSH<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>10</td>
<td>88.61%</td>
<td>86.82%</td>
<td>68.88%</td>
<td>65.85%</td>
<td>66.18%</td>
</tr>
<tr class="even">
<td>20</td>
<td>90.27%</td>
<td>89.46%</td>
<td>78.02%</td>
<td>74.81%</td>
<td>75.88%</td>
</tr>
<tr class="odd">
<td>30</td>
<td>90.34%</td>
<td>90.00%</td>
<td>82.14%</td>
<td>81.87%</td>
<td>82.50%</td>
</tr>
<tr class="even">
<td>40</td>
<td>90.48%</td>
<td>90.21%</td>
<td>84.64%</td>
<td>85.72%</td>
<td>86.03%</td>
</tr>
<tr class="odd">
<td>50</td>
<td>90.55%</td>
<td>90.27%</td>
<td>85.94%</td>
<td>88.11%</td>
<td>88.09%</td>
</tr>
<tr class="even">
<td>60</td>
<td>90.53%</td>
<td>90.56%</td>
<td>86.86%</td>
<td>89.58%</td>
<td>89.28%</td>
</tr>
<tr class="odd">
<td>70</td>
<td>90.60%</td>
<td>90.60%</td>
<td>87.57%</td>
<td>90.75%</td>
<td>89.89%</td>
</tr>
<tr class="even">
<td>80</td>
<td>90.59%</td>
<td>90.59%</td>
<td>88.20%</td>
<td>91.56%</td>
<td>90.37%</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>DBhash 模型架构</strong></p>
<p>整体架构如下图所示，需要训练的哈希层为Thresh layer。</p>
<p><img src="./images/image_hash_exp/DBhash_1.png"> <img src="/images/image_hash_exp/DBhash_1.png">
<!-- <img src="./images/image_hash_exp/DBhash_1.png"  height = "500" alt="图片名称"/> --></p>
<p><strong>训练目标函数有3个</strong>：语义标签分类损失、KL散度及量化损失。（效果见3.3.1）</p>
<p><strong>训练数据</strong>：imagenet1K</p>
<p><strong>PS：</strong>在实际尝试的过程中发现一个坑。BN层的统计数据(running_mean,
running_var)更新是在每一次训练阶段model.train()后的forward()方法中自动实现的，<strong>而不是</strong>在梯度计算与反向传播中更新optim.step()中完成。采用require_grad=False这个方法无法正常冻结。正确的冻结BN的方式是在模型训练时，把BN单独挑出来，重新设置其状态为eval
(在model.train()之后覆盖training状态）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">set_bn_eval</span>(<span class="params">m</span>):</span><br><span class="line">    classname = m.__class__.__name__</span><br><span class="line">    <span class="keyword">if</span> classname.find(<span class="string">&#x27;BatchNorm&#x27;</span>) != -<span class="number">1</span>:</span><br><span class="line">      m.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">model.apply(set_bn_eval)</span><br></pre></td></tr></table></figure>
<h5 id="直接基于最小化量化误差来训练哈希层">3.1.1.2直接基于最小化量化误差来训练哈希层</h5>
<p>本次POC主要尝试了iteration quantization（ITQ<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a>）。这个方法的核心思路是将经过PCA的向量数据集中的数据点映射到一个二进制超立方体的顶点上，使得对应的量化误差最小，从而而已得到对应该数据集优良的二进制编码。其核心思路是：找到最优的旋转投影矩阵来使得量化误差最小。代码实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ITQ</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;training hash code by ITQ method&quot;&quot;&quot;</span></span><br><span class="line">    DEFAULT_DEVICE = torch.device(<span class="string">&quot;cuda&quot;</span>) <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> torch.device(<span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, device=DEFAULT_DEVICE</span>):</span><br><span class="line">        self.device = device</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span> </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_pipeline</span>(<span class="params"></span></span><br><span class="line"><span class="params">            self, </span></span><br><span class="line"><span class="params">            vec_rtpath, </span></span><br><span class="line"><span class="params">            file_type, </span></span><br><span class="line"><span class="params">            pca_file=<span class="literal">None</span>, </span></span><br><span class="line"><span class="params">            checkpoints=<span class="literal">None</span>, </span></span><br><span class="line"><span class="params">            iterations=<span class="number">1000</span>, </span></span><br><span class="line"><span class="params">            thred=<span class="literal">None</span>, </span></span><br><span class="line"><span class="params">            debug=<span class="literal">False</span></span></span><br><span class="line"><span class="params">            </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        trainset = self.prepare_patent_data(</span><br><span class="line">            vec_rtpath, file_type, pca_file=pca_file, debug=debug</span><br><span class="line">        )</span><br><span class="line">        self.train(</span><br><span class="line">            trainset, checkpoints=checkpoints, iterations=iterations, thred=thred</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">prepare_patent_data</span>(<span class="params">self, vec_rtpath, file_type, pca_file=<span class="literal">None</span>, debug=<span class="literal">False</span></span>):</span><br><span class="line">        vector_ls, image_ls = VectorFileDecoder(file_type=file_type)(</span><br><span class="line">            vec_rtpath, sample_number=<span class="number">30</span> <span class="keyword">if</span> debug <span class="keyword">else</span> -<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> pca_file <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            pca_func = <span class="keyword">lambda</span> x: x </span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pca_func = PCA(pca_file)</span><br><span class="line">        vector_ls = [pca_func(np.array(i).reshape(<span class="number">1</span>, -<span class="number">1</span>)).reshape(-<span class="number">1</span>).tolist() <span class="keyword">for</span> i <span class="keyword">in</span> tqdm(vector_ls)]</span><br><span class="line">        vector_arr = np.array(vector_ls)  <span class="comment"># N * M</span></span><br><span class="line">        <span class="keyword">return</span> vector_arr</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, trainset: np.ndarray, checkpoints=<span class="literal">None</span>, iterations=<span class="number">1000</span>, thred=<span class="literal">None</span></span>):</span><br><span class="line">        trainset_tensor = torch.from_numpy(trainset.astype(np.float32)).to(self.device)</span><br><span class="line">        V = trainset_tensor</span><br><span class="line">        nbits = trainset_tensor.shape[<span class="number">1</span>]</span><br><span class="line">        R = torch.randn(nbits, nbits).to(self.device) </span><br><span class="line">        torch.nn.init.orthogonal_(R)</span><br><span class="line">        origin_quan_loss = self.frobenius_norm(V.sign(), V)</span><br><span class="line">        <span class="keyword">if</span> thred <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            binary_vec = FaissSearchAPI.img2hash_by_thred(</span><br><span class="line">                trainset, thred, to_int8_compress=<span class="literal">False</span></span><br><span class="line">            ).astype(np.float32)</span><br><span class="line">            logger.info(<span class="string">f&quot;generate binary vector by OT method: binary vec shape: <span class="subst">&#123;binary_vec.shape&#125;</span>&quot;</span>)</span><br><span class="line">            origin_quan_loss_2 = self.frobenius_norm(torch.from_numpy(binary_vec).to(self.device), V)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            origin_quan_loss_2 = <span class="number">0.0000</span></span><br><span class="line"></span><br><span class="line">        best_quant_loss = <span class="number">1e10</span></span><br><span class="line">        best_R = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">            <span class="comment"># step 1: update B</span></span><br><span class="line">            V_tilde = V @ R </span><br><span class="line">            B = V_tilde.sign()</span><br><span class="line">            <span class="comment"># step2: update R </span></span><br><span class="line">            [S, _, S_tilde_transpose] = torch.svd(B.t() @ V)</span><br><span class="line">            R = (S_tilde_transpose.t() @ S.t())</span><br><span class="line"></span><br><span class="line">            quant_loss = self.frobenius_norm(B, V_tilde)</span><br><span class="line">            <span class="keyword">if</span> quant_loss &lt; best_quant_loss:</span><br><span class="line">                best_quant_loss = quant_loss</span><br><span class="line">                best_R = R </span><br><span class="line">            logger.info(<span class="string">f&quot;Iter: <span class="subst">&#123;i:04d&#125;</span> frobenius_norm: <span class="subst">&#123;quant_loss:<span class="number">.4</span>f&#125;</span>, BEST: <span class="subst">&#123;best_quant_loss:<span class="number">.4</span>f&#125;</span>, ORIGIN: <span class="subst">&#123;origin_quan_loss:<span class="number">.4</span>f&#125;</span>, ORI2: <span class="subst">&#123;origin_quan_loss_2:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> checkpoints:</span><br><span class="line">            np.savez(checkpoints, R=best_R.cpu().numpy()) </span><br><span class="line">             </span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">frobenius_norm</span>(<span class="params">B, V_tilde</span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;$E = || B - V_tilde ||_&#123;F&#125;^&#123;2&#125;$&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> (B - V_tilde).<span class="built_in">pow</span>(<span class="number">2</span>).<span class="built_in">sum</span>().sqrt().item() / B.shape[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<h4 id="基于统计特征获得向量哈希参数">3.1.2
基于统计特征获得向量哈希参数</h4>
<p>该方法的本质是挖掘浮点向量的数值分布统计特征，以最小化量化损失、平衡损失为目标来构建哈希层。基于最优传输理论（Op
timal Transport, OT）的Bi-HalfNet<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a>。论文为什么写了很多，感兴趣可以看原文，这里主要讲怎么做。目前我们有1800w的专利图片向量，其构成的矩阵记为<span class="math inline">\(\mathrm{M}=\{m_i |i=1,2,...,18000000 \}, m_i \in
\mathbb{R}^{256}\)</span>,对于向量检索任务，向量<span class="math inline">\(m_i\)</span>可以看作是对应图片<span class="math inline">\(x_i\)</span>的表征。已知<span class="math inline">\(m_i\)</span>是256维，基于OT理论的哈希方法是将<span class="math inline">\(m_i\)</span>的每一维都当作一个特征。已知<span class="math inline">\(m_i=[m_{i,1},
m_{i,2},...,m_{i,256}]\)</span>。将所有样本第一维的特征汇聚一起可得：<span class="math inline">\(f_1=\{m_{i1}|i=1,2, ..., 18000000
\}\)</span>，如何得到一个划分，将<span class="math inline">\(f_i\)</span>转为二值化，且量化误差最小是我们的目标函数，即
<span class="math display">\[
\mathop{min} \sum \limits_{j} \parallel  f_i^{j} - b_i^{j} \parallel ^ 2
\]</span> <span class="math inline">\(f_i^{j}\)</span>表示在<span class="math inline">\(f_i\)</span>的第<span class="math inline">\(j\)</span>个样本；<span class="math inline">\(b_i^{j}\)</span>表示<span class="math inline">\(f_i^{j}\)</span>的哈希表示。</p>
<p>显然<span class="math inline">\(\mathop{mean}
(f_i)\)</span>是我们所需的解。但仅仅考虑量化误差没有兼顾哈希特征的丰富性，在实践中往往会加入一个平衡误差来使得一条哈希向量两个值的数量尽可能的接近。<span class="math inline">\(f_i\)</span>的中位数是我们所需的解。</p>
<p>综上所述，我们只需分别找到每一维的中位数作为该位置的划分，即可获得最小量化误差、最优平衡的哈希表征。</p>
<h3 id="检索系统搭建">3.2检索系统搭建</h3>
<p>Milvus
1.x并不支持哈希检索。本次POC采用Faiss平台搭建基于哈希的检索系统。（吐槽一下，faiss关于搭建哈希搜索的文档真的非常简略）里面有个大坑是插入哈希code导Faiss引擎是需要将哈希吗转为int8后在输入，随后需要将向量的维度变为
<span class="math inline">\(\mathrm{dim} /8\)</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">bytes2int8</span>(<span class="params">byte_vec</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    convert 0,1 matrix to uint8</span></span><br><span class="line"><span class="string">    shape: (N, M) -&gt; (N, M // 8)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> byte_vec.ndim == <span class="number">2</span></span><br><span class="line">    mutiple = np.array([<span class="number">2</span>**i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7</span>, -<span class="number">1</span>, -<span class="number">1</span>)]).reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">    hash_code = byte_vec</span><br><span class="line">    hash_code_uint8 = np.concatenate(</span><br><span class="line">        [np.<span class="built_in">sum</span>(hash_code[:, i * <span class="number">8</span> : (i + <span class="number">1</span>) * <span class="number">8</span>] * mutiple, axis=<span class="number">1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(hash_code.shape[<span class="number">1</span>] // <span class="number">8</span>)],</span><br><span class="line">        axis=<span class="number">1</span></span><br><span class="line">    ).astype(np.uint8)</span><br><span class="line">    <span class="keyword">return</span> hash_code_uint8</span><br></pre></td></tr></table></figure>
<h4 id="索引构建">3.2.1索引构建</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FaissSearchEngin</span>:</span><br><span class="line">    SUPPORT_INDEX_TYPE = <span class="built_in">set</span>(</span><br><span class="line">        [</span><br><span class="line">            <span class="string">&quot;binary_flat_ivf&quot;</span>,</span><br><span class="line">            <span class="string">&quot;binary_flat&quot;</span>,</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        index_type,</span></span><br><span class="line"><span class="params">        index_params=<span class="built_in">dict</span>(<span class="params"></span>),</span></span><br><span class="line"><span class="params">        index_rtpath=DEFAULT_INDEX_RTPATH,</span></span><br><span class="line"><span class="params">        vector=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        img_name_ls=<span class="literal">None</span>, </span></span><br><span class="line"><span class="params">        reuse=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">        logger=logger,</span></span><br><span class="line"><span class="params">        prefix = <span class="string">&#x27;&#x27;</span>, </span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            index_type(str): faiss index type</span></span><br><span class="line"><span class="string">            index_params(dict): faiss index create parameters</span></span><br><span class="line"><span class="string">            index_rtpath(str): faiss index rtpath</span></span><br><span class="line"><span class="string">            vector(np.ndarray, None): faiss index database</span></span><br><span class="line"><span class="string">            reuse(bool): always create index, whatever</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.logger = logger</span><br><span class="line">        self.reuse = reuse</span><br><span class="line">        self.index_type =  index_type</span><br><span class="line">        <span class="keyword">assert</span> (</span><br><span class="line">            index_type <span class="keyword">in</span> self.SUPPORT_INDEX_TYPE</span><br><span class="line">        ), <span class="string">f&quot;index type only support <span class="subst">&#123;self.SUPPORT_INDEX_TYPE&#125;</span> now!&quot;</span></span><br><span class="line">        self.vector = vector</span><br><span class="line">        self.img_name_ls = img_name_ls</span><br><span class="line">        <span class="keyword">if</span> self.vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            dim = vector.shape[<span class="number">1</span>] * <span class="number">8</span> <span class="keyword">if</span> <span class="string">&quot;binary&quot;</span> <span class="keyword">in</span> self.index_type <span class="keyword">else</span> vector.shape[<span class="number">1</span>]</span><br><span class="line">            index_params.update(<span class="built_in">dict</span>(dim=dim))</span><br><span class="line">        self.logger.info(<span class="string">f&quot;index params: <span class="subst">&#123;index_params&#125;</span>&quot;</span>)</span><br><span class="line">        self.index_save_rtpath = os.path.join(index_rtpath, index_type)</span><br><span class="line">        self.index_path = os.path.join(</span><br><span class="line">            self.index_save_rtpath,</span><br><span class="line">            <span class="string">f&quot;<span class="subst">&#123;prefix&#125;</span>_<span class="subst">&#123;<span class="string">&#x27;_&#x27;</span>.join([<span class="string">f&#x27;<span class="subst">&#123;k&#125;</span>_<span class="subst">&#123;v&#125;</span>&#x27;</span> <span class="keyword">for</span> k, v <span class="keyword">in</span> index_params.items()])&#125;</span>.index&quot;</span>,</span><br><span class="line">        )</span><br><span class="line">        self.index_params = index_params</span><br><span class="line">        checkdir(self.index_save_rtpath)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        self.check_index()</span><br><span class="line">        self.init_index_func(self.index_type)</span><br><span class="line">        self.index = self.build_index(</span><br><span class="line">            self.vector, index_params=self.index_params, index_path=self.index_path, reuse=self.reuse</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">check_index</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">if</span> self.reuse <span class="keyword">and</span> self.vector <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">assert</span> os.path.exists(</span><br><span class="line">                self.index_path</span><br><span class="line">            ), <span class="string">f&quot;there are no index file, you should input [vector] parameters to create it&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">convert_byte_vector_2_uint8</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span> </span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_index_func</span>(<span class="params">self, index_type</span>):</span><br><span class="line">        <span class="keyword">if</span> index_type == <span class="string">&quot;binary_flat_ivf&quot;</span>:</span><br><span class="line">            self._index_func = self._binary_flat_ivf</span><br><span class="line">            self.write_index_func = faiss.write_index_binary</span><br><span class="line">            self.read_index_func = faiss.read_index_binary</span><br><span class="line">        <span class="keyword">elif</span> index_type == <span class="string">&quot;binary_flat&quot;</span>:</span><br><span class="line">            self._index_func = self._binary_flat</span><br><span class="line">            self.write_index_func = faiss.write_index_binary</span><br><span class="line">            self.read_index_func = faiss.read_index_binary</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">search</span>(<span class="params">self, query, search_params</span>):</span><br><span class="line">        D, I = self.index.search(query, **search_params)</span><br><span class="line">        <span class="keyword">return</span> D, I</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build_index</span>(<span class="params">self, vector, index_path, index_params=<span class="built_in">dict</span>(<span class="params"></span>), reuse=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;create faiss index&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> os.path.exists(index_path) <span class="keyword">and</span> reuse:</span><br><span class="line">            self.logger.info(<span class="string">f&quot;read index from exists file: <span class="subst">&#123;index_path&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> self.read_index_func(index_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            index_info = self._index_func(index_params)</span><br><span class="line">            vector = vector.astype(index_info.vec_dtype)</span><br><span class="line">            self.logger.info(<span class="string">f&quot;vector shape: <span class="subst">&#123;vector.shape&#125;</span>, dtype: <span class="subst">&#123;vector.dtype&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="keyword">if</span> index_info.need_train:</span><br><span class="line">                self.logger.info(<span class="string">f&quot;start train index, please wait...&quot;</span>)</span><br><span class="line">                _t = time.perf_counter()</span><br><span class="line">                index_info.index_func.train(vector)</span><br><span class="line">                self.logger.info(</span><br><span class="line">                    <span class="string">f&quot;train index finish, time consume: <span class="subst">&#123;time.perf_counter() - _t&#125;</span>s&quot;</span></span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.logger.info(<span class="string">f&quot;current index type need not to train!&quot;</span>)</span><br><span class="line">            index_info.index_func.add(vector)</span><br><span class="line">            self.save_id_map(self.index_path.replace(<span class="string">&quot;.index&quot;</span>, <span class="string">&quot;_id_map.txt&quot;</span>))</span><br><span class="line">            self.logger.info(<span class="string">f&quot;save index file to <span class="subst">&#123;index_path&#125;</span>&quot;</span>)</span><br><span class="line">            self.write_index_func(index_info.index_func, index_path)</span><br><span class="line">            <span class="keyword">return</span> index_info.index_func</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_binary_flat</span>(<span class="params">self, params</span>):</span><br><span class="line">        index = faiss.IndexBinaryFlat(params.get(<span class="string">&quot;dim&quot;</span>))</span><br><span class="line">        <span class="keyword">return</span> index_info(index, <span class="literal">False</span>, np.uint8)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_binary_flat_ivf</span>(<span class="params">self, params</span>):</span><br><span class="line">        quantizer = faiss.IndexBinaryFlat(params.get(<span class="string">&quot;dim&quot;</span>))</span><br><span class="line">        index = faiss.IndexBinaryIVF(quantizer, params.get(<span class="string">&quot;dim&quot;</span>), params.get(<span class="string">&quot;nlist&quot;</span>))</span><br><span class="line">        <span class="keyword">return</span> index_info(index, <span class="literal">True</span>, np.uint8)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, index, training_vector</span>):</span><br><span class="line">        self.logger.info(<span class="string">f&quot;start train index&quot;</span>)</span><br><span class="line">        _t = time.perf_counter()</span><br><span class="line">        index.train(training_vector)</span><br><span class="line">        self.logger.info(<span class="string">f&quot;train index succeed! time consume: <span class="subst">&#123;time.perf_counter() - _t:<span class="number">.4</span>f&#125;</span>s&quot;</span>)</span><br><span class="line">        <span class="keyword">assert</span> index.is_trained, <span class="string">f&quot;index not train!&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_id_map</span>(<span class="params">self, save_path</span>):</span><br><span class="line">        checkdir(os.path.split(save_path)[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(save_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">&#x27;\n&#x27;</span>.join(self.img_name_ls))</span><br></pre></td></tr></table></figure>
<h3 id="指标及web-demo搭建">3.3 指标及web demo搭建</h3>
<h4 id="指标评估">3.3.1 指标评估</h4>
<p>分别在灰度测试集和轮廓测试集来测试哈希检索的效果。baseline为SQ8量化
（目前线上的量化方式）</p>
<p>候选数据集：140W 外观专利图片数据</p>
<p>测试集：外观专利灰度测试集、外观专利轮廓测试集</p>
<h5 id="精度评估">3.3.1.1 精度评估</h5>
<ul>
<li>灰度测试集的效果对比</li>
</ul>
<table>
<colgroup>
<col style="width: 8%">
<col style="width: 13%">
<col style="width: 31%">
<col style="width: 25%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>topk</th>
<th>baseline</th>
<th>哈希检索（Dbhash）</th>
<th>哈希检索（ITQ）</th>
<th>哈希检索(OT)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>10</td>
<td>31.43%</td>
<td>17.30%</td>
<td>22.91%</td>
<td>25.73%</td>
</tr>
<tr class="even">
<td>100</td>
<td>57.86%</td>
<td>39.95%</td>
<td>48.11%</td>
<td>50.54%</td>
</tr>
<tr class="odd">
<td>500</td>
<td>71.82%</td>
<td>56.28%</td>
<td>64.53%</td>
<td>64.09%</td>
</tr>
<tr class="even">
<td>1000</td>
<td>77.35%</td>
<td>64.00%</td>
<td>70.85%</td>
<td>69.18%</td>
</tr>
<tr class="odd">
<td>3000</td>
<td>83.32%</td>
<td>72.78%</td>
<td>78.75%</td>
<td>76.12%</td>
</tr>
<tr class="even">
<td>5000</td>
<td>86.57%</td>
<td>75.94%</td>
<td>81.47%</td>
<td>78.67%</td>
</tr>
<tr class="odd">
<td>10000</td>
<td>89.73%</td>
<td>81.21%</td>
<td>85.34%</td>
<td>82.53%</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="./images/image_hash_exp/GrayTestsetSearchResult.png">
<!-- <img src="./images/image_hash_exp/GrayTestsetSearchResult.png"  height = "500" alt="graytest"/> --></p>
<ul>
<li>轮廓测试集的效果对比</li>
</ul>
<table>
<colgroup>
<col style="width: 8%">
<col style="width: 13%">
<col style="width: 31%">
<col style="width: 25%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>topk</th>
<th>baseline</th>
<th>哈希检索（Dbhash）</th>
<th>哈希检索（ITQ）</th>
<th>哈希检索(OT)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>10</td>
<td>4.97%</td>
<td>4.67%</td>
<td>4.19%</td>
<td>5.51%</td>
</tr>
<tr class="even">
<td>100</td>
<td>12.21%</td>
<td>12.33%</td>
<td>9.16%</td>
<td>14.00%</td>
</tr>
<tr class="odd">
<td>500</td>
<td>21.48%</td>
<td>22.20%</td>
<td>15.74%</td>
<td>26.03%</td>
</tr>
<tr class="even">
<td>1000</td>
<td>27.53%</td>
<td>28.61%</td>
<td>20.59%</td>
<td>33.21%</td>
</tr>
<tr class="odd">
<td>3000</td>
<td>37.64%</td>
<td>38.78%</td>
<td>29.44%</td>
<td>42.85%</td>
</tr>
<tr class="even">
<td>5000</td>
<td>41.17%</td>
<td>43.57%</td>
<td>33.45%</td>
<td>46.92%</td>
</tr>
<tr class="odd">
<td>10000</td>
<td>46.62%</td>
<td>52.00%</td>
<td>38.90%</td>
<td>52.24%</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img src="./images/image_hash_exp/GrayTestsetSearchResult-4894374.png">
<!-- <img src="./images/image_hash_exp/GrayTestsetSearchResult-4894374.png"  height = "500" alt="graytest"/> --></p>
<p>从实验结果看，采用OT方法进行哈希量化能达到最优的效果。并且该方法实现简单，能够复用已刷的向量。</p>
<h5 id="向量存储评估">3.3.3.2 向量存储评估</h5>
<p>以目前256维向量为例。线上采用SQ8量化相较float32存储占用少4倍。哈希量化存储量化在SQ8基础上还能少8倍。</p>
<h5 id="检索速度评估">3.3.1.3 检索速度评估</h5>
<p>候选集大小：140W</p>
<p>测试数据量： 100条</p>
<table>
<thead>
<tr class="header">
<th>检索类型</th>
<th>平均检索耗时</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>SQ8检索</td>
<td>50.11m s</td>
</tr>
<tr class="even">
<td>哈希检索</td>
<td>24.92ms</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>哈希检索较SQ8速度提升50.31%</strong></p>
<h4 id="web-demo">3.3.2 web demo</h4>
<table>
<thead>
<tr class="header">
<th>检索类型</th>
<th>web demo 地址</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>常规的SQ8搜索</td>
<td>http://192.168.18.240:20002/baseline</td>
</tr>
<tr class="even">
<td>哈希搜索</td>
<td>http://192.168.18.240:20002/binary_flat_ivf</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="结论">3.4 结论</h3>
<p>本次POC调研了image
hash的常用算法，并在专利图片检索中进行尝试。并对哈希搜索的精度、速度有了一定的认知。</p>
<p><strong>精度上：</strong></p>
<ul>
<li>灰度测试集在top1k召回上，哈希搜索较向量搜索降低8.17% （77.35% -&gt;
69.18%）。但是哈希检索top3K的召回能达到76.12%。若后续做重排的话，粗筛可用哈希搜索。</li>
<li>轮廓测试集在top1k召回上，哈希搜索较向量搜索提升4.68% (27.53% -&gt;
33.21%)</li>
</ul>
<p><strong>存储上：</strong></p>
<ul>
<li>哈希向量比原浮点型内存占用降低32倍，较SQ8向量内存占用降低8倍。</li>
</ul>
<p><strong>检索速度上：</strong></p>
<ul>
<li>哈希搜索相较SQ8提升50.13%（gallery 140w）</li>
</ul>
<p>后续可以应用的方向目前来看有2个：</p>
<ol type="1">
<li>对于粗精排检索范式，可在粗排阶段用哈希做召回，精排阶段用浮点向量做排序。</li>
<li>精度要求不高的检索场景可用哈希检索。</li>
</ol>
<h2 id="附录图片哈希检索的经典论文">4 附录：图片哈希检索的经典论文</h2>
<h3 id="图片哈希检索经典论文">4.1 图片哈希检索经典论文</h3>
<table>
<colgroup>
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 36%">
<col style="width: 29%">
<col style="width: 4%">
<col style="width: 2%">
<col style="width: 2%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Model</th>
<th>Learning Paradiam</th>
<th>Loss Function</th>
<th>Benchmark</th>
<th>Publish</th>
<th>Cite</th>
<th>year</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">CNNH<a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a></td>
<td>有监督</td>
<td></td>
<td></td>
<td>AAAI</td>
<td>949</td>
<td>2014</td>
</tr>
<tr class="even">
<td style="text-align: left;">SDH<a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a></td>
<td>有监督</td>
<td>标签语义损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE,MNIST,ImageNet100</td>
<td>CVPR</td>
<td>1121</td>
<td>2015</td>
</tr>
<tr class="odd">
<td style="text-align: left;">DSH<a href="#fn26" class="footnote-ref" id="fnref26" role="doc-noteref"><sup>26</sup></a></td>
<td>有监督</td>
<td>成对标签损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE</td>
<td>CVPR</td>
<td>774</td>
<td>2016</td>
</tr>
<tr class="even">
<td style="text-align: left;">DPSH<a href="#fn27" class="footnote-ref" id="fnref27" role="doc-noteref"><sup>27</sup></a></td>
<td>有监督</td>
<td>成对标签损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE</td>
<td>IJCAI</td>
<td>607</td>
<td>2016</td>
</tr>
<tr class="odd">
<td style="text-align: left;">DTSH<a href="#fn28" class="footnote-ref" id="fnref28" role="doc-noteref"><sup>28</sup></a></td>
<td>有监督</td>
<td>三元组对损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE</td>
<td>-</td>
<td>168</td>
<td>2016</td>
</tr>
<tr class="even">
<td style="text-align: left;">DHN<a href="#fn29" class="footnote-ref" id="fnref29" role="doc-noteref"><sup>29</sup></a></td>
<td>有监督</td>
<td>成对标签损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE,Flickr</td>
<td>AAAI</td>
<td>563</td>
<td>2016</td>
</tr>
<tr class="odd">
<td style="text-align: left;">HashNet<a href="#fn30" class="footnote-ref" id="fnref30" role="doc-noteref"><sup>30</sup></a></td>
<td>有监督</td>
<td>加权成对标签损失，量化损失</td>
<td>ImageNet100,NUS-WIDE,MS COCO</td>
<td>ICCV</td>
<td>503</td>
<td>2017</td>
</tr>
<tr class="even">
<td style="text-align: left;">DSDH<a href="#fn31" class="footnote-ref" id="fnref31" role="doc-noteref"><sup>31</sup></a></td>
<td>有监督</td>
<td>成对标签损失，语义标签损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE</td>
<td>NIPS</td>
<td>243</td>
<td>2017</td>
</tr>
<tr class="odd">
<td style="text-align: left;">LCDSH<a href="#fn32" class="footnote-ref" id="fnref32" role="doc-noteref"><sup>32</sup></a></td>
<td>有监督</td>
<td>成对标签损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE</td>
<td>IJCAI</td>
<td>13</td>
<td>2017</td>
</tr>
<tr class="even">
<td style="text-align: left;">DAPH<a href="#fn33" class="footnote-ref" id="fnref33" role="doc-noteref"><sup>33</sup></a></td>
<td>有监督</td>
<td>成对标签损失，平衡损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE</td>
<td>ACM</td>
<td>105</td>
<td>2017</td>
</tr>
<tr class="odd">
<td style="text-align: left;">GreedyHash<a href="#fn34" class="footnote-ref" id="fnref34" role="doc-noteref"><sup>34</sup></a></td>
<td>有监督</td>
<td>语义标签损失，量化损失</td>
<td>CIFAR-10,ImageNet100</td>
<td>NIPS</td>
<td>100</td>
<td>2018</td>
</tr>
<tr class="even">
<td style="text-align: left;">DCH<a href="#fn35" class="footnote-ref" id="fnref35" role="doc-noteref"><sup>35</sup></a></td>
<td>有监督</td>
<td></td>
<td>CIFAR-10,NUS-WIDE,MS COCO</td>
<td>CVPR</td>
<td>258</td>
<td>2018</td>
</tr>
<tr class="odd">
<td style="text-align: left;">DFH<a href="#fn36" class="footnote-ref" id="fnref36" role="doc-noteref"><sup>36</sup></a></td>
<td>有监督</td>
<td>带margin的成对标签损失，语义标签损失，量化损失</td>
<td>CIFAR-10,ImageNet100</td>
<td>BMVC</td>
<td>15</td>
<td>2019</td>
</tr>
<tr class="even">
<td style="text-align: left;">IDHN<a href="#fn37" class="footnote-ref" id="fnref37" role="doc-noteref"><sup>37</sup></a></td>
<td>有监督，多标签</td>
<td>成对多标签损失，量化损失</td>
<td>NUS-WIDE,Flickr,VOC2012,IAPRTC12</td>
<td>IEEE</td>
<td>82</td>
<td>2019</td>
</tr>
<tr class="odd">
<td style="text-align: left;">DAGH<a href="#fn38" class="footnote-ref" id="fnref38" role="doc-noteref"><sup>38</sup></a></td>
<td>有监督</td>
<td>成对标签损失，量化损失，平衡损失</td>
<td>CIFAR-10,NUS-WIDE,Fashion-MNIST</td>
<td>ICCV</td>
<td>43</td>
<td>2019</td>
</tr>
<tr class="even">
<td style="text-align: left;">DSHSD<a href="#fn39" class="footnote-ref" id="fnref39" role="doc-noteref"><sup>39</sup></a></td>
<td>有监督</td>
<td>成对标签L2损失，语义标签损失</td>
<td>CIFAR-10,NUS-WIDE,ImageNet100</td>
<td>IEEE</td>
<td>11</td>
<td>2019</td>
</tr>
<tr class="odd">
<td style="text-align: left;">DistillHash<a href="#fn40" class="footnote-ref" id="fnref40" role="doc-noteref"><sup>40</sup></a></td>
<td>无监督</td>
<td></td>
<td></td>
<td>CVPR</td>
<td>105</td>
<td>2019</td>
</tr>
<tr class="even">
<td style="text-align: left;">SPDAQ<a href="#fn41" class="footnote-ref" id="fnref41" role="doc-noteref"><sup>41</sup></a></td>
<td>有监督</td>
<td>相似度维持损失，平衡损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE-21,NUS-WIDE-81,MS-COCO</td>
<td>AAAI</td>
<td>12</td>
<td>2019</td>
</tr>
<tr class="odd">
<td style="text-align: left;">DBDH<a href="#fn42" class="footnote-ref" id="fnref42" role="doc-noteref"><sup>42</sup></a></td>
<td>有监督</td>
<td>成对标签损失，平衡损失</td>
<td>MNIST,CIFAR-10,CIFAR-20,Youtube Faces</td>
<td>-</td>
<td>31</td>
<td>2020</td>
</tr>
<tr class="even">
<td style="text-align: left;">CSQ<a href="#fn43" class="footnote-ref" id="fnref43" role="doc-noteref"><sup>43</sup></a></td>
<td>有监督</td>
<td>平衡损失，基于聚类的量化损失</td>
<td>UCF101,HMDB51,ImageNet100, MS COCO,NUS-WIDE</td>
<td>CVPR</td>
<td>133</td>
<td>2020</td>
</tr>
<tr class="odd">
<td style="text-align: left;">TBH<a href="#fn44" class="footnote-ref" id="fnref44" role="doc-noteref"><sup>44</sup></a></td>
<td>无监督</td>
<td>重建损失，差异判别损失</td>
<td>CIFAR-10,NUS-WIDE,MS COCO</td>
<td>CVPR</td>
<td>67</td>
<td>2020</td>
</tr>
<tr class="even">
<td style="text-align: left;">DPAH<a href="#fn45" class="footnote-ref" id="fnref45" role="doc-noteref"><sup>45</sup></a></td>
<td>有监督，多标签</td>
<td>差异正则损失，类间距离差异损失</td>
<td>NUS-WIDE,MS COCO,ImageNet100</td>
<td>WACV</td>
<td>13</td>
<td>2020</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ICICH<a href="#fn46" class="footnote-ref" id="fnref46" role="doc-noteref"><sup>46</sup></a></td>
<td>有监督，跨模态</td>
<td>-</td>
<td>WIKI,MIRFlickr,NUS-WIDE</td>
<td>-</td>
<td>12</td>
<td>2020</td>
</tr>
<tr class="even">
<td style="text-align: left;">TSDH<a href="#fn47" class="footnote-ref" id="fnref47" role="doc-noteref"><sup>47</sup></a></td>
<td>有监督</td>
<td>类内中心损失，相似矩阵一致性损失</td>
<td>CIFAR-10,NUS-WIDE,Flickr25K</td>
<td>TNNLS</td>
<td>73</td>
<td>2020</td>
</tr>
<tr class="odd">
<td style="text-align: left;">DDDH<a href="#fn48" class="footnote-ref" id="fnref48" role="doc-noteref"><sup>48</sup></a></td>
<td>有监督</td>
<td>成对标签损失，语义标签损失，量化损失</td>
<td>CIFAR-10,NUS-WIDE,MS COCO</td>
<td>-</td>
<td>8</td>
<td>2020</td>
</tr>
<tr class="even">
<td style="text-align: left;">EDSH<a href="#fn49" class="footnote-ref" id="fnref49" role="doc-noteref"><sup>49</sup></a></td>
<td>有监督，跨模态</td>
<td>-</td>
<td>WIKI,MIRFlickr25K,NUS-WIDE</td>
<td>-</td>
<td>21</td>
<td>2020</td>
</tr>
<tr class="odd">
<td style="text-align: left;">SPLH<a href="#fn50" class="footnote-ref" id="fnref50" role="doc-noteref"><sup>50</sup></a></td>
<td>有监督</td>
<td>相似度维持损失</td>
<td>CIFAR-10,MINIST,Places205</td>
<td>IEEE</td>
<td>30</td>
<td>2020</td>
</tr>
<tr class="even">
<td style="text-align: left;">Bi-Half Net<a href="#fn51" class="footnote-ref" id="fnref51" role="doc-noteref"><sup>51</sup></a></td>
<td>无监督</td>
<td>量化损失</td>
<td>CIFAR-10,MS COCO,MNIST,UCF101,HMDB51</td>
<td>AAAI</td>
<td>24</td>
<td>2021</td>
</tr>
<tr class="odd">
<td style="text-align: left;">CIBHash<a href="#fn52" class="footnote-ref" id="fnref52" role="doc-noteref"><sup>52</sup></a></td>
<td>无监督，对比</td>
<td>对比损失</td>
<td>CIFAR-10,NUS-WIDE,MS COCO</td>
<td>-</td>
<td>13</td>
<td>2021</td>
</tr>
<tr class="even">
<td style="text-align: left;">CIMON<a href="#fn53" class="footnote-ref" id="fnref53" role="doc-noteref"><sup>53</sup></a></td>
<td>有监督，对比</td>
<td>平行语义一致性损失，交叉语义一致性损失，对比一致损失</td>
<td>CIFAR-10,NUS-WIDE,Flickr25K</td>
<td>-</td>
<td>14</td>
<td>2021</td>
</tr>
<tr class="odd">
<td style="text-align: left;">SPQ<a href="#fn54" class="footnote-ref" id="fnref54" role="doc-noteref"><sup>54</sup></a></td>
<td>有监督，对比</td>
<td>交叉对比损失</td>
<td>CIFAR-10,NUS-WIDE,Flickr25K</td>
<td>ICCV</td>
<td>19</td>
<td>2021</td>
</tr>
<tr class="even">
<td style="text-align: left;">BNNH<a href="#fn55" class="footnote-ref" id="fnref55" role="doc-noteref"><sup>55</sup></a></td>
<td>有监督</td>
<td>相似度维持损失，激活感知损失</td>
<td>CIFAR-10,MNIST,ImageNet100</td>
<td>-</td>
<td>6</td>
<td>2021</td>
</tr>
<tr class="odd">
<td style="text-align: left;">DCDH<a href="#fn56" class="footnote-ref" id="fnref56" role="doc-noteref"><sup>56</sup></a></td>
<td>有监督</td>
<td>成对标签损失，类间差异似然损失，语义标签回归损失</td>
<td>YouTube Faces,FaceScrub,CFW-60K,VGGFace2</td>
<td>PR</td>
<td>13</td>
<td>2021</td>
</tr>
<tr class="even">
<td style="text-align: left;">DATE<a href="#fn57" class="footnote-ref" id="fnref57" role="doc-noteref"><sup>57</sup></a></td>
<td>无监督</td>
<td>语义维持损失，对比损失</td>
<td>CIFAR-10,Flickr25K,NUSWIDE-10,NUSWIDE-21</td>
<td>MM</td>
<td>7</td>
<td>2021</td>
</tr>
<tr class="odd">
<td style="text-align: left;">SortedNCE<a href="#fn58" class="footnote-ref" id="fnref58" role="doc-noteref"><sup>58</sup></a></td>
<td>有监督</td>
<td>排序损失</td>
<td>CIFAR-10,NUS-WIDE,MS COCO</td>
<td>-</td>
<td>3</td>
<td>2022</td>
</tr>
<tr class="even">
<td style="text-align: left;">MeCoQ<a href="#fn59" class="footnote-ref" id="fnref59" role="doc-noteref"><sup>59</sup></a></td>
<td>无监督</td>
<td>对比量化损失</td>
<td>CIFAR-10,NUS-WIDE,Flickr25K</td>
<td>AAAI</td>
<td>7</td>
<td>2022</td>
</tr>
<tr class="odd">
<td style="text-align: left;">DSPH<a href="#fn60" class="footnote-ref" id="fnref60" role="doc-noteref"><sup>60</sup></a></td>
<td>有监督，多模态</td>
<td>-</td>
<td>MIRFlickr,NUS-WIDE,Websearch</td>
<td>-</td>
<td>0</td>
<td>2022</td>
</tr>
<tr class="even">
<td style="text-align: left;">Domino<a href="#fn61" class="footnote-ref" id="fnref61" role="doc-noteref"><sup>61</sup></a></td>
<td>有监督，跨模态</td>
<td>-</td>
<td>CelebA,ImageNet,MIMIC-CXR,EEG</td>
<td>ICLR</td>
<td>27</td>
<td>2022</td>
</tr>
<tr class="odd">
<td style="text-align: left;">VTS<a href="#fn62" class="footnote-ref" id="fnref62" role="doc-noteref"><sup>62</sup></a></td>
<td>有监督</td>
<td>-</td>
<td>CIFAR-10,NUS-WIDE,MS COCO,ImageNet100</td>
<td>ICME</td>
<td>8</td>
<td>2022</td>
</tr>
<tr class="even">
<td style="text-align: left;">CLIP4hashing<a href="#fn63" class="footnote-ref" id="fnref63" role="doc-noteref"><sup>63</sup></a></td>
<td>有监督</td>
<td>相似矩阵一致性损失</td>
<td>MSRVTT,DiDeMo,MSVD</td>
<td>ICMR</td>
<td>1</td>
<td>2022</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="reference">Reference</h2>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/1162229/">Vector
quantization</a><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/5432202/">Product
quantization for nearest neighbor search</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Liu_Deep_Supervised_Hashing_CVPR_2016_paper.pdf">Deep
Supervised Hashing for Fast Image Retrieval</a><a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2017/file/e94f63f579e05cb49c05c2d050ead9c0-Paper.pdf">Deep
Supervised Discrete Hashing</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1511.03855.pdf">Feature
Learning based Deep Supervised Hashing with Pairwise Labels</a><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.00206.pdf">Push for
Quantization: Deep Fisher Hashing</a><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1612.03900.pdf">Deep
Supervised Hashing with Triplet Labels</a><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Cao_HashNet_Deep_Learning_ICCV_2017_paper.pdf">HashNet:
Deep Learning to Hash by Continuation</a><a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.02987.pdf">Improved
Deep Hashing with Soft Pairwise Similarity for Multi-label Image
Retrieval</a><a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p><a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2017/file/e94f63f579e05cb49c05c2d050ead9c0-Paper.pdf">Deep
Supervised Discrete Hashing</a><a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2010.07804.pdf">CIMON:
Towards High-quality Hash Codes</a><a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12"><p><a target="_blank" rel="noopener" href="https://see.xidian.edu.cn/faculty/chdeng/Welcome%20to%20Cheng%20Deng&#39;s%20Homepage_files/Papers/Journal/TNNLS2020_Cheng.pdf">Two-Stream
Deep Hashing With Class-Specific Centers for Supervised Image
Search</a><a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Shen_Auto-Encoding_Twin-Bottleneck_Hashing_CVPR_2020_paper.pdf">Auto-Encoding
twin bottleneck hashing</a><a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2201.13322.pdf">Learning
to Hash Naturally Sorts</a><a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Yuan_Central_Similarity_Quantization_for_Efficient_Image_and_Video_Retrieval_CVPR_2020_paper.pdf">Central
Similarity Quantization for Efficient Image and Video Retrieval</a><a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16"><p><a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/download/20147/19906">Contrastive
Quantization with Code Memory for Unsupervised Image Retrieval</a><a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17"><p><a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2018/file/13f3cf8c531952d72e5847c4183e6910-Paper.pdf">Greedy
Hash: Towards Fast Optimization for Accurate Hash Coding in CNN</a><a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18"><p><a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2018/file/13f3cf8c531952d72e5847c4183e6910-Paper.pdf">Greedy
Hash: Towards Fast Optimization for Accurate Hash Coding in CNN</a><a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Yuan_Central_Similarity_Quantization_for_Efficient_Image_and_Video_Retrieval_CVPR_2020_paper.pdf">Central
Similarity Quantization for Efficient Image and Video Retrieval</a><a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20"><p><a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/10235/10094">Deep
Hashing Network for Efficient Similarity Retrieval</a><a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1511.03855.pdf">Feature
Learning based Deep Supervised Hashing with Pairwise Labels</a><a href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn22"><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/6296665/">Iterative
quantization: A procrustean approach to learning binary codes for
large-scale image retrieval</a><a href="#fnref22" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn23"><p><a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/16296/16103">Deep
Unsupervised Image Hashing by Maximizing Bit Entropy</a><a href="#fnref23" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn24"><p><a target="_blank" rel="noopener" href="https://scholar.google.com/scholar?hl=zh-CN&amp;as_sdt=0%2C5&amp;q=Supervised+Hashing++for+Image+Retrieval+via+Image+Representation+Learning&amp;btnG=">Supervised
Hashing for Image Retrieval via Image Representation Learning</a><a href="#fnref24" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn25"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_cvpr_2015/papers/Shen_Supervised_Discrete_Hashing_2015_CVPR_paper.pdf">Supervised
Discrete Hashing</a><a href="#fnref25" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn26"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Liu_Deep_Supervised_Hashing_CVPR_2016_paper.pdf">Deep
Supervised Hashing for Fast Image Retrieval</a><a href="#fnref26" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn27"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1511.03855.pdf">Feature
Learning based Deep Supervised Hashing with Pairwise Labels</a><a href="#fnref27" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn28"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1612.03900.pdf">Deep
Supervised Hashing with Triplet Labels</a><a href="#fnref28" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn29"><p><a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/10235/10094">Deep
Hashing Network for Efficient Similarity Retrieval</a><a href="#fnref29" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn30"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Cao_HashNet_Deep_Learning_ICCV_2017_paper.pdf">HashNet:
Deep Learning to Hash by Continuation</a><a href="#fnref30" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn31"><p><a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2017/file/e94f63f579e05cb49c05c2d050ead9c0-Paper.pdf">Deep
Supervised Discrete Hashing</a><a href="#fnref31" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn32"><p><a target="_blank" rel="noopener" href="https://www.ijcai.org/proceedings/2017/0499.pdf">Locality-Constrained
Deep Supervised Hashing for Image Retrieval</a><a href="#fnref32" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn33"><p><a target="_blank" rel="noopener" href="https://cfm.uestc.edu.cn/~fshen/DAPH.pdf">Deep
Asymmetric Pairwise Hashing</a><a href="#fnref33" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn34"><p><a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2018/file/13f3cf8c531952d72e5847c4183e6910-Paper.pdf">Greedy
Hash: Towards Fast Optimization for Accurate Hash Coding in CNN</a><a href="#fnref34" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn35"><p><a target="_blank" rel="noopener" href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Cao_Deep_Cauchy_Hashing_CVPR_2018_paper.pdf">Deep
Cauchy Hashing for Hamming Space Retrieval</a><a href="#fnref35" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn36"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1909.00206.pdf">Push for
Quantization: Deep Fisher Hashing</a><a href="#fnref36" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn37"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.02987.pdf">Improved
Deep Hashing with Soft Pairwise Similarity for Multi-label Image
Retrieval</a><a href="#fnref37" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn38"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Deep_Supervised_Hashing_With_Anchor_Graph_ICCV_2019_paper.pdf">Deep
Supervised Hashing with Anchor Graph</a><a href="#fnref38" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn39"><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8648432/">Deep Supervised
Hashing Based on Stable Distribution</a><a href="#fnref39" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn40"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Yang_DistillHash_Unsupervised_Deep_Hashing_by_Distilling_Data_Pairs_CVPR_2019_paper.pdf">DistillHash:
Unsupervised Deep Hashing by Distilling Data Pairs</a><a href="#fnref40" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn41"><p><a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/4828">Similarity
preserving deep asymmetric quantization for image retrieval</a><a href="#fnref41" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn42"><p><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0925231220306032">Deep
balanced discrete hashing for image retrieval</a><a href="#fnref42" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn43"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Yuan_Central_Similarity_Quantization_for_Efficient_Image_and_Video_Retrieval_CVPR_2020_paper.pdf">Central
Similarity Quantization for Efficient Image and Video Retrieval</a><a href="#fnref43" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn44"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Shen_Auto-Encoding_Twin-Bottleneck_Hashing_CVPR_2020_paper.pdf">Auto-Encoding
twin bottleneck hashing</a><a href="#fnref44" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn45"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_WACV_2020/papers/Wang_Deep_Position-Aware_Hashing_for_Semantic_Continuous_Image_Retrieval_WACV_2020_paper.pdf">Deep
Position-Aware Hashing for Semantic Continuous Image Retrieval</a><a href="#fnref45" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn46"><p><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0306457319305357">Label
consistent locally linear embedding based cross-modal hashing</a><a href="#fnref46" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn47"><p><a target="_blank" rel="noopener" href="https://see.xidian.edu.cn/faculty/chdeng/Welcome%20to%20Cheng%20Deng&#39;s%20Homepage_files/Papers/Journal/TNNLS2020_Cheng.pdf">Two-Stream
Deep Hashing With Class-Specific Centers for Supervised Image
Search</a><a href="#fnref47" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn48"><p><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0306457320307834">Discriminative
dual-stream deep hashing for large-scale image retrieval</a><a href="#fnref48" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn49"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1905.01304.pdf">Efficient Discrete
Supervised Hashing for Large-scale Cross-modal Retrieval</a><a href="#fnref49" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn50"><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9046296/">Similarity-preserving
linkage hashing for online image retrieval</a><a href="#fnref50" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn51"><p><a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/view/16296/16103">Deep
Unsupervised Image Hashing by Maximizing Bit Entropy</a><a href="#fnref51" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn52"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2105.06138.pdf">Unsupervised Hashing with
Contrastive Information Bottleneck</a><a href="#fnref52" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn53"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2010.07804.pdf">CIMON:
Towards High-quality Hash Codes</a><a href="#fnref53" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn54"><p><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Jang_Self-Supervised_Product_Quantization_for_Deep_Unsupervised_Image_Retrieval_ICCV_2021_paper.pdf">Self-supervised
Product Quantization for Deep Unsupervised Image Retrieval</a><a href="#fnref54" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn55"><p><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/pdf/10.1145/3404835.3462896">Binary Neural
Network Hashing for Image Retrieval</a><a href="#fnref55" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn56"><p><a target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/abs/pii/S0031320321001631">Deep
center-based dual-constrained hashing for discriminative face image
retrieval</a><a href="#fnref56" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn57"><p><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/abs/10.1145/3474085.3475570">A Statistical
Approach to Mining Semantic Similarity for Deep Unsupervised
Hashing</a><a href="#fnref57" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn58"><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2201.13322.pdf">Learning
to Hash Naturally Sorts</a><a href="#fnref58" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn59"><p><a target="_blank" rel="noopener" href="https://ojs.aaai.org/index.php/AAAI/article/download/20147/19906">Contrastive
Quantization with Code Memory for Unsupervised Image Retrieval</a><a href="#fnref59" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn60"><p><a target="_blank" rel="noopener" href="https://www.researchgate.net/profile/Shujuan-Ji/publication/359796301_An_efficient_dual_semantic_preserving_hashing_for_cross-modal_retrieval/links/625680cf328abe6281538210/An-efficient-dual-semantic-preserving-hashing-for-cross-modal-retrieval.pdf">An
efficient dual semantic preserving hashing for cross-modal
retrieval</a><a href="#fnref60" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn61"><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.14960">Domino:
Discovering systematic errors with cross-modal embeddings</a><a href="#fnref61" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn62"><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/abstract/document/9859900/">Vision
transformer hashing for image retrieval</a><a href="#fnref62" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn63"><p><a target="_blank" rel="noopener" href="https://dl.acm.org/doi/abs/10.1145/3512527.3531381">CLIP4Hashing:
Unsupervised Deep Hashing for Cross-Modal Video-Text Retrieval</a><a href="#fnref63" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://github.com/myhz0606/2023/01/28/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/myhz0606/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/myhz0606/2023/01/28/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-01-28 10:26:35" itemprop="dateCreated datePublished" datetime="2023-01-28T10:26:35+08:00">2023-01-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-20 13:46:40" itemprop="dateModified" datetime="2023-02-20T13:46:40+08:00">2023-02-20</time>
              </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>78</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very
first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for
more info. If you get any problems when using Hexo, you can find the
answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or
you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://github.com/myhz0606/2016/01/02/2016-01-02-Notes-On-Creating-A-Hexo-Theme/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/myhz0606/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/myhz0606/2016/01/02/2016-01-02-Notes-On-Creating-A-Hexo-Theme/" class="post-title-link" itemprop="url">Notes On Creating A Hexo Theme</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2016-01-02 00:00:00" itemprop="dateCreated datePublished" datetime="2016-01-02T00:00:00+08:00">2016-01-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-20 13:46:22" itemprop="dateModified" datetime="2023-02-20T13:46:22+08:00">2023-02-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/myhz0606/categories/Hexo/" itemprop="url" rel="index"><span itemprop="name">Hexo</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>414</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <div class="image-strip">
<img src="https://s3.amazonaws.com/ptsteadman-images/hexo.png" class>
</div>
<h2 id="setup">Setup</h2>
<p>To Update NPM: <code>npm install npm@latest -g</code>.</p>
<p>In 2015 it makes sense to use NVM. <a target="_blank" rel="noopener" href="http://linoxide.com/ubuntu-how-to/install-node-js-ubuntu">NVM
Installation Instructions</a>.</p>
<p>Update NPM: <code>npm install npm@latest -g</code></p>
<p>Hexo: why can't you use helper functions in source code? This should
be in docs.</p>
<h2 id="creating-a-custom-index-file-in-hexo">Creating a Custom Index
File in Hexo</h2>
<p>Trying to generate a custom index file in source, hexo would ignore
<code>source/index.md</code> no matter what I did. What I had to do was
uninstall <code>hexo-generator-index</code>. <a href="https://github.com/hexojs/hexo/issues/1077">See here</a>. Then it
works. So, that will be part of the setup for my theme. But, it's worth
it in order to properly seperate the theme from the content, I think.
Having everyone edit the theme index.ejs template is no good.</p>
<h2 id="hexo-rendering-raw-ejs-file-problem-i-encountered">Hexo
Rendering Raw EJS File Problem I Encountered</h2>
<p>Sometimes the server would keep rendering an old version of my code,
but as text. So I'd see stuff like</p>
<pre><code>&lt;% if (site.tags.length)&#123; %&gt;</code></pre>
<p>The raw ejs, essentially. Restarting the server or running
<code>hexo clean</code> didn't do anything.</p>
<p>After some time, I realized it was due to the gedit swap files being
read by hexo as the actual layout files: for example,
<code>tag.ejs~</code>. My <code>partial</code> helpers looked like:
<code>&lt;%- partial('_partials/tag') %&gt;</code>, and apparently hexo
was reading in <code>tag.ejs~</code> instead of <code>tag.ejs</code>.
And therefore, the ejs wasn't rendering.</p>
<p>To fix this, I simply changed my partial helper to
<code>&lt;%- partial('_partials/tag.ejs') %&gt;</code>. Problem
solved.</p>
<h2 id="hexo-excerpt-variable">Hexo Excerpt Variable</h2>
<p>I was confused by the behavior of the hexo <code>excerpt</code>
variable. If you define <code>excerpt: something</code> in the front
matter, hexo ignores that. Instead, to get it to work, one needs to add
a <code>&lt;!-- more --&gt;</code> comment in the source of the post.
Or, you can install a plugin that allows you to define custom excerpt in
the front matter.</p>
<h2 id="scripts-directory">Scripts Directory</h2>
<p>One of the things I really discovered too late is the "Scripts"
directory in the theme folder. In Hexo, the various plugins drive the
structure of the site, as opposed to the placement of different files
and directories, as in Jekyll. The plugins programatically create folder
structure, etc, where in Jekyll I mostly used the liquid markup to
structure the site.</p>
<p>The problem is, then, that the user wants to extend hexo to do some
sort of custom thing. If one had to publish a new plugin, that'd be too
much work. But the theme level scripts folder allows one to extend the
base hexo functionality in 'user space' effectively.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://github.com/myhz0606/2015/05/02/2015-05-02-How-To-Impress/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/myhz0606/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/myhz0606/2015/05/02/2015-05-02-How-To-Impress/" class="post-title-link" itemprop="url">How To Impress Employers at Infosessions</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2015-05-02 00:00:00" itemprop="dateCreated datePublished" datetime="2015-05-02T00:00:00+08:00">2015-05-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-20 13:45:55" itemprop="dateModified" datetime="2023-02-20T13:45:55+08:00">2023-02-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/myhz0606/categories/Hexo/" itemprop="url" rel="index"><span itemprop="name">Hexo</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>462</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Top tech talent knows that industry recruiters often bring a stack of
pre-negotiated offers to university infosessions, so that they can snag
programmers and UX designers who really stand out. Instead of spending
valuable time validating a particularly promising candidate's skillset
through a protracted series of interviews, it's often more efficient to
simply <strong>give the individual an offer right then and
there</strong>. Internal studies at Google have shown that experienced
recruiters can usually tell if a programmer has 'what it takes' just
from how they act at infosessions: the insightful questions they ask,
the stickers on their laptop, and how they comport themselves in
general.</p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/myhz0606/2015/05/02/2015-05-02-How-To-Impress/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://github.com/myhz0606/2015/04/08/2015-04-08-NAV-Programming-Resources/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/myhz0606/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/myhz0606/2015/04/08/2015-04-08-NAV-Programming-Resources/" class="post-title-link" itemprop="url">NAV Web Service Programming Resources</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2015-04-08 00:00:00" itemprop="dateCreated datePublished" datetime="2015-04-08T00:00:00+08:00">2015-04-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-20 13:45:47" itemprop="dateModified" datetime="2023-02-20T13:45:47+08:00">2023-02-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/myhz0606/categories/Hexo/" itemprop="url" rel="index"><span itemprop="name">Hexo</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>375</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Here are some of the resources I found helpful for learning to
develop Dynamics NAV web service based applications.</p>
<h4 id="cal-programming">C/AL Programming:</h4>
<p><a target="_blank" rel="noopener" href="http://www.consultec.es/DocTutoriales/Introduction_to_CAL_Programming.pdf">Introduction
to CAL Programming</a> This provides a good overview of the basics of
CAL programming, which can become necessary in building a web service
applications when a custom codeunit or page extension is required.</p>
<h4 id="setting-up-web-services">Setting up Web Services:</h4>
<p><a target="_blank" rel="noopener" href="http://vjeko.com/blog/connecting-to-nav-through-web-services-recorded-session">Vjecko
Web Service Recorded Session</a> Vjecko.com has a lot of detailed
articles about web service programming, but this older post has a pdf
and recorded session that shows how to expose and connect to web
services from a .NET application. Unfortunately, he shows how to create
Web Service references in .NET using the now-deprecated Web Refrence
method (from .NET 2) instead of the more current Service Reference
method.</p>
<p><a target="_blank" rel="noopener" href="http://blogs.msdn.com/b/freddyk/archive/2010/01/20/connecting-to-nav-web-services-from-c-using-service-reference-config-file-version.aspx">Using
Service Reference to Connect to Web Services</a> This explains how to
use Service Reference, using code instead of XML web.config
configuration, which I found difficult to configure. (Each time I
updated the service reference, I would have to reconfigure the XML).</p>
<h4 id="nav-upgrade-process">NAV Upgrade Process:</h4>
<p><a target="_blank" rel="noopener" href="http://saurav-nav.blogspot.com/2012/12/nav-2013-upgrade-part-iv-sql-migration.html">Migration
to SQL Server from C/SIDE Database</a> In order to use web services, you
don't need to be using the Role Tailored Client, but you must be using
the a SQL server based NAV database. Web Services can be configured and
exposed using the Classic Client for SQL Server Databases.</p>
<p><a target="_blank" rel="noopener" href="http://blogs.msdn.com/b/nav/archive/2012/03/05/rtc-debugging.aspx">Debugging
Code Called by Web Services</a> C/AL code won't necessarily execute the
same as it did in the Classic Client when called as a Web Service. C/AL
code called as web service execute in the NAV Server tier, instead of
the client. <a target="_blank" rel="noopener" href="http://msdn.microsoft.com/en-us/library/ff477107.aspx">Certain
functions</a> aren't available for code running in the NAV Server, and
some design changes need to be made (for example, CONFIRM dialogue boxes
don't make sense in the context of a web service). To debug the
codeunits called through web services (or the Role Tailored Client), you
will need to use Visual Studio. <a target="_blank" rel="noopener" href="http://msdn.microsoft.com/en-us/library/dd338765.aspx#SU">More
information.</a></p>
<h4 id="deploying-a-.net-application">Deploying a .NET Application:</h4>
<p><a target="_blank" rel="noopener" href="http://www.asp.net/mvc/overview/deployment/visual-studio-web-deployment/deploying-to-iis">Deploying
to IIS</a> After you've built a .NET application that consumes .NET web
services, you'll have to find a way to deploy it on your servers, or
Azure. Connection strings can be used to specify different NAV servers
for different environments (like development, QA, and prod).</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://github.com/myhz0606/2015/04/05/2015-04-05-Lookup-on-Page/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/myhz0606/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/myhz0606/2015/04/05/2015-04-05-Lookup-on-Page/" class="post-title-link" itemprop="url">Adding Lookup Field to a Page in Dynamics NAV</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2015-04-05 00:00:00" itemprop="dateCreated datePublished" datetime="2015-04-05T00:00:00+08:00">2015-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-20 13:45:35" itemprop="dateModified" datetime="2023-02-20T13:45:35+08:00">2023-02-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/myhz0606/categories/Hexo/" itemprop="url" rel="index"><span itemprop="name">Hexo</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>451</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>2 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>One of the problems I faced in building a non-trivial application
that consumed NAV Web Services was figuring out how to "join" fields
from different tables. For example, when exposing a list of jobs from a
job table which includes a resource needed for the job, you might need
more than just the resource id that's a field in the table: you might
also need the resource name and description. While this is easy to get
for one record, what about when you need a few hundred records in a
table that has been dynamically filtered? When exposing a Page as a web
service, it's easy to include the fields of the table that the page is
based on, but it's less clear how to include fields from another
table.</p>
<p>Forum posts like <a target="_blank" rel="noopener" href="http://dynamicsuser.net/forums/p/32550/170843.aspx">this</a> led
me to believe that I couldn't expose flow fields in a Page web service,
and I would get exceptions when I tried to expose all the fields of a
table. In fact, it's perfectly possible to expose a flow field: it's
<strong>flow filters</strong> that don't work with web services. But, I
also didn't want to modify the underlying [job] table to add a flow
field, and didn't see an easy way of adding a flow field to a Page. I
tried "joining" the data in the C# application, but found network
overhead made the application unusuably slow.</p>
<p>The solution to this problem was to use C/AL code to the Page to
effectively create a lookup / flow field. This way, the data is
"pre-joined" before leaving the NAV Server, which is fast and clean, but
you didn't modify any tables. Here's how it's done:</p>
<p>Step 1. <strong>Add a Field with SourceExpression Set to a Function
Name</strong></p>
<p>To start, we create a Page using the wizard that includes all of the
fields of an underlying table. Then, we create manually add fields that
will contain the lookup data from other tables. The text in the
SourceExpression column will be the name of the function that populates
this field. <img src="http://ptsteadman.github.io/images/lookup-1.PNG" alt="Add a Field with SourceExpression Set to a Function Name"></p>
<p>Step 2. <strong>Create Function in the Page's C/AL Code</strong></p>
<p>With the Page field designer open, go to the functions tab of C/AL
Globals form, and add a function with the name of the text in the
SourceExpression column. Set the return type of the function with the
"Locals" button, and a function trigger will appear in the C/AL code
editor for your page. Add code to the body of the function trigger that
will be called for each record to provide a value for the field. <img src="http://ptsteadman.github.io/images/lookup-2.PNG" alt="Create Function in the Page&#39;s C/AL Code"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://github.com/myhz0606/2014/02/23/2014-02-23-hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/myhz0606/images/avatar.gif">
      <meta itemprop="name" content="wwjiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="莫叶何竹">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/myhz0606/2014/02/23/2014-02-23-hello-world/" class="post-title-link" itemprop="url">Welcome To Hexo</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2014-02-23 00:00:00" itemprop="dateCreated datePublished" datetime="2014-02-23T00:00:00+08:00">2014-02-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-02-20 13:46:31" itemprop="dateModified" datetime="2023-02-20T13:46:31+08:00">2023-02-20</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/myhz0606/categories/Hexo/" itemprop="url" rel="index"><span itemprop="name">Hexo</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>79</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>1 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a target="_blank" rel="noopener" href="http://hexo.io/">Hexo</a>! This is your very
first post. Check <a target="_blank" rel="noopener" href="http://hexo.io/docs/">documentation</a> for
more info. If you get any problems when using Hexo, you can find the
answer in <a target="_blank" rel="noopener" href="http://hexo.io/docs/troubleshooting.html">troubleshooting</a> or
you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/myhz0606/2014/02/23/2014-02-23-hello-world/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">wwjiang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/myhz0606/archives/">
        
          <span class="site-state-item-count">8</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/myhz0606/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/myhz0606/tags/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wwjiang</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">12k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">45 分钟</span>
</div>

<!--
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>
-->

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/myhz0606/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/myhz0606/lib/velocity/velocity.min.js"></script>
  <script src="/myhz0606/lib/velocity/velocity.ui.min.js"></script>

<script src="/myhz0606/js/utils.js"></script>

<script src="/myhz0606/js/motion.js"></script>


<script src="/myhz0606/js/schemes/muse.js"></script>


<script src="/myhz0606/js/next-boot.js"></script>

<script src="/myhz0606/js/bookmark.js"></script>




  




  
<script src="/myhz0606/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
